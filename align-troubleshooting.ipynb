{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "127b5eb3",
   "metadata": {},
   "source": [
    "# Align and remove blanks\n",
    "\n",
    "Adapted from Giulia Vallardi's ImageJ macro, this notebook removes any blank frames from timelapse experiments and aligns the images. \n",
    "\n",
    "\"Fiji macro to remove over- and under-exposed images, and align the image stacks\n",
    "\n",
    "The settings for the alignments are: \n",
    "registration by Translation > only modify XY coordinates\n",
    "Shrinkage constrain activated (this model allows a better registration based on all images, not using a reference image. It is more time consuming though)\n",
    "Transform matrices are saved during registration and then applied to the other channels during transformation.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7859805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import enum\n",
    "import numpy as np\n",
    "from pystackreg import StackReg\n",
    "from skimage import io\n",
    "from tqdm import tqdm\n",
    "from octopuslite import DaskOctopusLiteLoader\n",
    "from skimage import transform as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b349a8a0",
   "metadata": {},
   "source": [
    "# Find images, organise into raw folder and load using dask octo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbeda8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### define root directory and specific experiment and location (will later make iterable)\n",
    "root_dir = '/home/nathan/data/kraken/commitment/test/'\n",
    "expt = \"MK0003\"\n",
    "pos = \"Pos1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1a5cbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "### create new subdir of for raw files and move them all there\n",
    "if not os.path.exists(os.path.join(root_dir, f'{expt}/{pos}/{pos}_raw')):\n",
    "    os.mkdir(os.path.join(root_dir, f'{expt}/{pos}/{pos}_raw'))\n",
    "    files = sorted(glob.glob(os.path.join(root_dir, f'{expt}/{pos}/*.tif')))\n",
    "    for file in files:\n",
    "        os.rename(file, file.replace(f'{pos}', f'{pos}/{pos}_raw'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a3d0870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cropping: None\n"
     ]
    }
   ],
   "source": [
    "### pre load files from raw file dir \n",
    "images = DaskOctopusLiteLoader(os.path.join(root_dir, f'{expt}/{pos}/{pos}_raw'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "683028b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table>\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 2.55 GiB </td>\n",
       "                        <td> 2.18 MiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (1200, 1352, 1688) </td>\n",
       "                        <td> (1, 1352, 1688) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Count </th>\n",
       "                        <td> 3600 Tasks </td>\n",
       "                        <td> 1200 Chunks </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                    <th> Type </th>\n",
       "                    <td> uint8 </td>\n",
       "                    <td> numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"230\" height=\"196\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"60\" y2=\"50\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"10\" y1=\"96\" x2=\"60\" y2=\"146\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"12\" y2=\"98\" />\n",
       "  <line x1=\"15\" y1=\"5\" x2=\"15\" y2=\"101\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"17\" y2=\"104\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"20\" y2=\"106\" />\n",
       "  <line x1=\"23\" y1=\"13\" x2=\"23\" y2=\"109\" />\n",
       "  <line x1=\"25\" y1=\"15\" x2=\"25\" y2=\"111\" />\n",
       "  <line x1=\"28\" y1=\"18\" x2=\"28\" y2=\"114\" />\n",
       "  <line x1=\"31\" y1=\"21\" x2=\"31\" y2=\"117\" />\n",
       "  <line x1=\"33\" y1=\"23\" x2=\"33\" y2=\"119\" />\n",
       "  <line x1=\"36\" y1=\"26\" x2=\"36\" y2=\"122\" />\n",
       "  <line x1=\"39\" y1=\"29\" x2=\"39\" y2=\"125\" />\n",
       "  <line x1=\"41\" y1=\"31\" x2=\"41\" y2=\"127\" />\n",
       "  <line x1=\"44\" y1=\"34\" x2=\"44\" y2=\"130\" />\n",
       "  <line x1=\"46\" y1=\"36\" x2=\"46\" y2=\"133\" />\n",
       "  <line x1=\"49\" y1=\"39\" x2=\"49\" y2=\"135\" />\n",
       "  <line x1=\"52\" y1=\"42\" x2=\"52\" y2=\"138\" />\n",
       "  <line x1=\"54\" y1=\"44\" x2=\"54\" y2=\"140\" />\n",
       "  <line x1=\"57\" y1=\"47\" x2=\"57\" y2=\"143\" />\n",
       "  <line x1=\"60\" y1=\"50\" x2=\"60\" y2=\"146\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 60.181209924728186,50.181209924728186 60.181209924728186,146.29495400055757 10.0,96.11374407582939\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"130\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"132\" y2=\"2\" />\n",
       "  <line x1=\"15\" y1=\"5\" x2=\"135\" y2=\"5\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"137\" y2=\"7\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"140\" y2=\"10\" />\n",
       "  <line x1=\"23\" y1=\"13\" x2=\"143\" y2=\"13\" />\n",
       "  <line x1=\"25\" y1=\"15\" x2=\"145\" y2=\"15\" />\n",
       "  <line x1=\"28\" y1=\"18\" x2=\"148\" y2=\"18\" />\n",
       "  <line x1=\"31\" y1=\"21\" x2=\"151\" y2=\"21\" />\n",
       "  <line x1=\"33\" y1=\"23\" x2=\"153\" y2=\"23\" />\n",
       "  <line x1=\"36\" y1=\"26\" x2=\"156\" y2=\"26\" />\n",
       "  <line x1=\"39\" y1=\"29\" x2=\"159\" y2=\"29\" />\n",
       "  <line x1=\"41\" y1=\"31\" x2=\"161\" y2=\"31\" />\n",
       "  <line x1=\"44\" y1=\"34\" x2=\"164\" y2=\"34\" />\n",
       "  <line x1=\"46\" y1=\"36\" x2=\"166\" y2=\"36\" />\n",
       "  <line x1=\"49\" y1=\"39\" x2=\"169\" y2=\"39\" />\n",
       "  <line x1=\"52\" y1=\"42\" x2=\"172\" y2=\"42\" />\n",
       "  <line x1=\"54\" y1=\"44\" x2=\"174\" y2=\"44\" />\n",
       "  <line x1=\"57\" y1=\"47\" x2=\"177\" y2=\"47\" />\n",
       "  <line x1=\"60\" y1=\"50\" x2=\"180\" y2=\"50\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"60\" y2=\"50\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"130\" y1=\"0\" x2=\"180\" y2=\"50\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 130.0,0.0 180.1812099247282,50.181209924728186 60.181209924728186,50.181209924728186\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"60\" y1=\"50\" x2=\"180\" y2=\"50\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"60\" y1=\"146\" x2=\"180\" y2=\"146\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"60\" y1=\"50\" x2=\"60\" y2=\"146\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"180\" y1=\"50\" x2=\"180\" y2=\"146\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"60.181209924728186,50.181209924728186 180.1812099247282,50.181209924728186 180.1812099247282,146.29495400055757 60.181209924728186,146.29495400055757\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"120.181210\" y=\"166.294954\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >1688</text>\n",
       "  <text x=\"200.181210\" y=\"98.238082\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,200.181210,98.238082)\">1352</text>\n",
       "  <text x=\"25.090605\" y=\"141.204349\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,25.090605,141.204349)\">1200</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<stack, shape=(1200, 1352, 1688), dtype=uint8, chunksize=(1, 1352, 1688), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images['irfp']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4314a4",
   "metadata": {},
   "source": [
    "# Find blank or overexposed images and display average channel brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df51bb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel = images.channels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c48412ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cropping: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding mean values of brightfield images: 100%|██████████| 4/4 [02:18<00:00, 34.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of under/over-exposed frames: 8\n",
      "CPU times: user 26.7 s, sys: 7.89 s, total: 34.6 s\n",
      "Wall time: 2min 19s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# pixel range criteria\n",
    "max_pixel, min_pixel = 200, 2\n",
    "\n",
    "### find mean values ### pre load files from raw file dir \n",
    "images = DaskOctopusLiteLoader(os.path.join(root_dir, f'{expt}/{pos}/{pos}_raw'))\n",
    "\n",
    "mean_arrays = {}\n",
    "dodgy_frame_list = set([])\n",
    "for channel in tqdm(images.channels, desc = f'Finding mean values of image channels'):\n",
    "    mean_arrays[channel.name] = np.mean(images[channel.name], axis = (1,2)).compute() \n",
    "    for frame, mean_value in enumerate(mean_arrays[channel.name]):\n",
    "        if max_pixel < mean_value or mean_value < min_pixel:\n",
    "            dodgy_frame_list.add(frame)\n",
    "dodgy_frame_list = list(dodgy_frame_list)\n",
    "\n",
    "print('Number of under/over-exposed frames:', len(dodgy_frame_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d691578",
   "metadata": {},
   "source": [
    "# Filtering to remove blank or overexposed frames from image array and mean value arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e00d0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_images= {}\n",
    "for channel in images.channels:\n",
    "    filtered_images[channel.name] = np.delete(images[channel], dodgy_frame_list, axis = 0)\n",
    "    mean_arrays[channel.name] = np.delete(mean_arrays[channel.name], dodgy_frame_list, axis = 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "13077a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BRIGHTFIELD': dask.array<concatenate, shape=(1192, 1352, 1688), dtype=uint8, chunksize=(1, 1352, 1688), chunktype=numpy.ndarray>,\n",
       " 'GFP': dask.array<concatenate, shape=(1192, 1352, 1688), dtype=uint8, chunksize=(1, 1352, 1688), chunktype=numpy.ndarray>,\n",
       " 'RFP': dask.array<concatenate, shape=(1192, 1352, 1688), dtype=uint8, chunksize=(1, 1352, 1688), chunktype=numpy.ndarray>,\n",
       " 'IRFP': dask.array<concatenate, shape=(1192, 1352, 1688), dtype=uint8, chunksize=(1, 1352, 1688), chunktype=numpy.ndarray>}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06e525f",
   "metadata": {},
   "source": [
    "# Select reference image to base alignment around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9407bfcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average channel brightness for selection of reference image:\n",
      "0: BRIGHTFIELD: 28.57426395073836\n",
      "1: GFP: 62.6540838696175\n",
      "2: RFP: 6.033528252931007\n",
      "3: IRFP: 76.07041093682862\n"
     ]
    }
   ],
   "source": [
    "print('Average channel brightness for selection of reference image:')\n",
    "for channel in images.channels:\n",
    "    print(f'{channel.value}: {channel.name}:', np.mean(mean_arrays[channel.name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6228689a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference channel: IRFP\n"
     ]
    }
   ],
   "source": [
    "# manually select reference channel by adding index\n",
    "# reference_channel = filtered_images['IRFP']\n",
    "# automatically select reference channel from max average pixel value (ie. brightest channel)\n",
    "reference_channel = images.channels[max([(channel.value, np.mean(mean_arrays[channel.name])) for channel in images.channels])[0]]\n",
    "reference_image = filtered_images[reference_channel.name]\n",
    "print('Reference channel:', reference_channel.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095cd623",
   "metadata": {},
   "source": [
    "## Set cropped area of reference image to base alignment around (whole image struggles to compute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "541f1915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1192, 500, 500)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crop_area = 500\n",
    "reference_image = reference_image[:,int((reference_image.shape[2]-crop_area)/2):int(reference_image.shape[2]-(reference_image.shape[2]-crop_area)/2),int((reference_image.shape[1]-crop_area)/2):int(reference_image.shape[1]-(reference_image.shape[1]-crop_area)/2)].compute()\n",
    "reference_image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534c5b5f",
   "metadata": {},
   "source": [
    "# Register alignment and save out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3de9f89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nathan/analysis/miniconda3/envs/cellx/lib/python3.9/site-packages/pystackreg/pystackreg.py:379: UserWarning: Detected axis 2 as the possible time axis for the stack due to its low variability, but axis 0 was supplied for registration. Are you sure you supplied the correct axis?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 33s, sys: 9.39 s, total: 2min 42s\n",
      "Wall time: 2min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create operator using transformation type (translation)\n",
    "sr = StackReg(StackReg.TRANSLATION) \n",
    "\n",
    "# register each frame to the previous as transformation matrices/tensor\n",
    "transform_tensor = sr.register_stack(reference_image, reference = 'first')\n",
    "\n",
    "# save out transform tensor\n",
    "np.save(os.path.join(root_dir, f'{expt}/{pos}/{reference_channel.name.lower()}_transform_tensor.npy'), transform_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae1b12f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1192, 3, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3f8b67",
   "metadata": {},
   "source": [
    "# Apply transformation matrix to all channels and save out images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "183a2711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning brightfield channel 1 / 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1191/1191 [06:33<00:00,  3.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning gfp channel 2 / 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1191/1191 [02:33<00:00,  7.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning rfp channel 3 / 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1191/1191 [02:29<00:00,  7.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning irfp channel 4 / 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1191/1191 [02:27<00:00,  8.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 5s, sys: 1min 4s, total: 7min 9s\n",
      "Wall time: 14min 3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### iterating over channels\n",
    "# create aligned image dir if does not exist \n",
    "if not os.path.exists(os.path.join(root_dir, f'{expt}/{pos}/{pos}_filtered_aligned')):\n",
    "    os.mkdir(os.path.join(root_dir, f'{expt}/{pos}/{pos}_filtered_aligned'))\n",
    "# iterate over channels\n",
    "for channel in images.channels:\n",
    "    print('Aligning', channel.name.lower(), 'channel', channel.value+1, '/', len(images.channels))\n",
    "    #iterate over all images in channel\n",
    "    for i in tqdm(range(1, len(filtered_images[channel.name]))):\n",
    "        # load specific transform matrix for that frame\n",
    "        transform_matrix = tf.EuclideanTransform(matrix = transform_tensor[i,...],rotation = None)\n",
    "        # transform image\n",
    "        transformed_image = (tf.warp(filtered_images[channel.name][i,...], transform_matrix)*255).astype(np.uint8)\n",
    "        # set transformed image pathname by editing base dir\n",
    "        fn = images.files(channel.name)[i].replace('_raw', '_filtered_aligned')\n",
    "        # save trans image out\n",
    "        io.imsave(fn, transformed_image, check_contrast=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd310bc",
   "metadata": {},
   "source": [
    "# check images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af516a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "71ad31a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cropping: None\n",
      "Using cropping: None\n"
     ]
    }
   ],
   "source": [
    "aligned_images = DaskOctopusLiteLoader(os.path.join(root_dir, f'{expt}/{pos}/{pos}_filtered_aligned_2'))\n",
    "old_aligned_images = DaskOctopusLiteLoader(os.path.join(root_dir, f'{expt}/{pos}/{pos}_aligned_nonfilt'))\n",
    "viewer = napari.Viewer()\n",
    "for channel in aligned_images.channels:\n",
    "    if channel.name == 'IRFP':\n",
    "        viewer.add_image(aligned_images[channel.name], name = channel.name, blending = 'additive', contrast_limits = [0,255])\n",
    "        #, colormap = napari.utils.colormaps.SIMPLE_COLORMAPS.popitem()) # lazy hack to randomly generate different colormaps\n",
    "                         #, colormap = napari.utils.colormaps.SIMPLE_COLORMAPS.popitem()) # lazy hack to randomly generate different colormaps\n",
    "        viewer.add_image(old_aligned_images[channel.name], name = channel.name+'old', blending = 'additive', contrast_limits = [0,255])\n",
    "                         #, colormap = napari.utils.colormaps.SIMPLE_COLORMAPS.popitem()) # lazy hack to randomly generate different colormaps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753378b7",
   "metadata": {},
   "source": [
    "# Troubleshooting jumpy transforms\n",
    "\n",
    "-- still have jumpy transforms using first frame ref and filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcbac05",
   "metadata": {},
   "source": [
    "# Check transform tensor for jumpy transtitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8a2e4bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame 126 \n",
      " [[  1.           0.         -19.02108231]\n",
      " [  0.           1.          31.07344466]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 127 \n",
      " [[  1.           0.         -19.36564639]\n",
      " [  0.           1.          28.93408194]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 128 \n",
      " [[  1.           0.         -22.73306477]\n",
      " [  0.           1.          37.18687011]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 129 \n",
      " [[  1.           0.         -25.49416724]\n",
      " [  0.           1.          38.08791503]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 130 \n",
      " [[  1.           0.         -27.43691191]\n",
      " [  0.           1.          38.71046724]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 131 \n",
      " [[  1.           0.         -34.23882241]\n",
      " [  0.           1.          69.13530435]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 132 \n",
      " [[  1.           0.         -60.7223268 ]\n",
      " [  0.           1.         143.11096348]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 133 \n",
      " [[  1.           0.         -23.14718633]\n",
      " [  0.           1.          39.04815069]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 134 \n",
      " [[  1.           0.         -27.36112267]\n",
      " [  0.           1.          52.71528692]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 135 \n",
      " [[  1.           0.         -22.62456355]\n",
      " [  0.           1.          39.33162188]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 136 \n",
      " [[  1.           0.         -28.83190176]\n",
      " [  0.           1.          47.20116076]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 137 \n",
      " [[  1.           0.         -23.045223  ]\n",
      " [  0.           1.          39.18217124]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 138 \n",
      " [[  1.           0.         -22.6777873 ]\n",
      " [  0.           1.          39.23370422]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 139 \n",
      " [[  1.           0.         -23.07077713]\n",
      " [  0.           1.          38.90858959]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 140 \n",
      " [[  1.           0.         -24.91615943]\n",
      " [  0.           1.          39.06950449]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 141 \n",
      " [[  1.           0.         -23.16157175]\n",
      " [  0.           1.          37.07473665]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 142 \n",
      " [[  1.           0.         -29.12883967]\n",
      " [  0.           1.          47.1004    ]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 143 \n",
      " [[  1.           0.         -23.49478749]\n",
      " [  0.           1.          38.16653521]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 144 \n",
      " [[  1.           0.         -42.19971558]\n",
      " [  0.           1.          93.07891358]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 145 \n",
      " [[  1.           0.         -21.66897557]\n",
      " [  0.           1.          30.86828998]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 146 \n",
      " [[  1.           0.         -43.44697683]\n",
      " [  0.           1.         100.80092075]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 147 \n",
      " [[  1.           0.         -47.80803083]\n",
      " [  0.           1.         100.0377541 ]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 148 \n",
      " [[  1.           0.         -44.99904387]\n",
      " [  0.           1.         110.75903663]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 149 \n",
      " [[  1.           0.         -35.04039876]\n",
      " [  0.           1.          84.92406115]\n",
      " [  0.           0.           1.        ]]\n"
     ]
    }
   ],
   "source": [
    "for j, i in enumerate(transform_tensor):\n",
    "    if 150 > j > 125:\n",
    "        print(\"frame\", j,'\\n', i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83af419f",
   "metadata": {},
   "source": [
    "# problematic shift at frame 1183"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "821eda60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[59, 61, 62, ..., 75, 76, 75],\n",
       "       [60, 61, 59, ..., 71, 73, 76],\n",
       "       [61, 60, 60, ..., 72, 74, 77],\n",
       "       ...,\n",
       "       [70, 71, 70, ..., 81, 86, 85],\n",
       "       [66, 68, 72, ..., 83, 87, 85],\n",
       "       [70, 70, 71, ..., 84, 87, 85]], dtype=uint8)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_image[1182]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e305fe5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[57, 60, 59, ..., 74, 70, 76],\n",
       "       [60, 62, 62, ..., 76, 74, 74],\n",
       "       [60, 61, 65, ..., 75, 71, 73],\n",
       "       ...,\n",
       "       [70, 68, 67, ..., 89, 88, 85],\n",
       "       [69, 65, 65, ..., 83, 84, 84],\n",
       "       [66, 68, 67, ..., 81, 85, 86]], dtype=uint8)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_image[1183]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "28ce64d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[61, 60, 62, ..., 72, 73, 74],\n",
       "       [56, 58, 60, ..., 74, 71, 73],\n",
       "       [60, 59, 63, ..., 70, 73, 72],\n",
       "       ...,\n",
       "       [75, 75, 77, ..., 84, 84, 86],\n",
       "       [72, 76, 74, ..., 83, 80, 89],\n",
       "       [75, 77, 76, ..., 82, 84, 82]], dtype=uint8)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_image[1184]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "31faacff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n",
      "50\n",
      "255\n",
      "49\n",
      "255\n",
      "50\n",
      "255\n",
      "50\n",
      "255\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "### checking raw images\n",
    "for i in range(1181, 1186):\n",
    "    print(np.amax(reference_image[i]))\n",
    "    print(np.amin(reference_image[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21535c5d",
   "metadata": {},
   "source": [
    "# Is the problematic shift a result of the stack reg, ie can i reproduce it in an individual frame by frame registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "04c85900",
   "metadata": {},
   "outputs": [],
   "source": [
    "### problematic frame\n",
    "i = 1183"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "45f1ab0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.        , -0.27052358],\n",
       "       [ 0.        ,  1.        , -0.08158292],\n",
       "       [ 0.        ,  0.        ,  1.        ]])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StackReg(StackReg.TRANSLATION).register(reference_image[i-1], reference_image[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db898ea5",
   "metadata": {},
   "source": [
    "#### is the stack registration a cumulative measure over 1183 frames?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "5d1ff15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1191/1191 [02:38<00:00,  7.53it/s]\n"
     ]
    }
   ],
   "source": [
    "stack_reg = []\n",
    "for i in tqdm(range(1,1192)):\n",
    "    stack_reg.append(StackReg(StackReg.TRANSLATION).register(reference_image[i-1], reference_image[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "ef295815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1191.        ,    0.        ,  -29.8818751 ],\n",
       "       [   0.        , 1191.        ,  127.99044408],\n",
       "       [   0.        ,    0.        , 1191.        ]])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(stack_reg, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d404306",
   "metadata": {},
   "source": [
    "# Try different transformation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4fe2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation matrix should take on the form\n",
    "\n",
    "#             [1 , 0 , x\n",
    "#              0 , 1 , y\n",
    "#              0 , 0 , 1]\n",
    "\n",
    "# where x and y are the translate magnitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "57fb49c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1184"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "389b6798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 1.69270859],\n",
       "       [0.        , 1.        , 0.54300491],\n",
       "       [0.        , 0.        , 1.        ]])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### float translation\n",
    "StackReg(StackReg.TRANSLATION).register(images['gfp'][i-1], images['gfp'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "8faf5856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1]], dtype=int8)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### int translation\n",
    "StackReg(StackReg.TRANSLATION).register(images['gfp'][i-1], images['gfp'][i]).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "290f7c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.99999870e-01,  5.09415957e-04,  1.32909743e+00],\n",
       "       [-5.09415957e-04,  9.99999870e-01,  9.69781071e-01],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00]])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### float rigid body\n",
    "StackReg(StackReg.RIGID_BODY).register(images['gfp'][i-1], images['gfp'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "710e0560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  1.],\n",
       "       [-0.,  1.,  1.],\n",
       "       [ 0.,  0.,  1.]])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### np.rint rigid body\n",
    "np.rint(StackReg(StackReg.RIGID_BODY).register(images['gfp'][i-1], images['gfp'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "6fe75192",
   "metadata": {},
   "outputs": [],
   "source": [
    "### integer-ising the matrix zeroes some important numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "d8bc82ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 1]], dtype=int8)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### int rigidbody\n",
    "StackReg(StackReg.RIGID_BODY).register(images['gfp'][i-1], images['gfp'][i]).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "d069cb67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00010486e+00,  7.31302774e-04,  1.14884038e+00],\n",
       "       [-4.18274933e-04,  9.99898269e-01,  9.75798050e-01],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00]])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### float affine\n",
    "StackReg(StackReg.AFFINE).register(images['gfp'][i-1], images['gfp'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "daa49c40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  1.],\n",
       "       [-0.,  1.,  1.],\n",
       "       [ 0.,  0.,  1.]])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### np.rint affine\n",
    "np.rint(StackReg(StackReg.AFFINE).register(images['gfp'][i-1], images['gfp'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "73cdc0a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 1]], dtype=int8)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### int affine\n",
    "StackReg(StackReg.AFFINE).register(images['gfp'][i-1], images['gfp'][i]).astype(np.int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f18898",
   "metadata": {},
   "source": [
    "# seems like all the alignment methods produce similar shifted outputs... is it the images?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1eda1afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BRIGHTFIELD [[  1   0  84]\n",
      " [  0   1 -15]\n",
      " [  0   0   1]]\n",
      "GFP [[1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]]\n",
      "RFP [[1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]]\n",
      "IRFP [[ 1  0 -1]\n",
      " [ 0  1  0]\n",
      " [ 0  0  1]]\n"
     ]
    }
   ],
   "source": [
    "for channel in images.channels:\n",
    "    print(channel.name, StackReg(StackReg.TRANSLATION).register(images[channel.name][i-1], images[channel.name][i]).astype(np.int8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58bb36f",
   "metadata": {},
   "source": [
    "# is it the gfp channel? checking each channel for max transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "824eaf46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting channel: BRIGHTFIELD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1199/1199 [25:51<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BRIGHTFIELD 126\n",
      "Starting channel: GFP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1199/1199 [26:16<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GFP 108\n",
      "Starting channel: RFP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1199/1199 [27:56<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFP 47\n",
      "Starting channel: IRFP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1199/1199 [27:06<00:00,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRFP 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trans_tensors = {}\n",
    "for channel in images.channels:\n",
    "    print('Starting channel:', channel.name)\n",
    "    trans_tensor = []\n",
    "#     for i in tqdm(range(1, len(images['gfp']))):\n",
    "#         ### create transformation matrix for i'th and i+1'th frame\n",
    "#         trans_matrix = StackReg(StackReg.TRANSLATION).register(images[channel.name][i-1], images[channel.name][i]).astype(np.int8)\n",
    "#         trans_tensor.append(trans_matrix)\n",
    "\n",
    "    trans_tensor = np.stack(trans_tensor)\n",
    "    trans_tensors[channel.name] = trans_tensor\n",
    "    print(channel.name, np.amax(trans_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3decf143",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('all_ch_trans_tensors.json', 'wb') as fp:\n",
    "    pickle.dump(trans_tensors, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c590b2",
   "metadata": {},
   "source": [
    "# Checking the alignment tensors of each channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95971133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BRIGHTFIELD 126\n",
      "GFP 108\n",
      "RFP 47\n",
      "IRFP 24\n"
     ]
    }
   ],
   "source": [
    "for channel in trans_tensors:\n",
    "    print(channel, np.amax(trans_tensors[channel]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d928e8c7",
   "metadata": {},
   "source": [
    "# irfp channel has lowest max shift in so test run alignment on that "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e1d3d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_tensor = trans_tensors['IRFP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c46fbee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.amax(transform_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f300630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200, 1199)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images['gfp']), len(transform_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "33ab7c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning brightfield channel 1 / 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [01:28<00:00, 13.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning gfp channel 2 / 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [01:28<00:00, 13.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning rfp channel 3 / 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [01:26<00:00, 13.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning irfp channel 4 / 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [01:31<00:00, 13.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 11s, sys: 43.9 s, total: 5min 55s\n",
      "Wall time: 5min 54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for channel in images.channels:\n",
    "    print('Aligning', channel.name.lower(), 'channel', channel.value+1, '/', len(images.channels))\n",
    "    #iterate over all images in channel\n",
    "    for i in tqdm(range(len(images[channel.name]))):\n",
    "        # skip dodgy frames and don't save out into aligned folder\n",
    "        if i in dodgy_frame_list or i == 1199:\n",
    "            continue\n",
    "        # load specific transform matrix for that frame\n",
    "        transform_matrix = tf.EuclideanTransform(matrix = transform_tensor[i,...],rotation = None)\n",
    "        # transform image\n",
    "        transformed_image = (tf.warp(images[channel.name][i,...], transform_matrix)*255).astype(np.uint8)\n",
    "        # set transformed image pathname by editing base dir\n",
    "        fn = images.files(channel.name)[i].replace('_raw', '_aligned')\n",
    "        # save trans image out\n",
    "        io.imsave(fn, transformed_image, check_contrast=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3aac445",
   "metadata": {},
   "source": [
    "# Batch execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63fa67c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/home/nathan/data/kraken/commitment/test/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc821c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "alignment(expt_list = ['MK0000', 'MK0001', 'MK0002', 'MK0003'], \n",
    "          max_pixel = 200, \n",
    "          min_pixel = 2, \n",
    "          crop_area = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952bbbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()\n",
    "for channel in aligned_images.channels:\n",
    "    viewer.add_image(aligned_images[channel.name], name = channel.name, blending = 'additive', contrast_limits = [0,255], colormap = napari.utils.colormaps.SIMPLE_COLORMAPS.popitem()) # lazy hack to randomly generate different colormaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eea9708c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alignment(expt_list, max_pixel, min_pixel, crop_area):\n",
    "\n",
    "    ### Iterate over all experiments defined in expt_list\n",
    "    for expt in expt_list:\n",
    "        # Find all positions in that experiment\n",
    "        pos_list = [pos for pos in os.listdir(os.path.join(root_dir, expt)) if 'Pos' in pos]\n",
    "        ### Iterate over all positions in that experiment\n",
    "        for pos in pos_list:\n",
    "            ### create new subdir of for raw files and move them all there\n",
    "            if not os.path.exists(os.path.join(root_dir, f'{expt}/{pos}/{pos}_raw')):\n",
    "                os.mkdir(os.path.join(root_dir, f'{expt}/{pos}/{pos}_raw'))\n",
    "                files = sorted(glob.glob(os.path.join(root_dir, f'{expt}/{pos}/*.tif')))\n",
    "                for file in files:\n",
    "                    os.rename(file, file.replace(f'{pos}', f'{pos}/{pos}_raw'))\n",
    "\n",
    "            ### pre load files from raw file dir \n",
    "            images = DaskOctopusLiteLoader(os.path.join(root_dir, f'{expt}/{pos}/{pos}_raw'))\n",
    "\n",
    "            ### measure mean pixel value arrays and use to find under/over-exposed frames\n",
    "            # create empty dicts and sets to store values in \n",
    "            mean_arrays = {}\n",
    "            dodgy_frame_list = set([])\n",
    "            # iterate over channels\n",
    "            for channel in tqdm(images.channels):\n",
    "                print(f'Finding mean values of {channel.name.lower()} images', pos, expt)\n",
    "                # find mean pixel values for each channel\n",
    "                mean_arrays[channel.name] = np.mean(images[channel.name], axis = (1,2)).compute() \n",
    "                # iterate over frames\n",
    "                for frame, mean_value in enumerate(mean_arrays[channel.name]):\n",
    "                    if max_pixel < mean_value or mean_value < min_pixel:\n",
    "                        # if frame does not meet inclusion criteria then add to dodgy list\n",
    "                        dodgy_frame_list.add(frame)\n",
    "            dodgy_frame_list = list(dodgy_frame_list)\n",
    "            print('Number of under/over-exposed frames:', len(dodgy_frame_list), pos, expt)\n",
    "\n",
    "            ### create aligned image dir if does not exist \n",
    "            if not os.path.exists(os.path.join(root_dir, f'{expt}/{pos}/{pos}_aligned')):\n",
    "                os.mkdir(os.path.join(root_dir, f'{expt}/{pos}/{pos}_aligned'))\n",
    "\n",
    "            ### Automatically pick reference image to perform alignment on \n",
    "            # Pick channel based on index of brightest channel from maximum mean pixel array\n",
    "            reference_channel = images.channels[max([(channel.value, np.mean(mean_arrays[channel.name])) for channel in images.channels])[0]]\n",
    "            # Define reference images\n",
    "            reference_image = images[reference_channel.name]\n",
    "            reference_image = reference_image[:,int((reference_image.shape[2]-crop_area)/2):int(reference_image.shape[2]-(reference_image.shape[2]-crop_area)/2),int((reference_image.shape[1]-crop_area)/2):int(reference_image.shape[1]-(reference_image.shape[1]-crop_area)/2)].compute()\n",
    "            reference_image.shape\n",
    "            print('Automatically selected and cropped reference image:', reference_channel.name)\n",
    "\n",
    "            ### Register alignment\n",
    "            print('Registering alignment for', pos, expt)\n",
    "            # create operator using transformation type (translation)\n",
    "            sr = StackReg(StackReg.TRANSLATION) \n",
    "            # register each frame using reference image to the previous as transformation matrices/tensor\n",
    "            transform_tensor = sr.register_stack(reference_image, reference = 'previous').astype(np.uint8)\n",
    "            # save out transform tensor\n",
    "            np.save(os.path.join(root_dir, f'{expt}/{pos}/{reference_channel.name.lower()}_transform_tensor.npy'), transform_tensor)\n",
    "\n",
    "            ### Perform alignment\n",
    "            # create aligned image dir if does not exist \n",
    "            if not os.path.exists(os.path.join(root_dir, f'{expt}/{pos}/{pos}_aligned')):\n",
    "                os.mkdir(os.path.join(root_dir, f'{expt}/{pos}/{pos}_aligned'))\n",
    "            # iterate over channels\n",
    "            for channel in images.channels:\n",
    "                print('Aligning', channel.name.lower(), 'channel', channel.value+1, '/', len(images.channels))\n",
    "                #iterate over all images in channel\n",
    "                for i in tqdm(range(len(images[channel.name]))):\n",
    "                    # skip dodgy frames and don't save out into aligned folder\n",
    "                    if i in dodgy_frame_list:\n",
    "                        continue\n",
    "                    # load specific transform matrix for that frame\n",
    "                    transform_matrix = tf.EuclideanTransform(matrix = transform_tensor[i,...],rotation = None)\n",
    "                    # transform image\n",
    "                    transformed_image = (tf.warp(images[channel.name][i,...], transform_matrix)*255).astype(np.uint8)\n",
    "                    # set transformed image pathname by editing base dir\n",
    "                    fn = images.files(channel.name)[i].replace('_raw', '_aligned')\n",
    "                    # save trans image out\n",
    "                    io.imsave(fn, transformed_image, check_contrast=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a80f5ab",
   "metadata": {},
   "source": [
    "# Repeat alignment for larger datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3af662",
   "metadata": {},
   "source": [
    "# Compile stacks and save out?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2c79b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "start()\n",
    "aligned_images = DaskOctopusLiteLoader(os.path.join(root_dir, f'{expt}/{pos}/{pos}_aligned'))\n",
    "stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CellX",
   "language": "python",
   "name": "cellx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
