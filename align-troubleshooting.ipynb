{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "127b5eb3",
   "metadata": {},
   "source": [
    "# Align and remove blanks\n",
    "\n",
    "Adapted from Giulia Vallardi's ImageJ macro, this notebook removes any blank frames from timelapse experiments and aligns the images. \n",
    "\n",
    "\"Fiji macro to remove over- and under-exposed images, and align the image stacks\n",
    "\n",
    "The settings for the alignments are: \n",
    "registration by Translation > only modify XY coordinates\n",
    "Shrinkage constrain activated (this model allows a better registration based on all images, not using a reference image. It is more time consuming though)\n",
    "Transform matrices are saved during registration and then applied to the other channels during transformation.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7859805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import enum\n",
    "import numpy as np\n",
    "from pystackreg import StackReg\n",
    "from skimage import io\n",
    "from tqdm import tqdm\n",
    "from octopuslite import DaskOctopusLiteLoader\n",
    "from skimage import transform as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b349a8a0",
   "metadata": {},
   "source": [
    "# Find images, organise into raw folder and load using dask octo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbeda8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### define root directory and specific experiment and location (will later make iterable)\n",
    "root_dir = '/home/nathan/data/kraken/test/'\n",
    "expt = \"MK0003\"\n",
    "pos = \"Pos15\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b1a5cbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "### create new subdir of for raw files and move them all there\n",
    "if not os.path.exists(os.path.join(root_dir, f'{expt}/{pos}/{pos}_raw')):\n",
    "    os.mkdir(os.path.join(root_dir, f'{expt}/{pos}/{pos}_raw'))\n",
    "    files = sorted(glob.glob(os.path.join(root_dir, f'{expt}/{pos}/*.tif')))\n",
    "    for file in files:\n",
    "        os.rename(file, file.replace(f'{pos}', f'{pos}/{pos}_raw'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5a3d0870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cropping: None\n"
     ]
    }
   ],
   "source": [
    "### pre load files from raw file dir \n",
    "images = DaskOctopusLiteLoader(os.path.join(root_dir, f'{expt}/{pos}/{pos}_raw'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "683028b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table>\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 0.99 GiB </td>\n",
       "                        <td> 2.18 MiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (465, 1352, 1688) </td>\n",
       "                        <td> (1, 1352, 1688) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Count </th>\n",
       "                        <td> 1395 Tasks </td>\n",
       "                        <td> 465 Chunks </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                    <th> Type </th>\n",
       "                    <td> uint8 </td>\n",
       "                    <td> numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"205\" height=\"171\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"35\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"10\" y1=\"96\" x2=\"35\" y2=\"121\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"11\" y1=\"1\" x2=\"11\" y2=\"97\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"12\" y2=\"98\" />\n",
       "  <line x1=\"13\" y1=\"3\" x2=\"13\" y2=\"100\" />\n",
       "  <line x1=\"15\" y1=\"5\" x2=\"15\" y2=\"101\" />\n",
       "  <line x1=\"16\" y1=\"6\" x2=\"16\" y2=\"102\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"17\" y2=\"104\" />\n",
       "  <line x1=\"19\" y1=\"9\" x2=\"19\" y2=\"105\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"20\" y2=\"106\" />\n",
       "  <line x1=\"22\" y1=\"12\" x2=\"22\" y2=\"108\" />\n",
       "  <line x1=\"23\" y1=\"13\" x2=\"23\" y2=\"109\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"24\" y2=\"110\" />\n",
       "  <line x1=\"26\" y1=\"16\" x2=\"26\" y2=\"112\" />\n",
       "  <line x1=\"27\" y1=\"17\" x2=\"27\" y2=\"113\" />\n",
       "  <line x1=\"28\" y1=\"18\" x2=\"28\" y2=\"114\" />\n",
       "  <line x1=\"30\" y1=\"20\" x2=\"30\" y2=\"116\" />\n",
       "  <line x1=\"31\" y1=\"21\" x2=\"31\" y2=\"117\" />\n",
       "  <line x1=\"32\" y1=\"22\" x2=\"32\" y2=\"118\" />\n",
       "  <line x1=\"34\" y1=\"24\" x2=\"34\" y2=\"120\" />\n",
       "  <line x1=\"35\" y1=\"25\" x2=\"35\" y2=\"121\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 35.442073267618994,25.44207326761899 35.442073267618994,121.55581734344838 10.0,96.11374407582939\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"130\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"11\" y1=\"1\" x2=\"131\" y2=\"1\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"132\" y2=\"2\" />\n",
       "  <line x1=\"13\" y1=\"3\" x2=\"133\" y2=\"3\" />\n",
       "  <line x1=\"15\" y1=\"5\" x2=\"135\" y2=\"5\" />\n",
       "  <line x1=\"16\" y1=\"6\" x2=\"136\" y2=\"6\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"137\" y2=\"7\" />\n",
       "  <line x1=\"19\" y1=\"9\" x2=\"139\" y2=\"9\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"140\" y2=\"10\" />\n",
       "  <line x1=\"22\" y1=\"12\" x2=\"142\" y2=\"12\" />\n",
       "  <line x1=\"23\" y1=\"13\" x2=\"143\" y2=\"13\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"144\" y2=\"14\" />\n",
       "  <line x1=\"26\" y1=\"16\" x2=\"146\" y2=\"16\" />\n",
       "  <line x1=\"27\" y1=\"17\" x2=\"147\" y2=\"17\" />\n",
       "  <line x1=\"28\" y1=\"18\" x2=\"148\" y2=\"18\" />\n",
       "  <line x1=\"30\" y1=\"20\" x2=\"150\" y2=\"20\" />\n",
       "  <line x1=\"31\" y1=\"21\" x2=\"151\" y2=\"21\" />\n",
       "  <line x1=\"32\" y1=\"22\" x2=\"152\" y2=\"22\" />\n",
       "  <line x1=\"34\" y1=\"24\" x2=\"154\" y2=\"24\" />\n",
       "  <line x1=\"35\" y1=\"25\" x2=\"155\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"35\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"130\" y1=\"0\" x2=\"155\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 130.0,0.0 155.44207326761898,25.44207326761899 35.442073267618994,25.44207326761899\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"35\" y1=\"25\" x2=\"155\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"35\" y1=\"121\" x2=\"155\" y2=\"121\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"35\" y1=\"25\" x2=\"35\" y2=\"121\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"155\" y1=\"25\" x2=\"155\" y2=\"121\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"35.442073267618994,25.44207326761899 155.44207326761898,25.44207326761899 155.44207326761898,121.55581734344838 35.442073267618994,121.55581734344838\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"95.442073\" y=\"141.555817\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >1688</text>\n",
       "  <text x=\"175.442073\" y=\"73.498945\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,175.442073,73.498945)\">1352</text>\n",
       "  <text x=\"12.721037\" y=\"128.834781\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,12.721037,128.834781)\">465</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<stack, shape=(465, 1352, 1688), dtype=uint8, chunksize=(1, 1352, 1688), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images['brightfield']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4314a4",
   "metadata": {},
   "source": [
    "# Find blank or overexposed images and display average channel brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c37594e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IRFP'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "channel.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ffeb49cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table>\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 2.18 MiB </td>\n",
       "                        <td> 2.18 MiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (1352, 1688) </td>\n",
       "                        <td> (1352, 1688) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Count </th>\n",
       "                        <td> 1396 Tasks </td>\n",
       "                        <td> 1 Chunks </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                    <th> Type </th>\n",
       "                    <td> uint8 </td>\n",
       "                    <td> numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"170\" height=\"146\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"120\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"96\" x2=\"120\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"120\" y1=\"0\" x2=\"120\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 120.0,0.0 120.0,96.11374407582939 0.0,96.11374407582939\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"60.000000\" y=\"116.113744\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >1688</text>\n",
       "  <text x=\"140.000000\" y=\"48.056872\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,140.000000,48.056872)\">1352</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<getitem, shape=(1352, 1688), dtype=uint8, chunksize=(1352, 1688), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[channel.name][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "691942a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table>\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 0.99 GiB </td>\n",
       "                        <td> 2.18 MiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (465, 1352, 1688) </td>\n",
       "                        <td> (1, 1352, 1688) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Count </th>\n",
       "                        <td> 1395 Tasks </td>\n",
       "                        <td> 465 Chunks </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                    <th> Type </th>\n",
       "                    <td> uint8 </td>\n",
       "                    <td> numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"205\" height=\"171\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"35\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"10\" y1=\"96\" x2=\"35\" y2=\"121\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"11\" y1=\"1\" x2=\"11\" y2=\"97\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"12\" y2=\"98\" />\n",
       "  <line x1=\"13\" y1=\"3\" x2=\"13\" y2=\"100\" />\n",
       "  <line x1=\"15\" y1=\"5\" x2=\"15\" y2=\"101\" />\n",
       "  <line x1=\"16\" y1=\"6\" x2=\"16\" y2=\"102\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"17\" y2=\"104\" />\n",
       "  <line x1=\"19\" y1=\"9\" x2=\"19\" y2=\"105\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"20\" y2=\"106\" />\n",
       "  <line x1=\"22\" y1=\"12\" x2=\"22\" y2=\"108\" />\n",
       "  <line x1=\"23\" y1=\"13\" x2=\"23\" y2=\"109\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"24\" y2=\"110\" />\n",
       "  <line x1=\"26\" y1=\"16\" x2=\"26\" y2=\"112\" />\n",
       "  <line x1=\"27\" y1=\"17\" x2=\"27\" y2=\"113\" />\n",
       "  <line x1=\"28\" y1=\"18\" x2=\"28\" y2=\"114\" />\n",
       "  <line x1=\"30\" y1=\"20\" x2=\"30\" y2=\"116\" />\n",
       "  <line x1=\"31\" y1=\"21\" x2=\"31\" y2=\"117\" />\n",
       "  <line x1=\"32\" y1=\"22\" x2=\"32\" y2=\"118\" />\n",
       "  <line x1=\"34\" y1=\"24\" x2=\"34\" y2=\"120\" />\n",
       "  <line x1=\"35\" y1=\"25\" x2=\"35\" y2=\"121\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 35.442073267618994,25.44207326761899 35.442073267618994,121.55581734344838 10.0,96.11374407582939\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"130\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"11\" y1=\"1\" x2=\"131\" y2=\"1\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"132\" y2=\"2\" />\n",
       "  <line x1=\"13\" y1=\"3\" x2=\"133\" y2=\"3\" />\n",
       "  <line x1=\"15\" y1=\"5\" x2=\"135\" y2=\"5\" />\n",
       "  <line x1=\"16\" y1=\"6\" x2=\"136\" y2=\"6\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"137\" y2=\"7\" />\n",
       "  <line x1=\"19\" y1=\"9\" x2=\"139\" y2=\"9\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"140\" y2=\"10\" />\n",
       "  <line x1=\"22\" y1=\"12\" x2=\"142\" y2=\"12\" />\n",
       "  <line x1=\"23\" y1=\"13\" x2=\"143\" y2=\"13\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"144\" y2=\"14\" />\n",
       "  <line x1=\"26\" y1=\"16\" x2=\"146\" y2=\"16\" />\n",
       "  <line x1=\"27\" y1=\"17\" x2=\"147\" y2=\"17\" />\n",
       "  <line x1=\"28\" y1=\"18\" x2=\"148\" y2=\"18\" />\n",
       "  <line x1=\"30\" y1=\"20\" x2=\"150\" y2=\"20\" />\n",
       "  <line x1=\"31\" y1=\"21\" x2=\"151\" y2=\"21\" />\n",
       "  <line x1=\"32\" y1=\"22\" x2=\"152\" y2=\"22\" />\n",
       "  <line x1=\"34\" y1=\"24\" x2=\"154\" y2=\"24\" />\n",
       "  <line x1=\"35\" y1=\"25\" x2=\"155\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"35\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"130\" y1=\"0\" x2=\"155\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 130.0,0.0 155.44207326761898,25.44207326761899 35.442073267618994,25.44207326761899\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"35\" y1=\"25\" x2=\"155\" y2=\"25\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"35\" y1=\"121\" x2=\"155\" y2=\"121\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"35\" y1=\"25\" x2=\"35\" y2=\"121\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"155\" y1=\"25\" x2=\"155\" y2=\"121\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"35.442073267618994,25.44207326761899 155.44207326761898,25.44207326761899 155.44207326761898,121.55581734344838 35.442073267618994,121.55581734344838\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"95.442073\" y=\"141.555817\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >1688</text>\n",
       "  <text x=\"175.442073\" y=\"73.498945\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,175.442073,73.498945)\">1352</text>\n",
       "  <text x=\"12.721037\" y=\"128.834781\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,12.721037,128.834781)\">465</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<stack, shape=(465, 1352, 1688), dtype=uint8, chunksize=(1, 1352, 1688), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images[channel.name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00424144",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71.97978245323762"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(images[channel.name][0].compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c48412ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding mean values of image channels: 100%|██████████| 4/4 [00:34<00:00,  8.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of under/over-exposed frames: 7\n",
      "CPU times: user 11.7 s, sys: 3.4 s, total: 15.1 s\n",
      "Wall time: 34.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# pixel range criteria\n",
    "max_pixel, min_pixel = 200, 2\n",
    "\n",
    "mean_arrays = {}\n",
    "dodgy_frame_list = set([])\n",
    "for channel in tqdm(images.channels, desc = f'Finding mean values of image channels'):\n",
    "    mean_arrays[channel.name] = np.mean(images[channel.name], axis = (1,2)).compute() \n",
    "    for frame, mean_value in enumerate(mean_arrays[channel.name]):\n",
    "        if max_pixel < mean_value or mean_value < min_pixel:\n",
    "            dodgy_frame_list.add(frame)\n",
    "dodgy_frame_list = list(dodgy_frame_list)\n",
    "\n",
    "print('Number of under/over-exposed frames:', len(dodgy_frame_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7a034fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[288, 324, 299, 109, 46, 370, 55]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dodgy_frame_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d691578",
   "metadata": {},
   "source": [
    "# Filtering to remove blank or overexposed frames from image array and mean value arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9e00d0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_images= {}\n",
    "for channel in images.channels:\n",
    "    filtered_images[channel.name] = np.delete(images[channel], dodgy_frame_list, axis = 0)\n",
    "    mean_arrays[channel.name] = np.delete(mean_arrays[channel.name], dodgy_frame_list, axis = 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "13077a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BRIGHTFIELD': dask.array<concatenate, shape=(459, 1352, 1688), dtype=uint8, chunksize=(1, 1352, 1688), chunktype=numpy.ndarray>,\n",
       " 'GFP': dask.array<concatenate, shape=(458, 1352, 1688), dtype=uint8, chunksize=(1, 1352, 1688), chunktype=numpy.ndarray>,\n",
       " 'RFP': dask.array<concatenate, shape=(458, 1352, 1688), dtype=uint8, chunksize=(1, 1352, 1688), chunktype=numpy.ndarray>,\n",
       " 'IRFP': dask.array<concatenate, shape=(458, 1352, 1688), dtype=uint8, chunksize=(1, 1352, 1688), chunktype=numpy.ndarray>}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06e525f",
   "metadata": {},
   "source": [
    "# Select reference image to base alignment around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9407bfcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average channel brightness for selection of reference image:\n",
      "0: BRIGHTFIELD: 37.62035125299296\n",
      "1: GFP: 78.58584791196907\n",
      "2: RFP: 4.305421344208685\n",
      "3: IRFP: 72.24970833064663\n"
     ]
    }
   ],
   "source": [
    "print('Average channel brightness for selection of reference image:')\n",
    "for channel in images.channels:\n",
    "    print(f'{channel.value}: {channel.name}:', np.mean(mean_arrays[channel.name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6228689a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference channel: IRFP\n"
     ]
    }
   ],
   "source": [
    "# manually select reference channel by adding index\n",
    "# reference_channel = filtered_images['IRFP']\n",
    "# automatically select reference channel from max average pixel value (ie. brightest channel)\n",
    "reference_channel = images.channels[max([(channel.value, np.mean(mean_arrays[channel.name])) for channel in images.channels])[0]]\n",
    "reference_image = filtered_images[reference_channel.name]\n",
    "print('Reference channel:', reference_channel.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095cd623",
   "metadata": {},
   "source": [
    "## Set cropped area of reference image to base alignment around (whole image struggles to compute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "541f1915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(458, 500, 500)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crop_area = 500\n",
    "reference_image = reference_image[:,int((reference_image.shape[2]-crop_area)/2):int(reference_image.shape[2]-(reference_image.shape[2]-crop_area)/2),int((reference_image.shape[1]-crop_area)/2):int(reference_image.shape[1]-(reference_image.shape[1]-crop_area)/2)].compute()\n",
    "reference_image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534c5b5f",
   "metadata": {},
   "source": [
    "# Register alignment and save out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "3de9f89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53 s, sys: 1.14 s, total: 54.1 s\n",
      "Wall time: 54.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create operator using transformation type (translation)\n",
    "sr = StackReg(StackReg.TRANSLATION) \n",
    "\n",
    "# register each frame to the previous as transformation matrices/tensor\n",
    "transform_tensor = sr.register_stack(reference_image, reference = 'first')\n",
    "\n",
    "# save out transform tensor\n",
    "np.save(os.path.join(root_dir, f'{expt}/{pos}/{reference_channel.name.lower()}_transform_tensor.npy'), transform_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ae1b12f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(458, 3, 3)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3f8b67",
   "metadata": {},
   "source": [
    "# Apply transformation matrix to all channels and save out images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "183a2711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning brightfield channel 1 / 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aligning brightfield channel 1/4: 100%|██████████| 458/458 [01:22<00:00,  5.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning gfp channel 2 / 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aligning gfp channel 2/4: 100%|██████████| 458/458 [00:56<00:00,  8.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning rfp channel 3 / 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aligning rfp channel 3/4: 100%|██████████| 458/458 [00:58<00:00,  7.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning irfp channel 4 / 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aligning irfp channel 4/4: 100%|██████████| 458/458 [01:11<00:00,  6.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 35s, sys: 30.7 s, total: 3min 6s\n",
      "Wall time: 4min 28s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### iterating over channels\n",
    "# create aligned image dir if does not exist \n",
    "if not os.path.exists(os.path.join(root_dir, f'{expt}/{pos}/{pos}_aligned')):\n",
    "    os.mkdir(os.path.join(root_dir, f'{expt}/{pos}/{pos}_aligned'))\n",
    "# iterate over channels\n",
    "for channel in images.channels:\n",
    "    #iterate over all images in channel\n",
    "    for i in tqdm(range(len(transform_tensor)), desc = f'Aligning {channel.name.lower()} channel {channel.value+1}/{len(images.channels)}'):#filtered_images[channel.name]))):\n",
    "        # load specific transform matrix for that frame\n",
    "        transform_matrix = tf.EuclideanTransform(matrix = transform_tensor[i,...],rotation = None)\n",
    "        # transform image\n",
    "        transformed_image = (tf.warp(filtered_images[channel.name][i,...].compute(), transform_matrix, preserve_range=True)).astype(np.uint8)\n",
    "        # set transformed image pathname by editing base dir\n",
    "        fn = images.files(channel.name)[i].replace('_raw', '_aligned')\n",
    "        # save trans image out\n",
    "        io.imsave(fn, transformed_image, check_contrast=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd310bc",
   "metadata": {},
   "source": [
    "# check images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "af516a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "71ad31a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cropping: (1200, 1600)\n",
      "Using cropping: None\n"
     ]
    }
   ],
   "source": [
    "aligned_images = DaskOctopusLiteLoader(os.path.join(root_dir, f'{expt}/{pos}/{pos}_aligned'), crop = (1200,1600))\n",
    "old_aligned_images = DaskOctopusLiteLoader(os.path.join(root_dir, f'{expt}/{pos}/{pos}_raw'))\n",
    "viewer = napari.Viewer()\n",
    "for channel in aligned_images.channels:\n",
    "#    if channel.name == 'IRFP':\n",
    "        viewer.add_image(aligned_images[channel.name], name = channel.name, blending = 'additive', contrast_limits = [0,255])\n",
    "        #, colormap = napari.utils.colormaps.SIMPLE_COLORMAPS.popitem()) # lazy hack to randomly generate different colormaps\n",
    "                         #, colormap = napari.utils.colormaps.SIMPLE_COLORMAPS.popitem()) # lazy hack to randomly generate different colormaps\n",
    "        #viewer.add_image(old_aligned_images[channel.name], name = channel.name+'raw', blending = 'additive', contrast_limits = [0,255])\n",
    "                         #, colormap = napari.utils.colormaps.SIMPLE_COLORMAPS.popitem()) # lazy hack to randomly generate different colormaps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753378b7",
   "metadata": {},
   "source": [
    "# Troubleshooting jumpy transforms\n",
    "\n",
    "-- still have jumpy transforms using first frame ref and filtered"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcbac05",
   "metadata": {},
   "source": [
    "# Check transform tensor for jumpy transtitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8a2e4bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame 101 \n",
      " [[  1.           0.         -13.65152047]\n",
      " [  0.           1.         -22.70402882]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 102 \n",
      " [[  1.           0.         -14.45267518]\n",
      " [  0.           1.         -23.35706889]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 103 \n",
      " [[  1.           0.         -14.59337138]\n",
      " [  0.           1.         -21.27063231]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 104 \n",
      " [[  1.           0.         -14.79626622]\n",
      " [  0.           1.         -20.1216003 ]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 105 \n",
      " [[  1.           0.         -14.35232363]\n",
      " [  0.           1.         -25.79305233]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 106 \n",
      " [[  1.           0.         -14.42558353]\n",
      " [  0.           1.         -25.12203227]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 107 \n",
      " [[  1.           0.         -14.57673501]\n",
      " [  0.           1.         -17.46695681]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 108 \n",
      " [[  1.           0.         -14.38793308]\n",
      " [  0.           1.         -17.30937757]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 109 \n",
      " [[  1.           0.         -14.51399718]\n",
      " [  0.           1.         -16.91207068]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 110 \n",
      " [[  1.           0.         -30.42406816]\n",
      " [  0.           1.         -14.36185967]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 111 \n",
      " [[  1.           0.         -29.75894382]\n",
      " [  0.           1.         -12.78396851]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 112 \n",
      " [[  1.           0.         -29.62077673]\n",
      " [  0.           1.         -12.70638228]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 113 \n",
      " [[  1.           0.         -30.02717307]\n",
      " [  0.           1.         -16.21125126]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 114 \n",
      " [[  1.           0.         -14.46866419]\n",
      " [  0.           1.         -16.57865269]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 115 \n",
      " [[  1.           0.         -22.48335621]\n",
      " [  0.           1.         -16.7764766 ]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 116 \n",
      " [[  1.           0.         -30.4076395 ]\n",
      " [  0.           1.         -10.06463797]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 117 \n",
      " [[  1.           0.         -30.46296585]\n",
      " [  0.           1.         -13.54088   ]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 118 \n",
      " [[  1.           0.         -30.31663016]\n",
      " [  0.           1.         -10.29524307]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 119 \n",
      " [[  1.           0.         -30.26504916]\n",
      " [  0.           1.         -10.23031375]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 120 \n",
      " [[  1.           0.         -29.79492568]\n",
      " [  0.           1.         -13.18353524]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 121 \n",
      " [[  1.           0.         -13.46866412]\n",
      " [  0.           1.         -17.99248861]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 122 \n",
      " [[  1.           0.         -14.45950734]\n",
      " [  0.           1.         -16.84504404]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 123 \n",
      " [[  1.           0.         -14.61737378]\n",
      " [  0.           1.         -16.37186552]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 124 \n",
      " [[  1.           0.         -14.4412738 ]\n",
      " [  0.           1.         -18.02233579]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 125 \n",
      " [[  1.           0.         -30.08273448]\n",
      " [  0.           1.         -16.2297817 ]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 126 \n",
      " [[  1.           0.         -30.22740292]\n",
      " [  0.           1.         -13.70470003]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 127 \n",
      " [[  1.           0.         -30.45320147]\n",
      " [  0.           1.         -15.95179609]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 128 \n",
      " [[  1.           0.         -30.27727645]\n",
      " [  0.           1.         -16.39202592]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 129 \n",
      " [[  1.           0.         -30.02758856]\n",
      " [  0.           1.         -16.45652361]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 130 \n",
      " [[  1.           0.         -30.89995882]\n",
      " [  0.           1.         -19.25869322]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 131 \n",
      " [[  1.           0.         -30.04895585]\n",
      " [  0.           1.         -20.41882582]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 132 \n",
      " [[  1.           0.         -30.6859849 ]\n",
      " [  0.           1.         -18.51763994]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 133 \n",
      " [[  1.           0.         -31.0193185 ]\n",
      " [  0.           1.         -17.79947727]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 134 \n",
      " [[  1.           0.         -31.03249256]\n",
      " [  0.           1.         -18.92473   ]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 135 \n",
      " [[  1.           0.         -30.92837682]\n",
      " [  0.           1.         -16.26649744]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 136 \n",
      " [[  1.           0.         -30.81232007]\n",
      " [  0.           1.         -17.02722475]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 137 \n",
      " [[  1.           0.         -30.82278402]\n",
      " [  0.           1.         -19.61165002]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 138 \n",
      " [[  1.           0.         -30.51919345]\n",
      " [  0.           1.         -21.67762284]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 139 \n",
      " [[  1.           0.         -30.69765072]\n",
      " [  0.           1.         -19.15920231]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 140 \n",
      " [[  1.           0.         -30.43385584]\n",
      " [  0.           1.         -16.85248422]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 141 \n",
      " [[  1.           0.         -30.65337358]\n",
      " [  0.           1.         -16.64528269]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 142 \n",
      " [[  1.           0.         -30.54210126]\n",
      " [  0.           1.         -15.66789068]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 143 \n",
      " [[  1.           0.         -30.82764349]\n",
      " [  0.           1.         -15.41632443]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 144 \n",
      " [[  1.           0.         -46.08838914]\n",
      " [  0.           1.         -13.26091961]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 145 \n",
      " [[  1.           0.         -30.54222053]\n",
      " [  0.           1.         -14.77173063]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 146 \n",
      " [[  1.           0.         -30.43854268]\n",
      " [  0.           1.         -15.50687023]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 147 \n",
      " [[  1.           0.         -22.52737302]\n",
      " [  0.           1.         -16.78690784]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 148 \n",
      " [[  1.           0.         -30.63583668]\n",
      " [  0.           1.         -15.39926924]\n",
      " [  0.           0.           1.        ]]\n",
      "frame 149 \n",
      " [[  1.           0.         -30.59549346]\n",
      " [  0.           1.         -11.5851494 ]\n",
      " [  0.           0.           1.        ]]\n"
     ]
    }
   ],
   "source": [
    "for j, i in enumerate(transform_tensor):\n",
    "    if 150 > j > 100:\n",
    "        print(\"frame\", j,'\\n', i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83af419f",
   "metadata": {},
   "source": [
    "# problematic shift at frame 107"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "821eda60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[76, 76, 74, ..., 70, 74, 74],\n",
       "       [79, 71, 71, ..., 72, 73, 77],\n",
       "       [72, 74, 75, ..., 76, 74, 73],\n",
       "       ...,\n",
       "       [75, 74, 76, ..., 69, 71, 69],\n",
       "       [75, 75, 72, ..., 70, 70, 70],\n",
       "       [71, 75, 72, ..., 72, 72, 73]], dtype=uint8)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_image[106]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e305fe5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[76, 77, 75, ..., 73, 72, 73],\n",
       "       [74, 74, 73, ..., 78, 74, 78],\n",
       "       [73, 75, 76, ..., 76, 79, 72],\n",
       "       ...,\n",
       "       [74, 77, 72, ..., 71, 74, 72],\n",
       "       [73, 70, 73, ..., 68, 69, 76],\n",
       "       [76, 73, 73, ..., 72, 72, 71]], dtype=uint8)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_image[107]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "28ce64d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[70, 74, 76, ..., 77, 74, 74],\n",
       "       [75, 73, 73, ..., 73, 73, 76],\n",
       "       [76, 75, 71, ..., 74, 77, 73],\n",
       "       ...,\n",
       "       [76, 79, 75, ..., 72, 73, 74],\n",
       "       [78, 75, 74, ..., 71, 71, 70],\n",
       "       [71, 72, 73, ..., 74, 71, 70]], dtype=uint8)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_image[108]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "31faacff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n",
      "60\n",
      "255\n",
      "60\n",
      "255\n",
      "60\n",
      "255\n",
      "60\n",
      "255\n",
      "59\n",
      "255\n",
      "59\n",
      "255\n",
      "60\n",
      "255\n",
      "60\n",
      "255\n",
      "61\n",
      "255\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "### checking raw images\n",
    "for i in range(100, 110):\n",
    "    print(np.amax(reference_image[i]))\n",
    "    print(np.amin(reference_image[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21535c5d",
   "metadata": {},
   "source": [
    "# Is the problematic shift a result of the stack reg, ie can i reproduce it in an individual frame by frame registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "04c85900",
   "metadata": {},
   "outputs": [],
   "source": [
    "### problematic frame\n",
    "i = 107"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "45f1ab0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.        , -0.18532186],\n",
       "       [ 0.        ,  1.        ,  0.05314004],\n",
       "       [ 0.        ,  0.        ,  1.        ]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StackReg(StackReg.TRANSLATION).register(reference_image[i-1], reference_image[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db898ea5",
   "metadata": {},
   "source": [
    "#### is the stack registration a cumulative measure over 1183 frames?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5d1ff15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 457/1191 [01:05<01:45,  6.97it/s]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 458 is out of bounds for axis 0 with size 458",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-85-cb143fbf936c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstack_reg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1192\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mstack_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStackReg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mStackReg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRANSLATION\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference_image\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreference_image\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 458 is out of bounds for axis 0 with size 458"
     ]
    }
   ],
   "source": [
    "stack_reg = []\n",
    "for i in tqdm(range(1,1192)):\n",
    "    stack_reg.append(StackReg(StackReg.TRANSLATION).register(reference_image[i-1], reference_image[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef295815",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(stack_reg, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d404306",
   "metadata": {},
   "source": [
    "# Try different transformation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4fe2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation matrix should take on the form\n",
    "\n",
    "#             [1 , 0 , x\n",
    "#              0 , 1 , y\n",
    "#              0 , 0 , 1]\n",
    "\n",
    "# where x and y are the translate magnitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57fb49c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 107"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389b6798",
   "metadata": {},
   "outputs": [],
   "source": [
    "### float translation\n",
    "StackReg(StackReg.TRANSLATION).register(images['gfp'][i-1], images['gfp'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8faf5856",
   "metadata": {},
   "outputs": [],
   "source": [
    "### int translation\n",
    "StackReg(StackReg.TRANSLATION).register(images['gfp'][i-1], images['gfp'][i]).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290f7c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### float rigid body\n",
    "StackReg(StackReg.RIGID_BODY).register(images['gfp'][i-1], images['gfp'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710e0560",
   "metadata": {},
   "outputs": [],
   "source": [
    "### np.rint rigid body\n",
    "np.rint(StackReg(StackReg.RIGID_BODY).register(images['gfp'][i-1], images['gfp'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "6fe75192",
   "metadata": {},
   "outputs": [],
   "source": [
    "### integer-ising the matrix zeroes some important numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bc82ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "### int rigidbody\n",
    "StackReg(StackReg.RIGID_BODY).register(images['gfp'][i-1], images['gfp'][i]).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d069cb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "### float affine\n",
    "StackReg(StackReg.AFFINE).register(images['gfp'][i-1], images['gfp'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa49c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "### np.rint affine\n",
    "np.rint(StackReg(StackReg.AFFINE).register(images['gfp'][i-1], images['gfp'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cdc0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### int affine\n",
    "StackReg(StackReg.AFFINE).register(images['gfp'][i-1], images['gfp'][i]).astype(np.int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f18898",
   "metadata": {},
   "source": [
    "# seems like all the alignment methods produce similar shifted outputs... is it the images?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eda1afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for channel in images.channels:\n",
    "    print(channel.name, StackReg(StackReg.TRANSLATION).register(images[channel.name][i-1], images[channel.name][i]).astype(np.int8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58bb36f",
   "metadata": {},
   "source": [
    "# is it the gfp channel? checking each channel for max transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "824eaf46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting channel: BRIGHTFIELD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1199/1199 [25:51<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BRIGHTFIELD 126\n",
      "Starting channel: GFP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1199/1199 [26:16<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GFP 108\n",
      "Starting channel: RFP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1199/1199 [27:56<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFP 47\n",
      "Starting channel: IRFP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1199/1199 [27:06<00:00,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRFP 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trans_tensors = {}\n",
    "for channel in images.channels:\n",
    "    print('Starting channel:', channel.name)\n",
    "    trans_tensor = []\n",
    "#     for i in tqdm(range(1, len(images['gfp']))):\n",
    "#         ### create transformation matrix for i'th and i+1'th frame\n",
    "#         trans_matrix = StackReg(StackReg.TRANSLATION).register(images[channel.name][i-1], images[channel.name][i]).astype(np.int8)\n",
    "#         trans_tensor.append(trans_matrix)\n",
    "\n",
    "    trans_tensor = np.stack(trans_tensor)\n",
    "    trans_tensors[channel.name] = trans_tensor\n",
    "    print(channel.name, np.amax(trans_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3decf143",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('all_ch_trans_tensors.json', 'wb') as fp:\n",
    "    pickle.dump(trans_tensors, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c590b2",
   "metadata": {},
   "source": [
    "# Checking the alignment tensors of each channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95971133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BRIGHTFIELD 126\n",
      "GFP 108\n",
      "RFP 47\n",
      "IRFP 24\n"
     ]
    }
   ],
   "source": [
    "for channel in trans_tensors:\n",
    "    print(channel, np.amax(trans_tensors[channel]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d928e8c7",
   "metadata": {},
   "source": [
    "# irfp channel has lowest max shift in so test run alignment on that "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e1d3d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_tensor = trans_tensors['IRFP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c46fbee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.amax(transform_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f300630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200, 1199)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images['gfp']), len(transform_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "33ab7c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning brightfield channel 1 / 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [01:28<00:00, 13.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning gfp channel 2 / 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [01:28<00:00, 13.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning rfp channel 3 / 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [01:26<00:00, 13.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning irfp channel 4 / 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [01:31<00:00, 13.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 11s, sys: 43.9 s, total: 5min 55s\n",
      "Wall time: 5min 54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for channel in images.channels:\n",
    "    print('Aligning', channel.name.lower(), 'channel', channel.value+1, '/', len(images.channels))\n",
    "    #iterate over all images in channel\n",
    "    for i in tqdm(range(len(images[channel.name]))):\n",
    "        # skip dodgy frames and don't save out into aligned folder\n",
    "        if i in dodgy_frame_list or i == 1199:\n",
    "            continue\n",
    "        # load specific transform matrix for that frame\n",
    "        transform_matrix = tf.EuclideanTransform(matrix = transform_tensor[i,...],rotation = None)\n",
    "        # transform image\n",
    "        transformed_image = (tf.warp(images[channel.name][i,...], transform_matrix)*255).astype(np.uint8)\n",
    "        # set transformed image pathname by editing base dir\n",
    "        fn = images.files(channel.name)[i].replace('_raw', '_aligned')\n",
    "        # save trans image out\n",
    "        io.imsave(fn, transformed_image, check_contrast=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3aac445",
   "metadata": {},
   "source": [
    "# Batch execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63fa67c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/home/nathan/data/kraken/commitment/test/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc821c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "alignment(expt_list = ['MK0000', 'MK0001', 'MK0002', 'MK0003'], \n",
    "          max_pixel = 200, \n",
    "          min_pixel = 2, \n",
    "          crop_area = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952bbbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()\n",
    "for channel in aligned_images.channels:\n",
    "    viewer.add_image(aligned_images[channel.name], name = channel.name, blending = 'additive', contrast_limits = [0,255], colormap = napari.utils.colormaps.SIMPLE_COLORMAPS.popitem()) # lazy hack to randomly generate different colormaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eea9708c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alignment(expt_list, max_pixel, min_pixel, crop_area):\n",
    "\n",
    "    ### Iterate over all experiments defined in expt_list\n",
    "    for expt in expt_list:\n",
    "        # Find all positions in that experiment\n",
    "        pos_list = [pos for pos in os.listdir(os.path.join(root_dir, expt)) if 'Pos' in pos]\n",
    "        ### Iterate over all positions in that experiment\n",
    "        for pos in pos_list:\n",
    "            ### create new subdir of for raw files and move them all there\n",
    "            if not os.path.exists(os.path.join(root_dir, f'{expt}/{pos}/{pos}_raw')):\n",
    "                os.mkdir(os.path.join(root_dir, f'{expt}/{pos}/{pos}_raw'))\n",
    "                files = sorted(glob.glob(os.path.join(root_dir, f'{expt}/{pos}/*.tif')))\n",
    "                for file in files:\n",
    "                    os.rename(file, file.replace(f'{pos}', f'{pos}/{pos}_raw'))\n",
    "\n",
    "            ### pre load files from raw file dir \n",
    "            images = DaskOctopusLiteLoader(os.path.join(root_dir, f'{expt}/{pos}/{pos}_raw'))\n",
    "\n",
    "            ### measure mean pixel value arrays and use to find under/over-exposed frames\n",
    "            # create empty dicts and sets to store values in \n",
    "            mean_arrays = {}\n",
    "            dodgy_frame_list = set([])\n",
    "            # iterate over channels\n",
    "            for channel in tqdm(images.channels):\n",
    "                print(f'Finding mean values of {channel.name.lower()} images', pos, expt)\n",
    "                # find mean pixel values for each channel\n",
    "                mean_arrays[channel.name] = np.mean(images[channel.name], axis = (1,2)).compute() \n",
    "                # iterate over frames\n",
    "                for frame, mean_value in enumerate(mean_arrays[channel.name]):\n",
    "                    if max_pixel < mean_value or mean_value < min_pixel:\n",
    "                        # if frame does not meet inclusion criteria then add to dodgy list\n",
    "                        dodgy_frame_list.add(frame)\n",
    "            dodgy_frame_list = list(dodgy_frame_list)\n",
    "            print('Number of under/over-exposed frames:', len(dodgy_frame_list), pos, expt)\n",
    "\n",
    "            ### create aligned image dir if does not exist \n",
    "            if not os.path.exists(os.path.join(root_dir, f'{expt}/{pos}/{pos}_aligned')):\n",
    "                os.mkdir(os.path.join(root_dir, f'{expt}/{pos}/{pos}_aligned'))\n",
    "\n",
    "            ### Automatically pick reference image to perform alignment on \n",
    "            # Pick channel based on index of brightest channel from maximum mean pixel array\n",
    "            reference_channel = images.channels[max([(channel.value, np.mean(mean_arrays[channel.name])) for channel in images.channels])[0]]\n",
    "            # Define reference images\n",
    "            reference_image = images[reference_channel.name]\n",
    "            reference_image = reference_image[:,int((reference_image.shape[2]-crop_area)/2):int(reference_image.shape[2]-(reference_image.shape[2]-crop_area)/2),int((reference_image.shape[1]-crop_area)/2):int(reference_image.shape[1]-(reference_image.shape[1]-crop_area)/2)].compute()\n",
    "            reference_image.shape\n",
    "            print('Automatically selected and cropped reference image:', reference_channel.name)\n",
    "\n",
    "            ### Register alignment\n",
    "            print('Registering alignment for', pos, expt)\n",
    "            # create operator using transformation type (translation)\n",
    "            sr = StackReg(StackReg.TRANSLATION) \n",
    "            # register each frame using reference image to the previous as transformation matrices/tensor\n",
    "            transform_tensor = sr.register_stack(reference_image, reference = 'previous').astype(np.uint8)\n",
    "            # save out transform tensor\n",
    "            np.save(os.path.join(root_dir, f'{expt}/{pos}/{reference_channel.name.lower()}_transform_tensor.npy'), transform_tensor)\n",
    "\n",
    "            ### Perform alignment\n",
    "            # create aligned image dir if does not exist \n",
    "            if not os.path.exists(os.path.join(root_dir, f'{expt}/{pos}/{pos}_aligned')):\n",
    "                os.mkdir(os.path.join(root_dir, f'{expt}/{pos}/{pos}_aligned'))\n",
    "            # iterate over channels\n",
    "            for channel in images.channels:\n",
    "                print('Aligning', channel.name.lower(), 'channel', channel.value+1, '/', len(images.channels))\n",
    "                #iterate over all images in channel\n",
    "                for i in tqdm(range(len(images[channel.name]))):\n",
    "                    # skip dodgy frames and don't save out into aligned folder\n",
    "                    if i in dodgy_frame_list:\n",
    "                        continue\n",
    "                    # load specific transform matrix for that frame\n",
    "                    transform_matrix = tf.EuclideanTransform(matrix = transform_tensor[i,...],rotation = None)\n",
    "                    # transform image\n",
    "                    transformed_image = (tf.warp(images[channel.name][i,...], transform_matrix)*255).astype(np.uint8)\n",
    "                    # set transformed image pathname by editing base dir\n",
    "                    fn = images.files(channel.name)[i].replace('_raw', '_aligned')\n",
    "                    # save trans image out\n",
    "                    io.imsave(fn, transformed_image, check_contrast=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a80f5ab",
   "metadata": {},
   "source": [
    "# Repeat alignment for larger datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3af662",
   "metadata": {},
   "source": [
    "# Compile stacks and save out?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2c79b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "start()\n",
    "aligned_images = DaskOctopusLiteLoader(os.path.join(root_dir, f'{expt}/{pos}/{pos}_aligned'))\n",
    "stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CellX",
   "language": "python",
   "name": "cellx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
