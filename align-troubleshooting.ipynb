{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "127b5eb3",
   "metadata": {},
   "source": [
    "# Align and remove blanks\n",
    "\n",
    "Adapted from Giulia Vallardi's ImageJ macro, this notebook removes any blank frames from timelapse experiments and aligns the images. \n",
    "\n",
    "\"Fiji macro to remove over- and under-exposed images, and align the image stacks\n",
    "\n",
    "The settings for the alignments are: \n",
    "registration by Translation > only modify XY coordinates\n",
    "Shrinkage constrain activated (this model allows a better registration based on all images, not using a reference image. It is more time consuming though)\n",
    "Transform matrices are saved during registration and then applied to the other channels during transformation.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa19f60e",
   "metadata": {},
   "source": [
    "# to - do: decide how to import dask octopus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20b37ccd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'octopuslite'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e4d1dcca6c3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0moctopuslite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'octopuslite'"
     ]
    }
   ],
   "source": [
    "import octopuslite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7859805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import enum\n",
    "import numpy as np\n",
    "from pystackreg import StackReg\n",
    "from skimage import io\n",
    "from tqdm import tqdm\n",
    "from daskoctopus import DaskOctopusLiteLoader\n",
    "from skimage import transform as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b349a8a0",
   "metadata": {},
   "source": [
    "# Find images, organise into raw folder and load using dask octo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbeda8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### define root directory and specific experiment and location (will later make iterable)\n",
    "root_dir = '/home/nathan/data/kraken/commitment/test/'\n",
    "expt = \"MK0003\"\n",
    "pos = \"Pos1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1a5cbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "### create new subdir of for raw files and move them all there\n",
    "if not os.path.exists(os.path.join(root_dir, f'{expt}/{pos}/{pos}_raw')):\n",
    "    os.mkdir(os.path.join(root_dir, f'{expt}/{pos}/{pos}_raw'))\n",
    "    files = sorted(glob.glob(os.path.join(root_dir, f'{expt}/{pos}/*.tif')))\n",
    "    for file in files:\n",
    "        os.rename(file, file.replace(f'{pos}', f'{pos}/{pos}_raw'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a3d0870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cropping: None\n"
     ]
    }
   ],
   "source": [
    "### pre load files from raw file dir \n",
    "images = DaskOctopusLiteLoader(os.path.join(root_dir, f'{expt}/{pos}/{pos}_raw'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "683028b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table>\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 10.20 GiB </td>\n",
       "                        <td> 8.71 MiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (1200, 1352, 1688) </td>\n",
       "                        <td> (1, 1352, 1688) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Count </th>\n",
       "                        <td> 3600 Tasks </td>\n",
       "                        <td> 1200 Chunks </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                    <th> Type </th>\n",
       "                    <td> float32 </td>\n",
       "                    <td> numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"230\" height=\"196\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"60\" y2=\"50\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"10\" y1=\"96\" x2=\"60\" y2=\"146\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"12\" y2=\"98\" />\n",
       "  <line x1=\"15\" y1=\"5\" x2=\"15\" y2=\"101\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"17\" y2=\"104\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"20\" y2=\"106\" />\n",
       "  <line x1=\"23\" y1=\"13\" x2=\"23\" y2=\"109\" />\n",
       "  <line x1=\"25\" y1=\"15\" x2=\"25\" y2=\"111\" />\n",
       "  <line x1=\"28\" y1=\"18\" x2=\"28\" y2=\"114\" />\n",
       "  <line x1=\"31\" y1=\"21\" x2=\"31\" y2=\"117\" />\n",
       "  <line x1=\"33\" y1=\"23\" x2=\"33\" y2=\"119\" />\n",
       "  <line x1=\"36\" y1=\"26\" x2=\"36\" y2=\"122\" />\n",
       "  <line x1=\"39\" y1=\"29\" x2=\"39\" y2=\"125\" />\n",
       "  <line x1=\"41\" y1=\"31\" x2=\"41\" y2=\"127\" />\n",
       "  <line x1=\"44\" y1=\"34\" x2=\"44\" y2=\"130\" />\n",
       "  <line x1=\"46\" y1=\"36\" x2=\"46\" y2=\"133\" />\n",
       "  <line x1=\"49\" y1=\"39\" x2=\"49\" y2=\"135\" />\n",
       "  <line x1=\"52\" y1=\"42\" x2=\"52\" y2=\"138\" />\n",
       "  <line x1=\"54\" y1=\"44\" x2=\"54\" y2=\"140\" />\n",
       "  <line x1=\"57\" y1=\"47\" x2=\"57\" y2=\"143\" />\n",
       "  <line x1=\"60\" y1=\"50\" x2=\"60\" y2=\"146\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 60.181209924728186,50.181209924728186 60.181209924728186,146.29495400055757 10.0,96.11374407582939\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"130\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"132\" y2=\"2\" />\n",
       "  <line x1=\"15\" y1=\"5\" x2=\"135\" y2=\"5\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"137\" y2=\"7\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"140\" y2=\"10\" />\n",
       "  <line x1=\"23\" y1=\"13\" x2=\"143\" y2=\"13\" />\n",
       "  <line x1=\"25\" y1=\"15\" x2=\"145\" y2=\"15\" />\n",
       "  <line x1=\"28\" y1=\"18\" x2=\"148\" y2=\"18\" />\n",
       "  <line x1=\"31\" y1=\"21\" x2=\"151\" y2=\"21\" />\n",
       "  <line x1=\"33\" y1=\"23\" x2=\"153\" y2=\"23\" />\n",
       "  <line x1=\"36\" y1=\"26\" x2=\"156\" y2=\"26\" />\n",
       "  <line x1=\"39\" y1=\"29\" x2=\"159\" y2=\"29\" />\n",
       "  <line x1=\"41\" y1=\"31\" x2=\"161\" y2=\"31\" />\n",
       "  <line x1=\"44\" y1=\"34\" x2=\"164\" y2=\"34\" />\n",
       "  <line x1=\"46\" y1=\"36\" x2=\"166\" y2=\"36\" />\n",
       "  <line x1=\"49\" y1=\"39\" x2=\"169\" y2=\"39\" />\n",
       "  <line x1=\"52\" y1=\"42\" x2=\"172\" y2=\"42\" />\n",
       "  <line x1=\"54\" y1=\"44\" x2=\"174\" y2=\"44\" />\n",
       "  <line x1=\"57\" y1=\"47\" x2=\"177\" y2=\"47\" />\n",
       "  <line x1=\"60\" y1=\"50\" x2=\"180\" y2=\"50\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"60\" y2=\"50\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"130\" y1=\"0\" x2=\"180\" y2=\"50\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 130.0,0.0 180.1812099247282,50.181209924728186 60.181209924728186,50.181209924728186\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"60\" y1=\"50\" x2=\"180\" y2=\"50\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"60\" y1=\"146\" x2=\"180\" y2=\"146\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"60\" y1=\"50\" x2=\"60\" y2=\"146\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"180\" y1=\"50\" x2=\"180\" y2=\"146\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"60.181209924728186,50.181209924728186 180.1812099247282,50.181209924728186 180.1812099247282,146.29495400055757 60.181209924728186,146.29495400055757\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"120.181210\" y=\"166.294954\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >1688</text>\n",
       "  <text x=\"200.181210\" y=\"98.238082\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,200.181210,98.238082)\">1352</text>\n",
       "  <text x=\"25.090605\" y=\"141.204349\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,25.090605,141.204349)\">1200</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<stack, shape=(1200, 1352, 1688), dtype=float32, chunksize=(1, 1352, 1688), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images['irfp']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4314a4",
   "metadata": {},
   "source": [
    "# Find blank or overexposed images and display average channel brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6531bd57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cropping: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding mean values of brightfield images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 1/4 [00:03<00:09,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding mean values of gfp images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 2/4 [00:06<00:06,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding mean values of rfp images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 3/4 [00:09<00:03,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding mean values of irfp images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:12<00:00,  3.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of under/over-exposed frames: 8\n",
      "CPU times: user 26.5 s, sys: 5.41 s, total: 31.9 s\n",
      "Wall time: 13.4 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# pixel range criteria\n",
    "max_pixel, min_pixel = 200, 2\n",
    "\n",
    "### find mean values ### pre load files from raw file dir \n",
    "images = DaskOctopusLiteLoader(os.path.join(root_dir, f'{expt}/{pos}/{pos}_raw'))\n",
    "\n",
    "mean_arrays = {}\n",
    "dodgy_frame_list = set([])\n",
    "for channel in tqdm(images.channels):\n",
    "    print(f'Finding mean values of {channel.name.lower()} images')\n",
    "    mean_arrays[channel.name] = np.mean(images[channel.name], axis = (1,2)).compute() \n",
    "    for frame, mean_value in enumerate(mean_arrays[channel.name]):\n",
    "        if max_pixel < mean_value or mean_value < min_pixel:\n",
    "            dodgy_frame_list.add(frame)\n",
    "dodgy_frame_list = list(dodgy_frame_list)\n",
    "\n",
    "print('Number of under/over-exposed frames:', len(dodgy_frame_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6686782",
   "metadata": {},
   "source": [
    "# Select reference image to base alignment around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8011e037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average channel brightness for selection of reference image:\n",
      "0: BRIGHTFIELD: 28.949467\n",
      "1: GFP: 62.79905\n",
      "2: RFP: 6.4401646\n",
      "3: IRFP: 76.01225\n"
     ]
    }
   ],
   "source": [
    "print('Average channel brightness for selection of reference image:')\n",
    "for channel in images.channels:\n",
    "    print(f'{channel.value}: {channel.name}:', np.mean(mean_arrays[channel.name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e83d0329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GFP'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manually select reference channel by adding index\n",
    "reference_channel = images.channels[1]\n",
    "# automatically select reference channel from max average pixel value (ie. brightest channel)\n",
    "#reference_channel = images.channels[max([(channel.value, np.mean(mean_arrays[channel.name])) for channel in images.channels])[0]]\n",
    "reference_image = images[reference_channel.name]\n",
    "reference_channel.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b4a94df5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table>\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 10.20 GiB </td>\n",
       "                        <td> 8.71 MiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (1200, 1352, 1688) </td>\n",
       "                        <td> (1, 1352, 1688) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Count </th>\n",
       "                        <td> 3600 Tasks </td>\n",
       "                        <td> 1200 Chunks </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                    <th> Type </th>\n",
       "                    <td> float32 </td>\n",
       "                    <td> numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"230\" height=\"196\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"60\" y2=\"50\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"10\" y1=\"96\" x2=\"60\" y2=\"146\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"12\" y2=\"98\" />\n",
       "  <line x1=\"15\" y1=\"5\" x2=\"15\" y2=\"101\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"17\" y2=\"104\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"20\" y2=\"106\" />\n",
       "  <line x1=\"23\" y1=\"13\" x2=\"23\" y2=\"109\" />\n",
       "  <line x1=\"25\" y1=\"15\" x2=\"25\" y2=\"111\" />\n",
       "  <line x1=\"28\" y1=\"18\" x2=\"28\" y2=\"114\" />\n",
       "  <line x1=\"31\" y1=\"21\" x2=\"31\" y2=\"117\" />\n",
       "  <line x1=\"33\" y1=\"23\" x2=\"33\" y2=\"119\" />\n",
       "  <line x1=\"36\" y1=\"26\" x2=\"36\" y2=\"122\" />\n",
       "  <line x1=\"39\" y1=\"29\" x2=\"39\" y2=\"125\" />\n",
       "  <line x1=\"41\" y1=\"31\" x2=\"41\" y2=\"127\" />\n",
       "  <line x1=\"44\" y1=\"34\" x2=\"44\" y2=\"130\" />\n",
       "  <line x1=\"46\" y1=\"36\" x2=\"46\" y2=\"133\" />\n",
       "  <line x1=\"49\" y1=\"39\" x2=\"49\" y2=\"135\" />\n",
       "  <line x1=\"52\" y1=\"42\" x2=\"52\" y2=\"138\" />\n",
       "  <line x1=\"54\" y1=\"44\" x2=\"54\" y2=\"140\" />\n",
       "  <line x1=\"57\" y1=\"47\" x2=\"57\" y2=\"143\" />\n",
       "  <line x1=\"60\" y1=\"50\" x2=\"60\" y2=\"146\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 60.181209924728186,50.181209924728186 60.181209924728186,146.29495400055757 10.0,96.11374407582939\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"130\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"132\" y2=\"2\" />\n",
       "  <line x1=\"15\" y1=\"5\" x2=\"135\" y2=\"5\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"137\" y2=\"7\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"140\" y2=\"10\" />\n",
       "  <line x1=\"23\" y1=\"13\" x2=\"143\" y2=\"13\" />\n",
       "  <line x1=\"25\" y1=\"15\" x2=\"145\" y2=\"15\" />\n",
       "  <line x1=\"28\" y1=\"18\" x2=\"148\" y2=\"18\" />\n",
       "  <line x1=\"31\" y1=\"21\" x2=\"151\" y2=\"21\" />\n",
       "  <line x1=\"33\" y1=\"23\" x2=\"153\" y2=\"23\" />\n",
       "  <line x1=\"36\" y1=\"26\" x2=\"156\" y2=\"26\" />\n",
       "  <line x1=\"39\" y1=\"29\" x2=\"159\" y2=\"29\" />\n",
       "  <line x1=\"41\" y1=\"31\" x2=\"161\" y2=\"31\" />\n",
       "  <line x1=\"44\" y1=\"34\" x2=\"164\" y2=\"34\" />\n",
       "  <line x1=\"46\" y1=\"36\" x2=\"166\" y2=\"36\" />\n",
       "  <line x1=\"49\" y1=\"39\" x2=\"169\" y2=\"39\" />\n",
       "  <line x1=\"52\" y1=\"42\" x2=\"172\" y2=\"42\" />\n",
       "  <line x1=\"54\" y1=\"44\" x2=\"174\" y2=\"44\" />\n",
       "  <line x1=\"57\" y1=\"47\" x2=\"177\" y2=\"47\" />\n",
       "  <line x1=\"60\" y1=\"50\" x2=\"180\" y2=\"50\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"60\" y2=\"50\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"130\" y1=\"0\" x2=\"180\" y2=\"50\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 130.0,0.0 180.1812099247282,50.181209924728186 60.181209924728186,50.181209924728186\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"60\" y1=\"50\" x2=\"180\" y2=\"50\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"60\" y1=\"146\" x2=\"180\" y2=\"146\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"60\" y1=\"50\" x2=\"60\" y2=\"146\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"180\" y1=\"50\" x2=\"180\" y2=\"146\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"60.181209924728186,50.181209924728186 180.1812099247282,50.181209924728186 180.1812099247282,146.29495400055757 60.181209924728186,146.29495400055757\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"120.181210\" y=\"166.294954\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >1688</text>\n",
       "  <text x=\"200.181210\" y=\"98.238082\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,200.181210,98.238082)\">1352</text>\n",
       "  <text x=\"25.090605\" y=\"141.204349\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,25.090605,141.204349)\">1200</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<stack, shape=(1200, 1352, 1688), dtype=float32, chunksize=(1, 1352, 1688), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images['gfp']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b286dc16",
   "metadata": {},
   "source": [
    "## Set cropped area of reference image to base alignment around (whole image struggles to compute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e5215fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200, 500, 500)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crop_area = 500\n",
    "reference_image = reference_image[:,int((reference_image.shape[2]-crop_area)/2):int(reference_image.shape[2]-(reference_image.shape[2]-crop_area)/2),int((reference_image.shape[1]-crop_area)/2):int(reference_image.shape[1]-(reference_image.shape[1]-crop_area)/2)].compute()\n",
    "reference_image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466ad46f",
   "metadata": {},
   "source": [
    "# Register alignment and save out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "831dfca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_image = reference_image.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59ebe809",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nathan/analysis/miniconda3/envs/cellx/lib/python3.9/site-packages/pystackreg/pystackreg.py:379: UserWarning: Detected axis 1 as the possible time axis for the stack due to its low variability, but axis 0 was supplied for registration. Are you sure you supplied the correct axis?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23min 39s, sys: 2min 19s, total: 25min 58s\n",
      "Wall time: 25min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create operator using transformation type (translation)\n",
    "sr = StackReg(StackReg.TRANSLATION) \n",
    "\n",
    "# register each frame to the previous as transformation matrices/tensor\n",
    "transform_tensor = sr.register_stack(reference_image, reference = 'previous').astype(np.int8)\n",
    "\n",
    "# save out transform tensor\n",
    "np.save(os.path.join(root_dir, f'{expt}/{pos}/{reference_channel.name.lower()}_transform_tensor.npy'), transform_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c5c334e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200, 3, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d310e7d",
   "metadata": {},
   "source": [
    "# Apply transformation matrix to all channels and save out images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ae81366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning brightfield channel 1 / 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [02:27<00:00,  8.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning gfp channel 2 / 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [02:21<00:00,  8.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning rfp channel 3 / 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [02:19<00:00,  8.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning irfp channel 4 / 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [02:23<00:00,  8.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 26s, sys: 16.4 s, total: 6min 43s\n",
      "Wall time: 9min 32s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### iterating over channels\n",
    "# create aligned image dir if does not exist \n",
    "if not os.path.exists(os.path.join(root_dir, f'{expt}/{pos}/{pos}_aligned')):\n",
    "    os.mkdir(os.path.join(root_dir, f'{expt}/{pos}/{pos}_aligned'))\n",
    "# iterate over channels\n",
    "for channel in images.channels:\n",
    "    print('Aligning', channel.name.lower(), 'channel', channel.value+1, '/', len(images.channels))\n",
    "    #iterate over all images in channel\n",
    "    for i in tqdm(range(len(images[channel.name]))):\n",
    "        # skip dodgy frames and don't save out into aligned folder\n",
    "        if i in dodgy_frame_list:\n",
    "            continue\n",
    "        # load specific transform matrix for that frame\n",
    "        transform_matrix = tf.EuclideanTransform(matrix = transform_tensor[i,...],rotation = None)\n",
    "        # transform image\n",
    "        transformed_image = (tf.warp(images[channel.name][i,...], transform_matrix)*255).astype(np.uint8)\n",
    "        # set transformed image pathname by editing base dir\n",
    "        fn = images.files(channel.name)[i].replace('_raw', '_aligned')\n",
    "        # save trans image out\n",
    "        io.imsave(fn, transformed_image, check_contrast=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1ec55c0",
   "metadata": {},
   "source": [
    "# Troubleshooting jumpy transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5981742b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### problematic frame\n",
    "i = 47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "1127d486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1,   0, -21],\n",
       "       [  0,   1, -98],\n",
       "       [  0,   0,   1]], dtype=int8)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### significant longitudinal shift at frame 1\n",
    "transform_tensor[i,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "80b1e962",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1,  0, 19],\n",
       "       [ 0,  1, -4],\n",
       "       [ 0,  0,  1]], dtype=int8)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### another lateral shift at frame 6\n",
    "transform_tensor[i-1,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9c64625",
   "metadata": {},
   "outputs": [],
   "source": [
    "### finding maximum shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "11b4a26d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "127"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.amax(transform_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fa369efe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "307\n",
      "391\n",
      "392\n",
      "393\n",
      "395\n",
      "396\n",
      "398\n",
      "399\n",
      "401\n",
      "415\n",
      "418\n",
      "420\n",
      "515\n",
      "530\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "580\n",
      "593\n",
      "613\n",
      "626\n",
      "627\n",
      "628\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "637\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "647\n",
      "648\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "665\n",
      "666\n",
      "667\n",
      "702\n",
      "728\n",
      "738\n",
      "743\n",
      "753\n",
      "756\n"
     ]
    }
   ],
   "source": [
    "### theres a lot of frames with this max shift\n",
    "for i in range(len(transform_tensor)):\n",
    "    if np.amax(transform_tensor[i,...]) == 127:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f57c13c",
   "metadata": {},
   "source": [
    "# Trying different methods of transformation alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cfa4062a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table>\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 8.71 MiB </td>\n",
       "                        <td> 8.71 MiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (1352, 1688) </td>\n",
       "                        <td> (1352, 1688) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Count </th>\n",
       "                        <td> 3601 Tasks </td>\n",
       "                        <td> 1 Chunks </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                    <th> Type </th>\n",
       "                    <td> float32 </td>\n",
       "                    <td> numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"170\" height=\"146\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"120\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"0\" y1=\"96\" x2=\"120\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"0\" y1=\"0\" x2=\"0\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"120\" y1=\"0\" x2=\"120\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"0.0,0.0 120.0,0.0 120.0,96.11374407582939 0.0,96.11374407582939\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"60.000000\" y=\"116.113744\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >1688</text>\n",
       "  <text x=\"140.000000\" y=\"48.056872\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,140.000000,48.056872)\">1352</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<getitem, shape=(1352, 1688), dtype=float32, chunksize=(1352, 1688), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images['gfp'][47]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab64fa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4c787a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[157,  29,  25, ...,  70,  69,  68],\n",
       "       [ 73,  73,  72, ...,  70,  67,  68],\n",
       "       [ 73,  74,  70, ...,  67,  68,  67],\n",
       "       ...,\n",
       "       [ 51,  54,  52, ...,  52,  52,  54],\n",
       "       [ 53,  53,  54, ...,  50,  52,  54],\n",
       "       [ 54,  52,  51, ...,  51,  51,  53]], dtype=uint8)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images['gfp'][47].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "13d6cfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "99f3f138",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_tra = sr.register(images['gfp'][i-1], images['gfp'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "35315dad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.        ,   0.        , -40.72189378],\n",
       "       [  0.        ,   1.        , -93.97357383],\n",
       "       [  0.        ,   0.        ,   1.        ]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_tra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "be05db99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1,   0, -40],\n",
       "       [  0,   1, -93],\n",
       "       [  0,   0,   1]], dtype=int8)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_tra.astype(np.int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e04f63f",
   "metadata": {},
   "source": [
    "# Try different transformation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0c6949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation matrix should take on the form\n",
    "\n",
    "#             [1 , 0 , x\n",
    "#              0 , 1 , y\n",
    "#              0 , 0 , 1]\n",
    "\n",
    "# where x and y are the translate magnitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c82a1098",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "04de3a1a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.        ,   0.        , -40.72189378],\n",
       "       [  0.        ,   1.        , -93.97357383],\n",
       "       [  0.        ,   0.        ,   1.        ]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### float translation\n",
    "StackReg(StackReg.TRANSLATION).register(images['gfp'][i-1], images['gfp'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8a43d2d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1,   0, -40],\n",
       "       [  0,   1, -93],\n",
       "       [  0,   0,   1]], dtype=int8)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### int translation\n",
    "StackReg(StackReg.TRANSLATION).register(images['gfp'][i-1], images['gfp'][i]).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f930a739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.99997919e-01,  2.04021154e-03, -3.24573990e+01],\n",
       "       [-2.04021154e-03,  9.99997919e-01, -6.02019623e+01],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### float rigid body\n",
    "StackReg(StackReg.RIGID_BODY).register(images['gfp'][i-1], images['gfp'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c6258439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.,   0., -32.],\n",
       "       [ -0.,   1., -60.],\n",
       "       [  0.,   0.,   1.]])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### np.rint rigid body\n",
    "np.rint(StackReg(StackReg.RIGID_BODY).register(images['gfp'][i-1], images['gfp'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d47c6c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "### integer-ising the matrix zeroes some important numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ede7b1e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0, 53],\n",
       "       [ 0,  0, 49],\n",
       "       [ 0,  0,  1]], dtype=int8)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### int rigidbody\n",
    "StackReg(StackReg.RIGID_BODY).register(images['gfp'][i-1], images['gfp'][i]).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "270bed8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 8.85810604e-01, -1.31468704e-02,  5.37588333e+01],\n",
       "       [-8.63918693e-03,  8.96640838e-01,  4.93034402e+01],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### float affine\n",
    "StackReg(StackReg.AFFINE).register(images['gfp'][i-1], images['gfp'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0abf6968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1., -0., 54.],\n",
       "       [-0.,  1., 49.],\n",
       "       [ 0.,  0.,  1.]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### np.rint rigid body\n",
    "np.rint(StackReg(StackReg.AFFINE).register(images['gfp'][i-1], images['gfp'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a806a596",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0, 53],\n",
       "       [ 0,  0, 49],\n",
       "       [ 0,  0,  1]], dtype=int8)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### int affine\n",
    "StackReg(StackReg.AFFINE).register(images['gfp'][i-1], images['gfp'][i]).astype(np.int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ecdf23",
   "metadata": {},
   "source": [
    "# seems like all the alignment methods produce similar shifted outputs... is it the images?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ec050a4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BRIGHTFIELD [[ 1  0 -6]\n",
      " [ 0  1  0]\n",
      " [ 0  0  1]]\n",
      "GFP [[  1   0 -40]\n",
      " [  0   1 -93]\n",
      " [  0   0   1]]\n",
      "RFP [[ 1  0 -5]\n",
      " [ 0  1 -1]\n",
      " [ 0  0  1]]\n",
      "IRFP [[ 1  0 -5]\n",
      " [ 0  1  0]\n",
      " [ 0  0  1]]\n"
     ]
    }
   ],
   "source": [
    "for channel in images.channels:\n",
    "    print(channel.name, StackReg(StackReg.TRANSLATION).register(images[channel.name][i-1], images[channel.name][i]).astype(np.int8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "666b7c5b",
   "metadata": {},
   "source": [
    "# is it the gfp channel? checking each channel for max transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bff765d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting channel: BRIGHTFIELD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1199/1199 [25:51<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BRIGHTFIELD 126\n",
      "Starting channel: GFP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1199/1199 [26:16<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GFP 108\n",
      "Starting channel: RFP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1199/1199 [27:56<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFP 47\n",
      "Starting channel: IRFP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1199/1199 [27:06<00:00,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRFP 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trans_tensors = {}\n",
    "for channel in images.channels:\n",
    "    print('Starting channel:', channel.name)\n",
    "    trans_tensor = []\n",
    "    for i in tqdm(range(1, len(images['gfp']))):\n",
    "        ### create transformation matrix for i'th and i+1'th frame\n",
    "        trans_matrix = StackReg(StackReg.TRANSLATION).register(images[channel.name][i-1], images[channel.name][i]).astype(np.int8)\n",
    "        trans_tensor.append(trans_matrix)\n",
    "    trans_tensor = np.stack(trans_tensor)\n",
    "    trans_tensors[channel.name] = trans_tensor\n",
    "    print(channel.name, np.amax(trans_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8759f6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('all_ch_trans_tensors.json', 'wb') as fp:\n",
    "    pickle.dump(trans_tensors, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c187e8f2",
   "metadata": {},
   "source": [
    "# Checking the alignment tensors of each channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4fc324a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BRIGHTFIELD 126\n",
      "GFP 108\n",
      "RFP 47\n",
      "IRFP 24\n"
     ]
    }
   ],
   "source": [
    "for channel in trans_tensors:\n",
    "    print(channel, np.amax(trans_tensors[channel]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be9284a",
   "metadata": {},
   "source": [
    "# irfp channel has lowest max shift in so test run alignment on that "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "053c7b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_tensor = trans_tensors['IRFP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4ad9f2da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.amax(transform_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0796a834",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200, 1199)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images['gfp']), len(transform_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "22b031be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning brightfield channel 1 / 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [01:28<00:00, 13.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning gfp channel 2 / 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [01:28<00:00, 13.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning rfp channel 3 / 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [01:26<00:00, 13.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning irfp channel 4 / 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [01:31<00:00, 13.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 11s, sys: 43.9 s, total: 5min 55s\n",
      "Wall time: 5min 54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for channel in images.channels:\n",
    "    print('Aligning', channel.name.lower(), 'channel', channel.value+1, '/', len(images.channels))\n",
    "    #iterate over all images in channel\n",
    "    for i in tqdm(range(len(images[channel.name]))):\n",
    "        # skip dodgy frames and don't save out into aligned folder\n",
    "        if i in dodgy_frame_list or i == 1199:\n",
    "            continue\n",
    "        # load specific transform matrix for that frame\n",
    "        transform_matrix = tf.EuclideanTransform(matrix = transform_tensor[i,...],rotation = None)\n",
    "        # transform image\n",
    "        transformed_image = (tf.warp(images[channel.name][i,...], transform_matrix)*255).astype(np.uint8)\n",
    "        # set transformed image pathname by editing base dir\n",
    "        fn = images.files(channel.name)[i].replace('_raw', '_aligned')\n",
    "        # save trans image out\n",
    "        io.imsave(fn, transformed_image, check_contrast=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e671b9a7",
   "metadata": {},
   "source": [
    "# is it saving out the image as unsigned?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4de0458b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning brightfield channel 1 / 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1199/1199 [01:30<00:00, 13.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning gfp channel 2 / 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1199/1199 [01:41<00:00, 11.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning rfp channel 3 / 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1199/1199 [02:09<00:00,  9.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning irfp channel 4 / 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1199/1199 [02:08<00:00,  9.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 26s, sys: 45.6 s, total: 6min 12s\n",
      "Wall time: 7min 30s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for channel in images.channels:\n",
    "    print('Aligning', channel.name.lower(), 'channel', channel.value+1, '/', len(images.channels))\n",
    "    #iterate over all images in channel\n",
    "    for i in tqdm(range(1, len(images[channel.name]))):\n",
    "        # skip dodgy frames and don't save out into aligned folder\n",
    "        if i in dodgy_frame_list or i == 1199:\n",
    "            continue\n",
    "        # load specific transform matrix for that frame\n",
    "        transform_matrix = tf.EuclideanTransform(matrix = transform_tensor[i,...],rotation = None)\n",
    "        # transform image\n",
    "        transformed_image = (tf.warp(images[channel.name][i,...], transform_matrix)*255).astype(np.int8)\n",
    "        # set transformed image pathname by editing base dir\n",
    "        fn = images.files(channel.name)[i].replace('_raw', '_aligned_signed')\n",
    "        # save trans image out\n",
    "        io.imsave(fn, transformed_image, check_contrast=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "685c67b1",
   "metadata": {},
   "source": [
    "# Print dodgy frame list as a part of troubleshooting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "85cd2250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[76, 108, 617, 630, 783, 972, 1003, 1096]\n"
     ]
    }
   ],
   "source": [
    "print(sorted(dodgy_frame_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918491e2",
   "metadata": {},
   "source": [
    "# Check alignment using Napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "262a10b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "866e356b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cropping: None\n"
     ]
    }
   ],
   "source": [
    "aligned_images = DaskOctopusLiteLoader(os.path.join(root_dir, f'{expt}/{pos}/{pos}_aligned'))\n",
    "\n",
    "viewer = napari.Viewer()\n",
    "for channel in aligned_images.channels:\n",
    "    viewer.add_image(aligned_images[channel.name], name = channel.name, blending = 'additive', contrast_limits = [0,255])\n",
    "                     #, colormap = napari.utils.colormaps.SIMPLE_COLORMAPS.popitem()) # lazy hack to randomly generate different colormaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e93eab69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cropping: None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Image layer 'gfp' at 0x7f80bc0d98e0>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aligned_images = DaskOctopusLiteLoader(os.path.join(root_dir, f'{expt}/{pos}/{pos}_aligned'))\n",
    "\n",
    "viewer = napari.Viewer()\n",
    "viewer.add_image(images['gfp'], name = 'gfp', blending = 'additive', contrast_limits = [0,255])\n",
    "                     #, colormap = napari.utils.colormaps.SIMPLE_COLORMAPS.popitem()) # lazy hack to randomly generate different colormaps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3aac445",
   "metadata": {},
   "source": [
    "# Batch execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63fa67c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/home/nathan/data/kraken/commitment/test/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc821c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "alignment(expt_list = ['MK0000', 'MK0001', 'MK0002', 'MK0003'], \n",
    "          max_pixel = 200, \n",
    "          min_pixel = 2, \n",
    "          crop_area = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952bbbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()\n",
    "for channel in aligned_images.channels:\n",
    "    viewer.add_image(aligned_images[channel.name], name = channel.name, blending = 'additive', contrast_limits = [0,255], colormap = napari.utils.colormaps.SIMPLE_COLORMAPS.popitem()) # lazy hack to randomly generate different colormaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eea9708c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alignment(expt_list, max_pixel, min_pixel, crop_area):\n",
    "\n",
    "    ### Iterate over all experiments defined in expt_list\n",
    "    for expt in expt_list:\n",
    "        # Find all positions in that experiment\n",
    "        pos_list = [pos for pos in os.listdir(os.path.join(root_dir, expt)) if 'Pos' in pos]\n",
    "        ### Iterate over all positions in that experiment\n",
    "        for pos in pos_list:\n",
    "            ### create new subdir of for raw files and move them all there\n",
    "            if not os.path.exists(os.path.join(root_dir, f'{expt}/{pos}/{pos}_raw')):\n",
    "                os.mkdir(os.path.join(root_dir, f'{expt}/{pos}/{pos}_raw'))\n",
    "                files = sorted(glob.glob(os.path.join(root_dir, f'{expt}/{pos}/*.tif')))\n",
    "                for file in files:\n",
    "                    os.rename(file, file.replace(f'{pos}', f'{pos}/{pos}_raw'))\n",
    "\n",
    "            ### pre load files from raw file dir \n",
    "            images = DaskOctopusLiteLoader(os.path.join(root_dir, f'{expt}/{pos}/{pos}_raw'))\n",
    "\n",
    "            ### measure mean pixel value arrays and use to find under/over-exposed frames\n",
    "            # create empty dicts and sets to store values in \n",
    "            mean_arrays = {}\n",
    "            dodgy_frame_list = set([])\n",
    "            # iterate over channels\n",
    "            for channel in tqdm(images.channels):\n",
    "                print(f'Finding mean values of {channel.name.lower()} images', pos, expt)\n",
    "                # find mean pixel values for each channel\n",
    "                mean_arrays[channel.name] = np.mean(images[channel.name], axis = (1,2)).compute() \n",
    "                # iterate over frames\n",
    "                for frame, mean_value in enumerate(mean_arrays[channel.name]):\n",
    "                    if max_pixel < mean_value or mean_value < min_pixel:\n",
    "                        # if frame does not meet inclusion criteria then add to dodgy list\n",
    "                        dodgy_frame_list.add(frame)\n",
    "            dodgy_frame_list = list(dodgy_frame_list)\n",
    "            print('Number of under/over-exposed frames:', len(dodgy_frame_list), pos, expt)\n",
    "\n",
    "            ### create aligned image dir if does not exist \n",
    "            if not os.path.exists(os.path.join(root_dir, f'{expt}/{pos}/{pos}_aligned')):\n",
    "                os.mkdir(os.path.join(root_dir, f'{expt}/{pos}/{pos}_aligned'))\n",
    "\n",
    "            ### Automatically pick reference image to perform alignment on \n",
    "            # Pick channel based on index of brightest channel from maximum mean pixel array\n",
    "            reference_channel = images.channels[max([(channel.value, np.mean(mean_arrays[channel.name])) for channel in images.channels])[0]]\n",
    "            # Define reference images\n",
    "            reference_image = images[reference_channel.name]\n",
    "            reference_image = reference_image[:,int((reference_image.shape[2]-crop_area)/2):int(reference_image.shape[2]-(reference_image.shape[2]-crop_area)/2),int((reference_image.shape[1]-crop_area)/2):int(reference_image.shape[1]-(reference_image.shape[1]-crop_area)/2)].compute()\n",
    "            reference_image.shape\n",
    "            print('Automatically selected and cropped reference image:', reference_channel.name)\n",
    "\n",
    "            ### Register alignment\n",
    "            print('Registering alignment for', pos, expt)\n",
    "            # create operator using transformation type (translation)\n",
    "            sr = StackReg(StackReg.TRANSLATION) \n",
    "            # register each frame using reference image to the previous as transformation matrices/tensor\n",
    "            transform_tensor = sr.register_stack(reference_image, reference = 'previous').astype(np.uint8)\n",
    "            # save out transform tensor\n",
    "            np.save(os.path.join(root_dir, f'{expt}/{pos}/{reference_channel.name.lower()}_transform_tensor.npy'), transform_tensor)\n",
    "\n",
    "            ### Perform alignment\n",
    "            # create aligned image dir if does not exist \n",
    "            if not os.path.exists(os.path.join(root_dir, f'{expt}/{pos}/{pos}_aligned')):\n",
    "                os.mkdir(os.path.join(root_dir, f'{expt}/{pos}/{pos}_aligned'))\n",
    "            # iterate over channels\n",
    "            for channel in images.channels:\n",
    "                print('Aligning', channel.name.lower(), 'channel', channel.value+1, '/', len(images.channels))\n",
    "                #iterate over all images in channel\n",
    "                for i in tqdm(range(len(images[channel.name]))):\n",
    "                    # skip dodgy frames and don't save out into aligned folder\n",
    "                    if i in dodgy_frame_list:\n",
    "                        continue\n",
    "                    # load specific transform matrix for that frame\n",
    "                    transform_matrix = tf.EuclideanTransform(matrix = transform_tensor[i,...],rotation = None)\n",
    "                    # transform image\n",
    "                    transformed_image = (tf.warp(images[channel.name][i,...], transform_matrix)*255).astype(np.uint8)\n",
    "                    # set transformed image pathname by editing base dir\n",
    "                    fn = images.files(channel.name)[i].replace('_raw', '_aligned')\n",
    "                    # save trans image out\n",
    "                    io.imsave(fn, transformed_image, check_contrast=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a80f5ab",
   "metadata": {},
   "source": [
    "# Repeat alignment for larger datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3af662",
   "metadata": {},
   "source": [
    "# Compile stacks and save out?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2c79b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "start()\n",
    "aligned_images = DaskOctopusLiteLoader(os.path.join(root_dir, f'{expt}/{pos}/{pos}_aligned'))\n",
    "stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CellX",
   "language": "python",
   "name": "cellx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
