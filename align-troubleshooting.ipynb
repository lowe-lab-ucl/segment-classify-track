{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "127b5eb3",
   "metadata": {},
   "source": [
    "# Align and remove blanks\n",
    "\n",
    "Adapted from Giulia Vallardi's ImageJ macro, this notebook removes any blank frames from timelapse experiments and aligns the images. \n",
    "\n",
    "\"Fiji macro to remove over- and under-exposed images, and align the image stacks\n",
    "\n",
    "The settings for the alignments are: \n",
    "registration by Translation > only modify XY coordinates\n",
    "Shrinkage constrain activated (this model allows a better registration based on all images, not using a reference image. It is more time consuming though)\n",
    "Transform matrices are saved during registration and then applied to the other channels during transformation.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa19f60e",
   "metadata": {},
   "source": [
    "# to - do: decide how to import dask octopus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20b37ccd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'octopuslite'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e4d1dcca6c3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0moctopuslite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'octopuslite'"
     ]
    }
   ],
   "source": [
    "import octopuslite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7859805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import enum\n",
    "import numpy as np\n",
    "from pystackreg import StackReg\n",
    "from skimage import io\n",
    "from tqdm import tqdm\n",
    "from daskoctopus import DaskOctopusLiteLoader\n",
    "from skimage import transform as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b349a8a0",
   "metadata": {},
   "source": [
    "# Find images, organise into raw folder and load using dask octo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbeda8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### define root directory and specific experiment and location (will later make iterable)\n",
    "root_dir = '/home/nathan/data/kraken/commitment/test/'\n",
    "expt = \"MK0003\"\n",
    "pos = \"Pos1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1a5cbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "### create new subdir of for raw files and move them all there\n",
    "if not os.path.exists(os.path.join(root_dir, f'{expt}/{pos}/{pos}_raw')):\n",
    "    os.mkdir(os.path.join(root_dir, f'{expt}/{pos}/{pos}_raw'))\n",
    "    files = sorted(glob.glob(os.path.join(root_dir, f'{expt}/{pos}/*.tif')))\n",
    "    for file in files:\n",
    "        os.rename(file, file.replace(f'{pos}', f'{pos}/{pos}_raw'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a3d0870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cropping: None\n"
     ]
    }
   ],
   "source": [
    "### pre load files from raw file dir \n",
    "images = DaskOctopusLiteLoader(os.path.join(root_dir, f'{expt}/{pos}/{pos}_raw'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "683028b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table>\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 10.20 GiB </td>\n",
       "                        <td> 8.71 MiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (1200, 1352, 1688) </td>\n",
       "                        <td> (1, 1352, 1688) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Count </th>\n",
       "                        <td> 3600 Tasks </td>\n",
       "                        <td> 1200 Chunks </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                    <th> Type </th>\n",
       "                    <td> float32 </td>\n",
       "                    <td> numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"230\" height=\"196\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"60\" y2=\"50\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"10\" y1=\"96\" x2=\"60\" y2=\"146\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"12\" y2=\"98\" />\n",
       "  <line x1=\"15\" y1=\"5\" x2=\"15\" y2=\"101\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"17\" y2=\"104\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"20\" y2=\"106\" />\n",
       "  <line x1=\"23\" y1=\"13\" x2=\"23\" y2=\"109\" />\n",
       "  <line x1=\"25\" y1=\"15\" x2=\"25\" y2=\"111\" />\n",
       "  <line x1=\"28\" y1=\"18\" x2=\"28\" y2=\"114\" />\n",
       "  <line x1=\"31\" y1=\"21\" x2=\"31\" y2=\"117\" />\n",
       "  <line x1=\"33\" y1=\"23\" x2=\"33\" y2=\"119\" />\n",
       "  <line x1=\"36\" y1=\"26\" x2=\"36\" y2=\"122\" />\n",
       "  <line x1=\"39\" y1=\"29\" x2=\"39\" y2=\"125\" />\n",
       "  <line x1=\"41\" y1=\"31\" x2=\"41\" y2=\"127\" />\n",
       "  <line x1=\"44\" y1=\"34\" x2=\"44\" y2=\"130\" />\n",
       "  <line x1=\"46\" y1=\"36\" x2=\"46\" y2=\"133\" />\n",
       "  <line x1=\"49\" y1=\"39\" x2=\"49\" y2=\"135\" />\n",
       "  <line x1=\"52\" y1=\"42\" x2=\"52\" y2=\"138\" />\n",
       "  <line x1=\"54\" y1=\"44\" x2=\"54\" y2=\"140\" />\n",
       "  <line x1=\"57\" y1=\"47\" x2=\"57\" y2=\"143\" />\n",
       "  <line x1=\"60\" y1=\"50\" x2=\"60\" y2=\"146\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 60.181209924728186,50.181209924728186 60.181209924728186,146.29495400055757 10.0,96.11374407582939\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"130\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"132\" y2=\"2\" />\n",
       "  <line x1=\"15\" y1=\"5\" x2=\"135\" y2=\"5\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"137\" y2=\"7\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"140\" y2=\"10\" />\n",
       "  <line x1=\"23\" y1=\"13\" x2=\"143\" y2=\"13\" />\n",
       "  <line x1=\"25\" y1=\"15\" x2=\"145\" y2=\"15\" />\n",
       "  <line x1=\"28\" y1=\"18\" x2=\"148\" y2=\"18\" />\n",
       "  <line x1=\"31\" y1=\"21\" x2=\"151\" y2=\"21\" />\n",
       "  <line x1=\"33\" y1=\"23\" x2=\"153\" y2=\"23\" />\n",
       "  <line x1=\"36\" y1=\"26\" x2=\"156\" y2=\"26\" />\n",
       "  <line x1=\"39\" y1=\"29\" x2=\"159\" y2=\"29\" />\n",
       "  <line x1=\"41\" y1=\"31\" x2=\"161\" y2=\"31\" />\n",
       "  <line x1=\"44\" y1=\"34\" x2=\"164\" y2=\"34\" />\n",
       "  <line x1=\"46\" y1=\"36\" x2=\"166\" y2=\"36\" />\n",
       "  <line x1=\"49\" y1=\"39\" x2=\"169\" y2=\"39\" />\n",
       "  <line x1=\"52\" y1=\"42\" x2=\"172\" y2=\"42\" />\n",
       "  <line x1=\"54\" y1=\"44\" x2=\"174\" y2=\"44\" />\n",
       "  <line x1=\"57\" y1=\"47\" x2=\"177\" y2=\"47\" />\n",
       "  <line x1=\"60\" y1=\"50\" x2=\"180\" y2=\"50\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"60\" y2=\"50\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"130\" y1=\"0\" x2=\"180\" y2=\"50\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 130.0,0.0 180.1812099247282,50.181209924728186 60.181209924728186,50.181209924728186\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"60\" y1=\"50\" x2=\"180\" y2=\"50\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"60\" y1=\"146\" x2=\"180\" y2=\"146\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"60\" y1=\"50\" x2=\"60\" y2=\"146\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"180\" y1=\"50\" x2=\"180\" y2=\"146\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"60.181209924728186,50.181209924728186 180.1812099247282,50.181209924728186 180.1812099247282,146.29495400055757 60.181209924728186,146.29495400055757\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"120.181210\" y=\"166.294954\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >1688</text>\n",
       "  <text x=\"200.181210\" y=\"98.238082\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,200.181210,98.238082)\">1352</text>\n",
       "  <text x=\"25.090605\" y=\"141.204349\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,25.090605,141.204349)\">1200</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<stack, shape=(1200, 1352, 1688), dtype=float32, chunksize=(1, 1352, 1688), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images['irfp']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4314a4",
   "metadata": {},
   "source": [
    "# Find blank or overexposed images and display average channel brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c48412ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cropping: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding mean values of brightfield images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 1/4 [00:34<01:44, 34.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding mean values of gfp images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 2/4 [01:11<01:11, 35.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding mean values of rfp images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 3/4 [01:45<00:35, 35.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding mean values of irfp images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [02:20<00:00, 35.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of under/over-exposed frames: 8\n",
      "CPU times: user 23 s, sys: 9.18 s, total: 32.2 s\n",
      "Wall time: 2min 20s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# pixel range criteria\n",
    "max_pixel, min_pixel = 200, 2\n",
    "\n",
    "### find mean values ### pre load files from raw file dir \n",
    "images = DaskOctopusLiteLoader(os.path.join(root_dir, f'{expt}/{pos}/{pos}_raw'))\n",
    "\n",
    "mean_arrays = {}\n",
    "dodgy_frame_list = set([])\n",
    "for channel in tqdm(images.channels, desc = f'Finding mean values of {channel.name.lower()} images'):\n",
    "    mean_arrays[channel.name] = np.mean(images[channel.name], axis = (1,2)).compute() \n",
    "    for frame, mean_value in enumerate(mean_arrays[channel.name]):\n",
    "        if max_pixel < mean_value or mean_value < min_pixel:\n",
    "            dodgy_frame_list.add(frame)\n",
    "dodgy_frame_list = list(dodgy_frame_list)\n",
    "\n",
    "print('Number of under/over-exposed frames:', len(dodgy_frame_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d691578",
   "metadata": {},
   "source": [
    "# Filtering to remove blank or overexposed frames from image array and mean value arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e00d0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_images= {}\n",
    "for channel in images.channels:\n",
    "    filtered_images[channel.name] = np.delete(images[channel], dodgy_frame_list, axis = 0)\n",
    "    mean_arrays[channel.name] = np.delete(mean_arrays[channel.name], dodgy_frame_list, axis = 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "13077a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BRIGHTFIELD': dask.array<concatenate, shape=(1192, 1352, 1688), dtype=float32, chunksize=(1, 1352, 1688), chunktype=numpy.ndarray>,\n",
       " 'GFP': dask.array<concatenate, shape=(1192, 1352, 1688), dtype=float32, chunksize=(1, 1352, 1688), chunktype=numpy.ndarray>,\n",
       " 'RFP': dask.array<concatenate, shape=(1192, 1352, 1688), dtype=float32, chunksize=(1, 1352, 1688), chunktype=numpy.ndarray>,\n",
       " 'IRFP': dask.array<concatenate, shape=(1192, 1352, 1688), dtype=float32, chunksize=(1, 1352, 1688), chunktype=numpy.ndarray>}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a76f8d",
   "metadata": {},
   "source": [
    "# write out dask octo function to forget certain frames\n",
    "\n",
    "### or write something to dask octo to delete from array???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "775d573b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DaskOctopusLiteLoader' object does not support item assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-1be687828837>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfiltered_images\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchannel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchannels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchannel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mchannel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdodgy_frame_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'DaskOctopusLiteLoader' object does not support item assignment"
     ]
    }
   ],
   "source": [
    "filtered_images= {}\n",
    "for channel in images.channels:\n",
    "    images[channel.name] = np.delete(images[channel], dodgy_frame_list, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f06e525f",
   "metadata": {},
   "source": [
    "# Select reference image to base alignment around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9407bfcd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average channel brightness for selection of reference image:\n",
      "0: BRIGHTFIELD: 28.574265\n",
      "1: GFP: 62.654087\n",
      "2: RFP: 6.0335283\n",
      "3: IRFP: 76.07041\n"
     ]
    }
   ],
   "source": [
    "print('Average channel brightness for selection of reference image:')\n",
    "for channel in images.channels:\n",
    "    print(f'{channel.value}: {channel.name}:', np.mean(mean_arrays[channel.name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6228689a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference channel: IRFP\n"
     ]
    }
   ],
   "source": [
    "# manually select reference channel by adding index\n",
    "# reference_channel = filtered_images['IRFP']\n",
    "# automatically select reference channel from max average pixel value (ie. brightest channel)\n",
    "reference_channel = images.channels[max([(channel.value, np.mean(mean_arrays[channel.name])) for channel in images.channels])[0]]\n",
    "reference_image = filtered_images[reference_channel.name]\n",
    "print('Reference channel:', reference_channel.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a980aa9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table>\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 10.13 GiB </td>\n",
       "                        <td> 8.71 MiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (1192, 1352, 1688) </td>\n",
       "                        <td> (1, 1352, 1688) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Count </th>\n",
       "                        <td> 7108 Tasks </td>\n",
       "                        <td> 1192 Chunks </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                    <th> Type </th>\n",
       "                    <td> float32 </td>\n",
       "                    <td> numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"229\" height=\"195\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"59\" y2=\"49\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"10\" y1=\"96\" x2=\"59\" y2=\"145\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"12\" y2=\"98\" />\n",
       "  <line x1=\"15\" y1=\"5\" x2=\"15\" y2=\"101\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"17\" y2=\"103\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"20\" y2=\"106\" />\n",
       "  <line x1=\"23\" y1=\"13\" x2=\"23\" y2=\"109\" />\n",
       "  <line x1=\"25\" y1=\"15\" x2=\"25\" y2=\"111\" />\n",
       "  <line x1=\"28\" y1=\"18\" x2=\"28\" y2=\"114\" />\n",
       "  <line x1=\"30\" y1=\"20\" x2=\"30\" y2=\"117\" />\n",
       "  <line x1=\"33\" y1=\"23\" x2=\"33\" y2=\"119\" />\n",
       "  <line x1=\"36\" y1=\"26\" x2=\"36\" y2=\"122\" />\n",
       "  <line x1=\"38\" y1=\"28\" x2=\"38\" y2=\"124\" />\n",
       "  <line x1=\"41\" y1=\"31\" x2=\"41\" y2=\"127\" />\n",
       "  <line x1=\"44\" y1=\"34\" x2=\"44\" y2=\"130\" />\n",
       "  <line x1=\"46\" y1=\"36\" x2=\"46\" y2=\"132\" />\n",
       "  <line x1=\"49\" y1=\"39\" x2=\"49\" y2=\"135\" />\n",
       "  <line x1=\"51\" y1=\"41\" x2=\"51\" y2=\"138\" />\n",
       "  <line x1=\"54\" y1=\"44\" x2=\"54\" y2=\"140\" />\n",
       "  <line x1=\"57\" y1=\"47\" x2=\"57\" y2=\"143\" />\n",
       "  <line x1=\"59\" y1=\"49\" x2=\"59\" y2=\"145\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 59.846668525229994,49.846668525229994 59.846668525229994,145.96041260105937 10.0,96.11374407582939\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"130\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"12\" y1=\"2\" x2=\"132\" y2=\"2\" />\n",
       "  <line x1=\"15\" y1=\"5\" x2=\"135\" y2=\"5\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"137\" y2=\"7\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"140\" y2=\"10\" />\n",
       "  <line x1=\"23\" y1=\"13\" x2=\"143\" y2=\"13\" />\n",
       "  <line x1=\"25\" y1=\"15\" x2=\"145\" y2=\"15\" />\n",
       "  <line x1=\"28\" y1=\"18\" x2=\"148\" y2=\"18\" />\n",
       "  <line x1=\"30\" y1=\"20\" x2=\"150\" y2=\"20\" />\n",
       "  <line x1=\"33\" y1=\"23\" x2=\"153\" y2=\"23\" />\n",
       "  <line x1=\"36\" y1=\"26\" x2=\"156\" y2=\"26\" />\n",
       "  <line x1=\"38\" y1=\"28\" x2=\"158\" y2=\"28\" />\n",
       "  <line x1=\"41\" y1=\"31\" x2=\"161\" y2=\"31\" />\n",
       "  <line x1=\"44\" y1=\"34\" x2=\"164\" y2=\"34\" />\n",
       "  <line x1=\"46\" y1=\"36\" x2=\"166\" y2=\"36\" />\n",
       "  <line x1=\"49\" y1=\"39\" x2=\"169\" y2=\"39\" />\n",
       "  <line x1=\"51\" y1=\"41\" x2=\"171\" y2=\"41\" />\n",
       "  <line x1=\"54\" y1=\"44\" x2=\"174\" y2=\"44\" />\n",
       "  <line x1=\"57\" y1=\"47\" x2=\"177\" y2=\"47\" />\n",
       "  <line x1=\"59\" y1=\"49\" x2=\"179\" y2=\"49\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"59\" y2=\"49\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"130\" y1=\"0\" x2=\"179\" y2=\"49\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 130.0,0.0 179.84666852523,49.846668525229994 59.846668525229994,49.846668525229994\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"59\" y1=\"49\" x2=\"179\" y2=\"49\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"59\" y1=\"145\" x2=\"179\" y2=\"145\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"59\" y1=\"49\" x2=\"59\" y2=\"145\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"179\" y1=\"49\" x2=\"179\" y2=\"145\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"59.846668525229994,49.846668525229994 179.84666852523,49.846668525229994 179.84666852523,145.96041260105937 59.846668525229994,145.96041260105937\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"119.846669\" y=\"165.960413\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >1688</text>\n",
       "  <text x=\"199.846669\" y=\"97.903541\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,199.846669,97.903541)\">1352</text>\n",
       "  <text x=\"24.923334\" y=\"141.037078\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,24.923334,141.037078)\">1192</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<concatenate, shape=(1192, 1352, 1688), dtype=float32, chunksize=(1, 1352, 1688), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095cd623",
   "metadata": {},
   "source": [
    "## Set cropped area of reference image to base alignment around (whole image struggles to compute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "541f1915",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1192, 500, 500)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crop_area = 500\n",
    "reference_image = reference_image[:,int((reference_image.shape[2]-crop_area)/2):int(reference_image.shape[2]-(reference_image.shape[2]-crop_area)/2),int((reference_image.shape[1]-crop_area)/2):int(reference_image.shape[1]-(reference_image.shape[1]-crop_area)/2)].compute()\n",
    "reference_image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534c5b5f",
   "metadata": {},
   "source": [
    "# Register alignment and save out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3de9f89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nathan/analysis/miniconda3/envs/cellx/lib/python3.9/site-packages/pystackreg/pystackreg.py:379: UserWarning: Detected axis 2 as the possible time axis for the stack due to its low variability, but axis 0 was supplied for registration. Are you sure you supplied the correct axis?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 34s, sys: 5.53 s, total: 2min 40s\n",
      "Wall time: 2min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create operator using transformation type (translation)\n",
    "sr = StackReg(StackReg.TRANSLATION) \n",
    "\n",
    "# register each frame to the previous as transformation matrices/tensor\n",
    "transform_tensor = sr.register_stack(reference_image, reference = 'first')\n",
    "\n",
    "# save out transform tensor\n",
    "np.save(os.path.join(root_dir, f'{expt}/{pos}/filtered_irfp_transform_tensor.npy'), transform_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "ae1b12f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1192, 3, 3)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3f8b67",
   "metadata": {},
   "source": [
    "# Apply transformation matrix to all channels and save out images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "183a2711",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning brightfield channel 1 / 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1191/1191 [01:35<00:00, 12.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning gfp channel 2 / 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1191/1191 [01:33<00:00, 12.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning rfp channel 3 / 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1191/1191 [01:31<00:00, 12.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning irfp channel 4 / 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1191/1191 [01:35<00:00, 12.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 30s, sys: 48 s, total: 6min 17s\n",
      "Wall time: 6min 16s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### iterating over channels\n",
    "# create aligned image dir if does not exist \n",
    "if not os.path.exists(os.path.join(root_dir, f'{expt}/{pos}/{pos}_filtered_aligned')):\n",
    "    os.mkdir(os.path.join(root_dir, f'{expt}/{pos}/{pos}_filtered_aligned'))\n",
    "# iterate over channels\n",
    "for channel in images.channels:\n",
    "    print('Aligning', channel.name.lower(), 'channel', channel.value+1, '/', len(images.channels))\n",
    "    #iterate over all images in channel\n",
    "    for i in tqdm(range(1, len(filtered_images[channel.name]))):\n",
    "        # load specific transform matrix for that frame\n",
    "        transform_matrix = tf.EuclideanTransform(matrix = transform_tensor[i,...],rotation = None)\n",
    "        # transform image\n",
    "        transformed_image = (tf.warp(filtered_images[channel.name][i,...], transform_matrix)*255).astype(np.uint8)\n",
    "        # set transformed image pathname by editing base dir\n",
    "        fn = images.files(channel.name)[i].replace('_raw', '_filtered_aligned')\n",
    "        # save trans image out\n",
    "        io.imsave(fn, transformed_image, check_contrast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd28bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_image = (tf.warp(filtered_images[channel.name][i,...], transform_matrix, preserve_range = True)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cd310bc",
   "metadata": {},
   "source": [
    "# check images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af516a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71ad31a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cropping: None\n",
      "Using cropping: None\n"
     ]
    }
   ],
   "source": [
    "aligned_images = DaskOctopusLiteLoader(os.path.join(root_dir, f'{expt}/{pos}/{pos}_filtered_aligned'))\n",
    "old_aligned_images = DaskOctopusLiteLoader(os.path.join(root_dir, f'{expt}/{pos}/{pos}_aligned'))\n",
    "viewer = napari.Viewer()\n",
    "for channel in aligned_images.channels:\n",
    "    if channel.name == 'IRFP':\n",
    "        viewer.add_image(aligned_images[channel.name], name = channel.name, blending = 'additive', contrast_limits = [0,255])\n",
    "        #, colormap = napari.utils.colormaps.SIMPLE_COLORMAPS.popitem()) # lazy hack to randomly generate different colormaps\n",
    "                         #, colormap = napari.utils.colormaps.SIMPLE_COLORMAPS.popitem()) # lazy hack to randomly generate different colormaps\n",
    "        viewer.add_image(old_aligned_images[channel.name], name = channel.name+'old', blending = 'additive', contrast_limits = [0,255])\n",
    "                         #, colormap = napari.utils.colormaps.SIMPLE_COLORMAPS.popitem()) # lazy hack to randomly generate different colormaps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "753378b7",
   "metadata": {},
   "source": [
    "# Troubleshooting jumpy transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dcbac05",
   "metadata": {},
   "source": [
    "# Check transform tensor for jumpy transtitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "8a2e4bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frame 1171 \n",
      " [[  1   0 -33]\n",
      " [  0   1 124]\n",
      " [  0   0   1]]\n",
      "frame 1172 \n",
      " [[  1   0 -31]\n",
      " [  0   1 125]\n",
      " [  0   0   1]]\n",
      "frame 1173 \n",
      " [[  1   0 -37]\n",
      " [  0   1 124]\n",
      " [  0   0   1]]\n",
      "frame 1174 \n",
      " [[  1   0 -32]\n",
      " [  0   1 125]\n",
      " [  0   0   1]]\n",
      "frame 1175 \n",
      " [[  1   0 -33]\n",
      " [  0   1 125]\n",
      " [  0   0   1]]\n",
      "frame 1176 \n",
      " [[  1   0 -31]\n",
      " [  0   1 125]\n",
      " [  0   0   1]]\n",
      "frame 1177 \n",
      " [[  1   0 -32]\n",
      " [  0   1 126]\n",
      " [  0   0   1]]\n",
      "frame 1178 \n",
      " [[  1   0 -37]\n",
      " [  0   1 126]\n",
      " [  0   0   1]]\n",
      "frame 1179 \n",
      " [[  1   0 -34]\n",
      " [  0   1 126]\n",
      " [  0   0   1]]\n",
      "frame 1180 \n",
      " [[  1   0 -30]\n",
      " [  0   1 127]\n",
      " [  0   0   1]]\n",
      "frame 1181 \n",
      " [[  1   0 -34]\n",
      " [  0   1 127]\n",
      " [  0   0   1]]\n",
      "frame 1182 \n",
      " [[  1   0 -34]\n",
      " [  0   1 127]\n",
      " [  0   0   1]]\n",
      "frame 1183 \n",
      " [[   1    0  -34]\n",
      " [   0    1 -128]\n",
      " [   0    0    1]]\n",
      "frame 1184 \n",
      " [[  1   0 -34]\n",
      " [  0   1 127]\n",
      " [  0   0   1]]\n",
      "frame 1185 \n",
      " [[  1   0 -34]\n",
      " [  0   1 127]\n",
      " [  0   0   1]]\n",
      "frame 1186 \n",
      " [[   1    0  -31]\n",
      " [   0    1 -128]\n",
      " [   0    0    1]]\n",
      "frame 1187 \n",
      " [[   1    0  -28]\n",
      " [   0    1 -128]\n",
      " [   0    0    1]]\n",
      "frame 1188 \n",
      " [[   1    0  -29]\n",
      " [   0    1 -128]\n",
      " [   0    0    1]]\n",
      "frame 1189 \n",
      " [[  1   0 -29]\n",
      " [  0   1 127]\n",
      " [  0   0   1]]\n",
      "frame 1190 \n",
      " [[   1    0  -29]\n",
      " [   0    1 -128]\n",
      " [   0    0    1]]\n",
      "frame 1191 \n",
      " [[  1   0 -29]\n",
      " [  0   1 127]\n",
      " [  0   0   1]]\n"
     ]
    }
   ],
   "source": [
    "for j, i in enumerate(transform_tensor):\n",
    "    if j > 1170:\n",
    "        print(\"frame\", j,'\\n', i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83af419f",
   "metadata": {},
   "source": [
    "# problematic shift at frame 1183"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "821eda60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[59, 61, 62, ..., 75, 76, 75],\n",
       "       [60, 61, 59, ..., 71, 73, 76],\n",
       "       [61, 60, 60, ..., 72, 74, 77],\n",
       "       ...,\n",
       "       [70, 71, 70, ..., 81, 86, 85],\n",
       "       [66, 68, 72, ..., 83, 87, 85],\n",
       "       [70, 70, 71, ..., 84, 87, 85]], dtype=uint8)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_image[1182]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e305fe5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[57, 60, 59, ..., 74, 70, 76],\n",
       "       [60, 62, 62, ..., 76, 74, 74],\n",
       "       [60, 61, 65, ..., 75, 71, 73],\n",
       "       ...,\n",
       "       [70, 68, 67, ..., 89, 88, 85],\n",
       "       [69, 65, 65, ..., 83, 84, 84],\n",
       "       [66, 68, 67, ..., 81, 85, 86]], dtype=uint8)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_image[1183]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "28ce64d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[61, 60, 62, ..., 72, 73, 74],\n",
       "       [56, 58, 60, ..., 74, 71, 73],\n",
       "       [60, 59, 63, ..., 70, 73, 72],\n",
       "       ...,\n",
       "       [75, 75, 77, ..., 84, 84, 86],\n",
       "       [72, 76, 74, ..., 83, 80, 89],\n",
       "       [75, 77, 76, ..., 82, 84, 82]], dtype=uint8)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_image[1184]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "31faacff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255\n",
      "50\n",
      "255\n",
      "49\n",
      "255\n",
      "50\n",
      "255\n",
      "50\n",
      "255\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "### checking raw images\n",
    "for i in range(1181, 1186):\n",
    "    print(np.amax(reference_image[i]))\n",
    "    print(np.amin(reference_image[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21535c5d",
   "metadata": {},
   "source": [
    "# Is the problematic shift a result of the stack reg, ie can i reproduce it in an individual frame by frame registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "04c85900",
   "metadata": {},
   "outputs": [],
   "source": [
    "### problematic frame\n",
    "i = 1183"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "45f1ab0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.        , -0.27052358],\n",
       "       [ 0.        ,  1.        , -0.08158292],\n",
       "       [ 0.        ,  0.        ,  1.        ]])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "StackReg(StackReg.TRANSLATION).register(reference_image[i-1], reference_image[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db898ea5",
   "metadata": {},
   "source": [
    "#### is the stack registration a cumulative measure over 1183 frames?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "5d1ff15b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1191/1191 [02:38<00:00,  7.53it/s]\n"
     ]
    }
   ],
   "source": [
    "stack_reg = []\n",
    "for i in tqdm(range(1,1192)):\n",
    "    stack_reg.append(StackReg(StackReg.TRANSLATION).register(reference_image[i-1], reference_image[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "ef295815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1191.        ,    0.        ,  -29.8818751 ],\n",
       "       [   0.        , 1191.        ,  127.99044408],\n",
       "       [   0.        ,    0.        , 1191.        ]])"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(stack_reg, axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d404306",
   "metadata": {},
   "source": [
    "# Try different transformation methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4fe2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformation matrix should take on the form\n",
    "\n",
    "#             [1 , 0 , x\n",
    "#              0 , 1 , y\n",
    "#              0 , 0 , 1]\n",
    "\n",
    "# where x and y are the translate magnitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "57fb49c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1184"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "389b6798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 1.69270859],\n",
       "       [0.        , 1.        , 0.54300491],\n",
       "       [0.        , 0.        , 1.        ]])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### float translation\n",
    "StackReg(StackReg.TRANSLATION).register(images['gfp'][i-1], images['gfp'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "8faf5856",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1],\n",
       "       [0, 1, 0],\n",
       "       [0, 0, 1]], dtype=int8)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### int translation\n",
    "StackReg(StackReg.TRANSLATION).register(images['gfp'][i-1], images['gfp'][i]).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "290f7c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.99999870e-01,  5.09415957e-04,  1.32909743e+00],\n",
       "       [-5.09415957e-04,  9.99999870e-01,  9.69781071e-01],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00]])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### float rigid body\n",
    "StackReg(StackReg.RIGID_BODY).register(images['gfp'][i-1], images['gfp'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "710e0560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  1.],\n",
       "       [-0.,  1.,  1.],\n",
       "       [ 0.,  0.,  1.]])"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### np.rint rigid body\n",
    "np.rint(StackReg(StackReg.RIGID_BODY).register(images['gfp'][i-1], images['gfp'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "6fe75192",
   "metadata": {},
   "outputs": [],
   "source": [
    "### integer-ising the matrix zeroes some important numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "d8bc82ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 1]], dtype=int8)"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### int rigidbody\n",
    "StackReg(StackReg.RIGID_BODY).register(images['gfp'][i-1], images['gfp'][i]).astype(np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "d069cb67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00010486e+00,  7.31302774e-04,  1.14884038e+00],\n",
       "       [-4.18274933e-04,  9.99898269e-01,  9.75798050e-01],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  1.00000000e+00]])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### float affine\n",
    "StackReg(StackReg.AFFINE).register(images['gfp'][i-1], images['gfp'][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "daa49c40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  0.,  1.],\n",
       "       [-0.,  1.,  1.],\n",
       "       [ 0.,  0.,  1.]])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### np.rint affine\n",
    "np.rint(StackReg(StackReg.AFFINE).register(images['gfp'][i-1], images['gfp'][i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "73cdc0a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 1],\n",
       "       [0, 0, 0],\n",
       "       [0, 0, 1]], dtype=int8)"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### int affine\n",
    "StackReg(StackReg.AFFINE).register(images['gfp'][i-1], images['gfp'][i]).astype(np.int8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f18898",
   "metadata": {},
   "source": [
    "# seems like all the alignment methods produce similar shifted outputs... is it the images?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "1eda1afd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BRIGHTFIELD [[  1   0  84]\n",
      " [  0   1 -15]\n",
      " [  0   0   1]]\n",
      "GFP [[1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]]\n",
      "RFP [[1 0 0]\n",
      " [0 1 0]\n",
      " [0 0 1]]\n",
      "IRFP [[ 1  0 -1]\n",
      " [ 0  1  0]\n",
      " [ 0  0  1]]\n"
     ]
    }
   ],
   "source": [
    "for channel in images.channels:\n",
    "    print(channel.name, StackReg(StackReg.TRANSLATION).register(images[channel.name][i-1], images[channel.name][i]).astype(np.int8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e58bb36f",
   "metadata": {},
   "source": [
    "# is it the gfp channel? checking each channel for max transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "824eaf46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting channel: BRIGHTFIELD\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1199/1199 [25:51<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BRIGHTFIELD 126\n",
      "Starting channel: GFP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1199/1199 [26:16<00:00,  1.31s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GFP 108\n",
      "Starting channel: RFP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1199/1199 [27:56<00:00,  1.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFP 47\n",
      "Starting channel: IRFP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1199/1199 [27:06<00:00,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IRFP 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trans_tensors = {}\n",
    "for channel in images.channels:\n",
    "    print('Starting channel:', channel.name)\n",
    "    trans_tensor = []\n",
    "#     for i in tqdm(range(1, len(images['gfp']))):\n",
    "#         ### create transformation matrix for i'th and i+1'th frame\n",
    "#         trans_matrix = StackReg(StackReg.TRANSLATION).register(images[channel.name][i-1], images[channel.name][i]).astype(np.int8)\n",
    "#         trans_tensor.append(trans_matrix)\n",
    "\n",
    "    trans_tensor = np.stack(trans_tensor)\n",
    "    trans_tensors[channel.name] = trans_tensor\n",
    "    print(channel.name, np.amax(trans_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3decf143",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('all_ch_trans_tensors.json', 'wb') as fp:\n",
    "    pickle.dump(trans_tensors, fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c590b2",
   "metadata": {},
   "source": [
    "# Checking the alignment tensors of each channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95971133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BRIGHTFIELD 126\n",
      "GFP 108\n",
      "RFP 47\n",
      "IRFP 24\n"
     ]
    }
   ],
   "source": [
    "for channel in trans_tensors:\n",
    "    print(channel, np.amax(trans_tensors[channel]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d928e8c7",
   "metadata": {},
   "source": [
    "# irfp channel has lowest max shift in so test run alignment on that "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7e1d3d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_tensor = trans_tensors['IRFP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c46fbee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.amax(transform_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f300630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200, 1199)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images['gfp']), len(transform_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "33ab7c90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning brightfield channel 1 / 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [01:28<00:00, 13.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning gfp channel 2 / 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [01:28<00:00, 13.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning rfp channel 3 / 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [01:26<00:00, 13.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning irfp channel 4 / 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [01:31<00:00, 13.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 11s, sys: 43.9 s, total: 5min 55s\n",
      "Wall time: 5min 54s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for channel in images.channels:\n",
    "    print('Aligning', channel.name.lower(), 'channel', channel.value+1, '/', len(images.channels))\n",
    "    #iterate over all images in channel\n",
    "    for i in tqdm(range(len(images[channel.name]))):\n",
    "        # skip dodgy frames and don't save out into aligned folder\n",
    "        if i in dodgy_frame_list or i == 1199:\n",
    "            continue\n",
    "        # load specific transform matrix for that frame\n",
    "        transform_matrix = tf.EuclideanTransform(matrix = transform_tensor[i,...],rotation = None)\n",
    "        # transform image\n",
    "        transformed_image = (tf.warp(images[channel.name][i,...], transform_matrix)*255).astype(np.uint8)\n",
    "        # set transformed image pathname by editing base dir\n",
    "        fn = images.files(channel.name)[i].replace('_raw', '_aligned')\n",
    "        # save trans image out\n",
    "        io.imsave(fn, transformed_image, check_contrast=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3aac445",
   "metadata": {},
   "source": [
    "# Batch execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63fa67c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/home/nathan/data/kraken/commitment/test/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc821c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "alignment(expt_list = ['MK0000', 'MK0001', 'MK0002', 'MK0003'], \n",
    "          max_pixel = 200, \n",
    "          min_pixel = 2, \n",
    "          crop_area = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952bbbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()\n",
    "for channel in aligned_images.channels:\n",
    "    viewer.add_image(aligned_images[channel.name], name = channel.name, blending = 'additive', contrast_limits = [0,255], colormap = napari.utils.colormaps.SIMPLE_COLORMAPS.popitem()) # lazy hack to randomly generate different colormaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eea9708c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alignment(expt_list, max_pixel, min_pixel, crop_area):\n",
    "\n",
    "    ### Iterate over all experiments defined in expt_list\n",
    "    for expt in expt_list:\n",
    "        # Find all positions in that experiment\n",
    "        pos_list = [pos for pos in os.listdir(os.path.join(root_dir, expt)) if 'Pos' in pos]\n",
    "        ### Iterate over all positions in that experiment\n",
    "        for pos in pos_list:\n",
    "            ### create new subdir of for raw files and move them all there\n",
    "            if not os.path.exists(os.path.join(root_dir, f'{expt}/{pos}/{pos}_raw')):\n",
    "                os.mkdir(os.path.join(root_dir, f'{expt}/{pos}/{pos}_raw'))\n",
    "                files = sorted(glob.glob(os.path.join(root_dir, f'{expt}/{pos}/*.tif')))\n",
    "                for file in files:\n",
    "                    os.rename(file, file.replace(f'{pos}', f'{pos}/{pos}_raw'))\n",
    "\n",
    "            ### pre load files from raw file dir \n",
    "            images = DaskOctopusLiteLoader(os.path.join(root_dir, f'{expt}/{pos}/{pos}_raw'))\n",
    "\n",
    "            ### measure mean pixel value arrays and use to find under/over-exposed frames\n",
    "            # create empty dicts and sets to store values in \n",
    "            mean_arrays = {}\n",
    "            dodgy_frame_list = set([])\n",
    "            # iterate over channels\n",
    "            for channel in tqdm(images.channels):\n",
    "                print(f'Finding mean values of {channel.name.lower()} images', pos, expt)\n",
    "                # find mean pixel values for each channel\n",
    "                mean_arrays[channel.name] = np.mean(images[channel.name], axis = (1,2)).compute() \n",
    "                # iterate over frames\n",
    "                for frame, mean_value in enumerate(mean_arrays[channel.name]):\n",
    "                    if max_pixel < mean_value or mean_value < min_pixel:\n",
    "                        # if frame does not meet inclusion criteria then add to dodgy list\n",
    "                        dodgy_frame_list.add(frame)\n",
    "            dodgy_frame_list = list(dodgy_frame_list)\n",
    "            print('Number of under/over-exposed frames:', len(dodgy_frame_list), pos, expt)\n",
    "\n",
    "            ### create aligned image dir if does not exist \n",
    "            if not os.path.exists(os.path.join(root_dir, f'{expt}/{pos}/{pos}_aligned')):\n",
    "                os.mkdir(os.path.join(root_dir, f'{expt}/{pos}/{pos}_aligned'))\n",
    "\n",
    "            ### Automatically pick reference image to perform alignment on \n",
    "            # Pick channel based on index of brightest channel from maximum mean pixel array\n",
    "            reference_channel = images.channels[max([(channel.value, np.mean(mean_arrays[channel.name])) for channel in images.channels])[0]]\n",
    "            # Define reference images\n",
    "            reference_image = images[reference_channel.name]\n",
    "            reference_image = reference_image[:,int((reference_image.shape[2]-crop_area)/2):int(reference_image.shape[2]-(reference_image.shape[2]-crop_area)/2),int((reference_image.shape[1]-crop_area)/2):int(reference_image.shape[1]-(reference_image.shape[1]-crop_area)/2)].compute()\n",
    "            reference_image.shape\n",
    "            print('Automatically selected and cropped reference image:', reference_channel.name)\n",
    "\n",
    "            ### Register alignment\n",
    "            print('Registering alignment for', pos, expt)\n",
    "            # create operator using transformation type (translation)\n",
    "            sr = StackReg(StackReg.TRANSLATION) \n",
    "            # register each frame using reference image to the previous as transformation matrices/tensor\n",
    "            transform_tensor = sr.register_stack(reference_image, reference = 'previous').astype(np.uint8)\n",
    "            # save out transform tensor\n",
    "            np.save(os.path.join(root_dir, f'{expt}/{pos}/{reference_channel.name.lower()}_transform_tensor.npy'), transform_tensor)\n",
    "\n",
    "            ### Perform alignment\n",
    "            # create aligned image dir if does not exist \n",
    "            if not os.path.exists(os.path.join(root_dir, f'{expt}/{pos}/{pos}_aligned')):\n",
    "                os.mkdir(os.path.join(root_dir, f'{expt}/{pos}/{pos}_aligned'))\n",
    "            # iterate over channels\n",
    "            for channel in images.channels:\n",
    "                print('Aligning', channel.name.lower(), 'channel', channel.value+1, '/', len(images.channels))\n",
    "                #iterate over all images in channel\n",
    "                for i in tqdm(range(len(images[channel.name]))):\n",
    "                    # skip dodgy frames and don't save out into aligned folder\n",
    "                    if i in dodgy_frame_list:\n",
    "                        continue\n",
    "                    # load specific transform matrix for that frame\n",
    "                    transform_matrix = tf.EuclideanTransform(matrix = transform_tensor[i,...],rotation = None)\n",
    "                    # transform image\n",
    "                    transformed_image = (tf.warp(images[channel.name][i,...], transform_matrix)*255).astype(np.uint8)\n",
    "                    # set transformed image pathname by editing base dir\n",
    "                    fn = images.files(channel.name)[i].replace('_raw', '_aligned')\n",
    "                    # save trans image out\n",
    "                    io.imsave(fn, transformed_image, check_contrast=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a80f5ab",
   "metadata": {},
   "source": [
    "# Repeat alignment for larger datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3af662",
   "metadata": {},
   "source": [
    "# Compile stacks and save out?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2c79b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "start()\n",
    "aligned_images = DaskOctopusLiteLoader(os.path.join(root_dir, f'{expt}/{pos}/{pos}_aligned'))\n",
    "stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CellX",
   "language": "python",
   "name": "cellx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
