{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cada0f4",
   "metadata": {},
   "source": [
    "# Object tracking using Bayesian Tracker\n",
    "\n",
    "This notebook shows how to previously localised and classified objects from a series of mask images and unite them over time using Bayesian multi-object tracking (btrack). \n",
    "\n",
    "The sections of this notebook are as follows:\n",
    "\n",
    "1. Load segmentation objects and filter based on size\n",
    "2. Run btrack, uniting the objects locations over time\n",
    "3. Batch process\n",
    "\n",
    "The data used in this notebook is timelapse microscopy data with h2b-gfp/rfp markers that show the spatial extent of the nucleus and it's mitotic state. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c311e3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import btrack\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a5906f",
   "metadata": {},
   "source": [
    "## 1. Load segmentation objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2f8f706c",
   "metadata": {},
   "outputs": [],
   "source": [
    "expt = 'ND0011'\n",
    "pos = 'Pos6'\n",
    "root_dir = '/home/nathan/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a23cce70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2022/01/27 05:10:40 PM] Opening HDF file: /home/nathan/data/ND0011/Pos6/segmented.h5...\n",
      "[INFO][2022/01/27 05:10:40 PM] Loading objects/obj_type_1 (327022, 5) (327022 filtered: None)\n",
      "[INFO][2022/01/27 05:10:45 PM] Closing HDF file: /home/nathan/data/ND0011/Pos6/segmented.h5\n"
     ]
    }
   ],
   "source": [
    "with btrack.dataio.HDF5FileHandler(\n",
    "     f'{root_dir}/{expt}/{pos}/objects.h5', 'r', obj_type='obj_type_1',\n",
    ") as hdf:\n",
    "    objects = hdf.objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ae825e9",
   "metadata": {},
   "source": [
    "Check objects feature classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6b5bcde1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>t</th>\n",
       "      <th>dummy</th>\n",
       "      <th>states</th>\n",
       "      <th>label</th>\n",
       "      <th>prob</th>\n",
       "      <th>area</th>\n",
       "      <th>prob_anaphase</th>\n",
       "      <th>prob_apoptosis</th>\n",
       "      <th>prob_interphase</th>\n",
       "      <th>prob_metaphase</th>\n",
       "      <th>prob_prometaphase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1410.627686</td>\n",
       "      <td>558.702515</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1163.0</td>\n",
       "      <td>1.724182e-10</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.999992</td>\n",
       "      <td>6.128119e-10</td>\n",
       "      <td>3.588410e-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "{'ID': 0, 'x': 1410.627685546875, 'y': 558.7025146484375, 'z': 0.0, 't': 0, 'dummy': False, 'states': 0, 'label': 0, 'prob': 0.0, 'area': 1163.0, 'prob_anaphase': 1.7241819e-10, 'prob_apoptosis': 7.640319e-06, 'prob_interphase': 0.9999923, 'prob_metaphase': 6.1281186e-10, 'prob_prometaphase': 3.58841e-09}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objects[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b1696a",
   "metadata": {},
   "source": [
    "Excluding segments that are too small to feasibly be cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "62f660dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = [o for o in objects if o.properties['area']>100.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64ac4ae",
   "metadata": {},
   "source": [
    "## 2. Run btrack  \n",
    "\n",
    "Unite each object with it's subsequent position at the following time point and export as a tracking file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb6623e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# initialise a tracker session using a context manager\n",
    "with btrack.BayesianTracker() as tracker:\n",
    "\n",
    "    # configure the tracker using a config file\n",
    "    tracker.configure_from_file(\n",
    "        './models/MDCK_config_wildtype.json'\n",
    "    )\n",
    "    tracker.max_search_radius = 40\n",
    "\n",
    "    # append the objects to be tracked\n",
    "    tracker.append(objects)\n",
    "\n",
    "    # set the volume\n",
    "    tracker.volume=((0, 1200), (0, 1600), (-1e5, 1e5))\n",
    "\n",
    "    # track them (in interactive mode)\n",
    "    tracker.track_interactive(step_size=100)\n",
    "\n",
    "    # generate hypotheses and run the global optimizer\n",
    "    tracker.optimize()\n",
    "\n",
    "    tracker.export(f'{root_dir}/{expt}/{pos}/tracks.h5', obj_type='obj_type_1')\n",
    "\n",
    "    # get the tracks in a format for napari visualization (optional)\n",
    "    visaulise_tracks, properties, graph = tracker.to_napari(ndim=2)\n",
    "    \n",
    "    tracks = tracker.tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2e10e7",
   "metadata": {},
   "source": [
    "# 3. Batch process\n",
    "Iterate over many experiments and positions (need to ensure you define normalisation and classification functions above first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae9809c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/home/nathan/data'\n",
    "expt_list = ['ND0009', 'ND0010', 'ND0011']\n",
    "pos_list = 'all'\n",
    "overwrite = False\n",
    "\n",
    "for expt in expt_list:\n",
    "    \n",
    "        # Find all positions in that experiment, if pos_list is all then it finds all positions\n",
    "        if pos_list == 'all':\n",
    "            pos_list = [pos for pos in os.listdir(f'{root_dir}/{expt}') \n",
    "                    if 'Pos' in pos \n",
    "                    and os.path.isdir(f'{root_dir}/{expt}/{pos}')]  \n",
    "            \n",
    "        ### Iterate over all positions in that experiment\n",
    "        for pos in pos_list:\n",
    "            \n",
    "            ### check if overwrite param is false check if raw directory already created and if type of transform file already exists and decide whether to skip pos\n",
    "            if not overwrite and glob.glob(f'{root_dir}/{expt}/{pos}/*tracks*.h5'):\n",
    "                print(glob.glob(f'{root_dir}/{expt}/{pos}/*tracks*.h5'), f'file found, skipping {expt}/{pos}')\n",
    "                continue\n",
    "                \n",
    "            print(f'Starting {expt}/{pos}')\n",
    "            \n",
    "            # load objects\n",
    "            with btrack.dataio.HDF5FileHandler(\n",
    "                 f'{root_dir}/{expt}/{pos}/objects.h5', 'r', obj_type='obj_type_1',\n",
    "            ) as hdf:\n",
    "                objects = hdf.objects\n",
    "            \n",
    "            # filter objects for non-cell type sizes\n",
    "            objects = [o for o in objects if o.properties['area']>100.]\n",
    "\n",
    "            # initialise a tracker session using a context manager\n",
    "            with btrack.BayesianTracker() as tracker:\n",
    "\n",
    "                # configure the tracker using a config file\n",
    "                tracker.configure_from_file(\n",
    "                    './models/MDCK_config_wildtype.json'\n",
    "                )\n",
    "                tracker.max_search_radius = 40\n",
    "\n",
    "                # append the objects to be tracked\n",
    "                tracker.append(objects)\n",
    "\n",
    "                # set the volume\n",
    "                tracker.volume=((0, 1200), (0, 1600), (-1e5, 1e5))\n",
    "\n",
    "                # track them (in interactive mode)\n",
    "                tracker.track_interactive(step_size=100)\n",
    "\n",
    "                # generate hypotheses and run the global optimizer\n",
    "                tracker.optimize()\n",
    "\n",
    "                tracker.export(f'{root_dir}/{expt}/{pos}/tracks.h5', obj_type='obj_type_1')\n",
    "                \n",
    "            print(f'Finished {expt}/{pos}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CellX",
   "language": "python",
   "name": "cellx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
