{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cada0f4",
   "metadata": {},
   "source": [
    "# Phenotype classifcation using CellX \n",
    "\n",
    "This notebook shows how to take segmented time lapse microscopy images and use h2b fluorescence markers to classfiy mitotic state of the cell cycle. \n",
    "\n",
    "The sections of this notebook are as follows:\n",
    "\n",
    "1. Load images\n",
    "2. Localise the objects\n",
    "3. Classify the objects\n",
    "4. Filter the objects\n",
    "5. Run btrack, uniting the objects locations over time\n",
    "\n",
    "The data used in this notebook is timelapse microscopy data with h2b-gfp/rfp markers that show the spatial extent of the nucleus and it's mitotic state. \n",
    "\n",
    "This notebook uses the dask octopuslite image loader from the CellX/Lowe lab project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c311e3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from octopuslite import DaskOctopusLiteLoader\n",
    "import btrack\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread, imshow\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [18,8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "907a6f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_generator(files, crop = None):\n",
    "    \"\"\"Image generator for iterative procesess\"\"\"\n",
    "    #get dims\n",
    "    shape = imread(files[0]).shape\n",
    "    dims = imread(files[0]).ndim\n",
    "    if crop == None:\n",
    "        for filename in files:\n",
    "            img = imread(filename)\n",
    "            yield img\n",
    "    else:\n",
    "        cslice = lambda d: slice(\n",
    "            int((shape[d] - crop[d]) // 2),\n",
    "            int((shape[d] - crop[d]) // 2 + crop[d]))\n",
    "        crops = tuple([cslice(d) for d in range(dims)])\n",
    "        for filename in files:\n",
    "            img = imread(filename)[crops]\n",
    "            yield img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a5906f",
   "metadata": {},
   "source": [
    "## 1. Load segmentation images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67ee9d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cropping: (1200, 1600)\n"
     ]
    }
   ],
   "source": [
    "# load images\n",
    "expt = 'ND0009'\n",
    "pos = 'Pos3'\n",
    "image_path = f'/home/nathan/data/kraken/ras/{expt}/{pos}/{pos}_stardist_masks'\n",
    "masks = DaskOctopusLiteLoader(image_path, crop=(1200,1600), remove_background=True)\n",
    "## efficiently load segmentation images by providing the path to the generator function\n",
    "segmentation_gfp = image_generator(masks.files('mask_gfp'), crop=(1200,1600))\n",
    "segmentation_rfp = image_generator(masks.files('mask_rfp'), crop=(1200,1600))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfccac2e",
   "metadata": {},
   "source": [
    "## 2. Localise the objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40600057",
   "metadata": {},
   "source": [
    "#### GFP object localisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e130c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_gfp = btrack.utils.segmentation_to_objects(\n",
    "    segmentation_gfp,\n",
    "    properties = ('area', ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a732ca0",
   "metadata": {},
   "source": [
    "#### (Optional) RFP object localisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e90cf45",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2022/01/20 01:13:59 PM] Localizing objects from segmentation...\n",
      "[INFO][2022/01/20 01:22:29 PM] Objects are of type: <class 'dict'>\n",
      "[INFO][2022/01/20 01:22:29 PM] ...Found 30102 objects in 1072 frames.\n"
     ]
    }
   ],
   "source": [
    "objects_rfp = btrack.utils.segmentation_to_objects(\n",
    "    segmentation_rfp,\n",
    "    properties = ('area', ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa49b7b",
   "metadata": {},
   "source": [
    "#### Can also assign measured values to each segment using `skimage.measure.regionprops` parameters\n",
    "But also need to load the images to be measured first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4548905",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = DaskOctopusLiteLoader(f'/home/nathan/data/kraken/ras/{expt}/{pos}/{pos}_aligned', crop = (1200,1600))\n",
    "gfp = image_generator(images.files('gfp'), crop=(1200,1600))\n",
    "objects_gfp = btrack.utils.segmentation_to_objects(\n",
    "    segmentation_gfp,\n",
    "    gfp,\n",
    "    properties = ('area', 'mean_intensity'),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc05b98",
   "metadata": {},
   "source": [
    "## 3. Classify the objects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10cd85e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellx import load_model\n",
    "from cellx.tools.image import InfinitePaddedImage\n",
    "from skimage.transform import resize\n",
    "\n",
    "model = load_model('/home/nathan/analysis/segment-classify-track/models/cellx_classifier_stardist.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bd5b60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = [\"interphase\", \"prometaphase\", \"metaphase\", \"anaphase\", \"apoptosis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92d135ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_channels(x):\n",
    "\n",
    "    for dim in range(x.shape[-1]):\n",
    "        x[..., dim] = normalize(x[..., dim])\n",
    "        \n",
    "    return x\n",
    "\n",
    "def normalize(x):\n",
    "\n",
    "    xf = x.astype(np.float32)\n",
    "    mx = np.mean(xf)\n",
    "    sd = np.max([np.std(xf), 1./np.prod(x.shape)])\n",
    "\n",
    "    return (xf - mx) / sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41184a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_objects(image, objects, obj_type=1):\n",
    "    labels = []\n",
    "    for n in tqdm(range(image.shape[0])):\n",
    "\n",
    "        _objects = [o for o in objects if o.t == n]\n",
    "\n",
    "        crops = []\n",
    "        to_update = []\n",
    "        \n",
    "        \n",
    "        fp = gfp if obj_type == 1 else rfp\n",
    "\n",
    "\n",
    "        frame = np.stack(\n",
    "            [image[n, ...].compute(), fp[n, ...].compute()], \n",
    "            axis=-1,\n",
    "        ) \n",
    "\n",
    "        vol = InfinitePaddedImage(frame, mode = 'reflect')\n",
    "\n",
    "        for obj in _objects:\n",
    "            xs = slice(int(obj.x-40), int(obj.x+40), 1)\n",
    "            ys = slice(int(obj.y-40), int(obj.y+40), 1)\n",
    "\n",
    "            crop = vol[ys, xs, :]\n",
    "            crop = resize(crop, (64, 64), preserve_range=True).astype(np.float32)\n",
    "\n",
    "            if crop.shape == (64 ,64, 2):\n",
    "                crops.append(normalize_channels(crop))\n",
    "                to_update.append(obj)\n",
    "            else:\n",
    "                print(crop.shape)\n",
    "\n",
    "        if not crops:\n",
    "            continue\n",
    "\n",
    "\n",
    "        pred = model.predict(np.stack(crops, axis=0))\n",
    "\n",
    "        assert pred.shape[0] == len(_objects)\n",
    "        for idx in range(pred.shape[0]):\n",
    "            obj = _objects[idx]\n",
    "\n",
    "            pred_label = np.argmax(pred[idx, ...])\n",
    "            pred_softmax = softmax(pred[idx, ...])\n",
    "\n",
    "            logits = {f\"prob_{k}\": pred_softmax[ki] for ki, k in enumerate(LABELS)}\n",
    "\n",
    "            obj.label = pred_label\n",
    "            obj.properties = logits\n",
    "            \n",
    "    return objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8781b4",
   "metadata": {},
   "source": [
    "#### Load raw images for classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657771d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = DaskOctopusLiteLoader(f'/home/nathan/data/kraken/ras/{expt}/{pos}/{pos}_aligned', crop = (1200,1600))\n",
    "bf = images['brightfield']\n",
    "gfp = images['gfp']\n",
    "rfp = images['rfp']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30835a86",
   "metadata": {},
   "source": [
    "#### Classify objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420e84c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_gfp = classify_objects(bf, objects_gfp, obj_type = 1)\n",
    "objects_rfp = classify_objects(bf, objects_rfp, obj_type = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70646be",
   "metadata": {},
   "source": [
    "#### Inspect objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec4f611",
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_gfp[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c5c716",
   "metadata": {},
   "source": [
    "#### Save out classified GFP objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796afd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "with btrack.dataio.HDF5FileHandler(\n",
    "    os.path.join(f'/home/nathan/data/kraken/ras/{expt}/{pos}/segmented_gfp.h5'), 'w', obj_type='obj_type_1',\n",
    ") as hdf:\n",
    "    hdf.write_segmentation(masks['mask_irfp'])\n",
    "    hdf.write_objects(objects_gfp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdb0274",
   "metadata": {},
   "source": [
    "#### Save out classified RFP objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71de0f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "with btrack.dataio.HDF5FileHandler(\n",
    "    os.path.join(f'/home/nathan/data/kraken/ras/{expt}/{pos}/segmented.h5'), 'w', obj_type='obj_type_2',\n",
    ") as hdf:\n",
    "    hdf.write_segmentation(masks['mask_rfp'])\n",
    "    hdf.write_objects(objects_rfp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b1696a",
   "metadata": {},
   "source": [
    "## 4. Filter the objects \n",
    "\n",
    "Based on segments that are too small to feasibly be cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f660dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_gfp_objects = [o for o in objects_gfp if o.properties['area']>100.]\n",
    "filtered_rfp_objects = [o for o in objects_rfp if o.properties['area']>100.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64ac4ae",
   "metadata": {},
   "source": [
    "## 5. Run btrack  \n",
    "\n",
    "Unite each object with it's subsequent position at the following time point and export as a tracking file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e456e142",
   "metadata": {},
   "source": [
    "#### For GFP objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb6623e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# initialise a tracker session using a context manager\n",
    "with btrack.BayesianTracker() as tracker:\n",
    "\n",
    "    # configure the tracker using a config file\n",
    "    tracker.configure_from_file(\n",
    "        \"/home/nathan/analysis/BayesianTracker/models/MDCK_config_new.json\"\n",
    "    )\n",
    "    tracker.max_search_radius = 40\n",
    "\n",
    "    # append the objects to be tracked\n",
    "    tracker.append(filtered_gfp_objects)\n",
    "\n",
    "    # set the volume\n",
    "    tracker.volume=((0, 1200), (0, 1600), (-1e5, 1e5))\n",
    "\n",
    "    # track them (in interactive mode)\n",
    "    tracker.track_interactive(step_size=100)\n",
    "\n",
    "    # generate hypotheses and run the global optimizer\n",
    "    tracker.optimize()\n",
    "\n",
    "    tracker.export((f'/home/nathan/data/kraken/ras/{expt}/{pos}/tracks.h5'), obj_type='obj_type_1')\n",
    "\n",
    "    # get the tracks in a format for napari visualization (optional)\n",
    "    data, properties, graph = tracker.to_napari(ndim=2)\n",
    "    \n",
    "    gfp_tracks = tracker.tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e418844",
   "metadata": {},
   "source": [
    "#### For RFP objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76bb469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise a tracker session using a context manager\n",
    "with btrack.BayesianTracker() as tracker:\n",
    "\n",
    "    # configure the tracker using a config file\n",
    "    tracker.configure_from_file(\n",
    "        \"/home/nathan/analysis/BayesianTracker/models/MDCK_config_new.json\"\n",
    "    )\n",
    "    tracker.max_search_radius = 40\n",
    "\n",
    "    # append the objects to be tracked\n",
    "    tracker.append(filtered_rfp_objects)\n",
    "\n",
    "    # set the volume\n",
    "    tracker.volume=((0, 1200), (0, 1600), (-1e5, 1e5))\n",
    "\n",
    "    # track them (in interactive mode)\n",
    "    tracker.track_interactive(step_size=100)\n",
    "\n",
    "    # generate hypotheses and run the global optimizer\n",
    "    tracker.optimize()\n",
    "\n",
    "    tracker.export((f'/home/nathan/data/kraken/ras/{expt}/{pos}/tracks.h5'), obj_type='obj_type_2')\n",
    "\n",
    "    # get the tracks in a format for napari visualization (optional)\n",
    "    data, properties, graph = tracker.to_napari(ndim=2)\n",
    "    \n",
    "    rfp_tracks = tracker.tracks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c8b6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gfp_tracks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb75fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rfp_tracks[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CellX",
   "language": "python",
   "name": "cellx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
