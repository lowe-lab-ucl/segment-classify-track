{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phenotype classifcation using CellX \n",
    "\n",
    "This notebook shows how to take segmented time lapse microscopy images and use h2b fluorescence markers to classfiy mitotic state of the cell cycle. \n",
    "\n",
    "The sections of this notebook are as follows:\n",
    "\n",
    "1. Load images\n",
    "2. Localise the objects\n",
    "3. Classify the objects\n",
    "4. Filter the objects\n",
    "5. Run btrack, uniting the objects locations over time\n",
    "\n",
    "The data used in this notebook is timelapse microscopy data with h2b-gfp/rfp markers that show the spatial extent of the nucleus and it's mitotic state. \n",
    "\n",
    "This notebook uses the dask octopuslite image loader from the CellX/Lowe lab project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from octopuslite import DaskOctopusLiteLoader\n",
    "import btrack\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread, imshow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load segmentation images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cropping: None\n"
     ]
    }
   ],
   "source": [
    "# load images\n",
    "expt = 'MK0003'\n",
    "pos = 'Pos15'\n",
    "image_path = f'/home/nathan/data/kraken/test/{expt}/{pos}/{pos}_stardist_masks'\n",
    "### dask octo loader seems to invert the background\n",
    "images = DaskOctopusLiteLoader(image_path)#, crop=(1200,1600), remove_background=False,)\n",
    "segmentation_gfp = images['mask'].compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Localise the objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2021/11/19 05:50:30 PM] Localizing objects from segmentation...\n",
      "[INFO][2021/11/19 05:50:40 PM] Objects are of type: <class 'dict'>\n",
      "[INFO][2021/11/19 05:50:41 PM] ...Found 77959 objects in 465 frames.\n"
     ]
    }
   ],
   "source": [
    "objects_gfp = btrack.utils.segmentation_to_objects(\n",
    "    segmentation_gfp,\n",
    "    properties = ('area', ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_rfp = btrack.utils.segmentation_to_objects(\n",
    "    segmentation_rfp,\n",
    "    properties = ('area', ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Classify the objects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cellx import load_model\n",
    "from cellx.tools.image import InfinitePaddedImage\n",
    "from skimage.transform import resize\n",
    "\n",
    "model = load_model('/home/nathan/analysis/cell-comp-analysis/segment-classify-track/models/cellx_classifier_stardist.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = [\"interphase\", \"prometaphase\", \"metaphase\", \"anaphase\", \"apoptosis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_channels(x):\n",
    "    for dim in range(x.shape[-1]):\n",
    "        x[..., dim] = normalize(x[..., dim])\n",
    "    return x￼\n",
    "1\n",
    "def normalize_channels(x):\n",
    "2\n",
    "    for dim in range(x.shape[-1]):\n",
    "3\n",
    "        x[..., dim] = normalize(x[..., dim])\n",
    "4\n",
    "    return x\n",
    "In [ ]:\n",
    "￼\n",
    "1\n",
    "def normalize(x):\n",
    "2\n",
    "    xf = x.astsype(np.float32)\n",
    "3\n",
    "    mx = np.mean(xf)\n",
    "4\n",
    "    sd = np.max([np.std(xf), 1./np.prod(x.shape)])\n",
    "5\n",
    "    return (xf - mx) / sd\n",
    "In [ ]:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x):\n",
    "    xf = x.astype(np.float32)\n",
    "    mx = np.mean(xf)\n",
    "    sd = np.max([np.std(xf), 1./np.prod(x.shape)])\n",
    "    return (xf - mx) / sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_objects(image, objects, obj_type=1):\n",
    "    labels = []\n",
    "    for n in tqdm(range(image.shape[0])):\n",
    "\n",
    "        _objects = [o for o in objects if o.t == n]\n",
    "\n",
    "        crops = []\n",
    "        to_update = []\n",
    "        \n",
    "        \n",
    "        fp = gfp if obj_type == 1 else rfp\n",
    "\n",
    "\n",
    "        frame = np.stack(\n",
    "            [image[n, ...].compute(), fp[n, ...].compute()], \n",
    "            axis=-1,\n",
    "        ) \n",
    "\n",
    "        vol = InfinitePaddedImage(frame)\n",
    "\n",
    "        for obj in _objects:\n",
    "            xs = slice(int(obj.x-40), int(obj.x+40), 1)\n",
    "            ys = slice(int(obj.y-40), int(obj.y+40), 1)\n",
    "\n",
    "            crop = vol[ys, xs, :]\n",
    "            crop = resize(crop, (64, 64), preserve_range=True).astype(np.float32)\n",
    "\n",
    "            if crop.shape == (64 ,64, 2):\n",
    "                crops.append(normalize_channels(crop))\n",
    "                to_update.append(obj)\n",
    "            else:\n",
    "                print(crop.shape)\n",
    "\n",
    "        if not crops:\n",
    "            continue\n",
    "\n",
    "\n",
    "        pred = model.predict(np.stack(crops, axis=0))\n",
    "\n",
    "        assert pred.shape[0] == len(_objects)\n",
    "        for idx in range(pred.shape[0]):\n",
    "            obj = _objects[idx]\n",
    "\n",
    "            pred_label = np.argmax(pred[idx, ...])\n",
    "            pred_softmax = softmax(pred[idx, ...])\n",
    "\n",
    "            logits = {f\"prob_{k}\": pred_softmax[ki] for ki, k in enumerate(LABELS)}\n",
    "\n",
    "            obj.label = pred_label\n",
    "            obj.properties = logits\n",
    "            \n",
    "    return objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cropping: (1200, 1600)\n"
     ]
    }
   ],
   "source": [
    "image = DaskOctopusLiteLoader('/home/nathan/data/kraken/test/MK0003/Pos15/Pos15_raw', crop = (1200,1600))\n",
    "bf = image['brightfield'][0:len(segmentation_gfp),...]\n",
    "gfp = image['gfp'][0:len(segmentation_gfp),...]\n",
    "rfp = image['rfp'][0:len(segmentation_gfp),...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 465/465 [09:05<00:00,  1.17s/it]\n"
     ]
    }
   ],
   "source": [
    "objects_gfp = classify_objects(bf, objects_gfp, obj_type = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2021/11/18 01:59:56 pm] Opening HDF file: /home/nathan/data/kraken/test/MK0003/Pos15/segmented.h5...\n",
      "[INFO][2021/11/18 02:00:11 pm] Writing objects/obj_type_1\n",
      "[INFO][2021/11/18 02:00:11 pm] Writing labels/obj_type_1\n",
      "[INFO][2021/11/18 02:00:11 pm] Writing properties/obj_type_1\n",
      "[INFO][2021/11/18 02:00:11 pm] Closing HDF file: /home/nathan/data/kraken/test/MK0003/Pos15/segmented.h5\n"
     ]
    }
   ],
   "source": [
    "with btrack.dataio.HDF5FileHandler(\n",
    "    os.path.join('/home/nathan/data/kraken/test/MK0003/Pos15/segmented.h5'), 'w', obj_type='obj_type_1',\n",
    ") as hdf:\n",
    "    hdf.write_segmentation(segmentation_gfp.astype(np.uint16))\n",
    "    hdf.write_objects(objects_gfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>t</th>\n",
       "      <th>dummy</th>\n",
       "      <th>states</th>\n",
       "      <th>label</th>\n",
       "      <th>prob</th>\n",
       "      <th>area</th>\n",
       "      <th>prob_interphase</th>\n",
       "      <th>prob_prometaphase</th>\n",
       "      <th>prob_metaphase</th>\n",
       "      <th>prob_anaphase</th>\n",
       "      <th>prob_apoptosis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>131.197368</td>\n",
       "      <td>477.65311</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1672</td>\n",
       "      <td>0.743234</td>\n",
       "      <td>2.535485e-07</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.256718</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "{'ID': 0, 'x': 131.19736842105263, 'y': 477.6531100478469, 'z': 0.0, 't': 0, 'dummy': False, 'states': 0, 'label': 0, 'prob': 0.0, 'area': 1672, 'prob_interphase': 0.7432343, 'prob_prometaphase': 2.535485e-07, 'prob_metaphase': 3.1620293e-05, 'prob_anaphase': 1.6020487e-05, 'prob_apoptosis': 0.25671756}"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "objects_gfp[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Filter the objects "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_objects = [o for o in objects_gfp if o.properties['area']>100.]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Run btrack  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2021/11/18 03:11:07 pm] Loaded btrack: /home/nathan/src/btrack/btrack/libs/libtracker.so\n",
      "[INFO][2021/11/18 03:11:07 pm] btrack (v0.4.2) library imported\n",
      "[INFO][2021/11/18 03:11:07 pm] Setting max XYZ search radius to: 100\n",
      "[INFO][2021/11/18 03:11:07 pm] Starting BayesianTracker session\n",
      "[INFO][2021/11/18 03:11:07 pm] Loading configuration file: /home/nathan/analysis/cell-comp-analysis/BayesianTracker/models/MDCK_config_new.json\n",
      "[INFO][2021/11/18 03:11:07 pm] Loading motion model: b'MDCK_motion_Kristina'\n",
      "[INFO][2021/11/18 03:11:07 pm] Setting max XYZ search radius to: 40\n",
      "[INFO][2021/11/18 03:11:07 pm] Objects are of type: <class 'list'>\n",
      "[INFO][2021/11/18 03:11:07 pm] Set volume to ((0, 1200), (0, 1600), (-100000.0, 100000.0))\n",
      "[INFO][2021/11/18 03:11:07 pm] Starting tracking... \n",
      "[INFO][2021/11/18 03:11:08 pm] Tracking objects in frames 0 to 99 (of 465)...\n",
      "[INFO][2021/11/18 03:11:09 pm]  - Timing (Bayesian updates: 11.48ms, Linking: 1.00ms)\n",
      "[INFO][2021/11/18 03:11:09 pm]  - Probabilities (Link: 0.99614, Lost: 1.00000)\n",
      "[INFO][2021/11/18 03:11:09 pm]  - Stats (Active: 395, Lost: 29854, Conflicts resolved: 4005)\n",
      "[INFO][2021/11/18 03:11:09 pm] Tracking objects in frames 100 to 199 (of 465)...\n",
      "[INFO][2021/11/18 03:11:11 pm]  - Timing (Bayesian updates: 24.28ms, Linking: 1.20ms)\n",
      "[INFO][2021/11/18 03:11:11 pm]  - Probabilities (Link: 0.65006, Lost: 1.00000)\n",
      "[INFO][2021/11/18 03:11:11 pm]  - Stats (Active: 460, Lost: 58540, Conflicts resolved: 8067)\n",
      "[INFO][2021/11/18 03:11:11 pm] Tracking objects in frames 200 to 299 (of 465)...\n",
      "[INFO][2021/11/18 03:11:13 pm]  - Timing (Bayesian updates: 20.03ms, Linking: 1.13ms)\n",
      "[INFO][2021/11/18 03:11:13 pm]  - Probabilities (Link: 0.68826, Lost: 0.99989)\n",
      "[INFO][2021/11/18 03:11:13 pm]  - Stats (Active: 471, Lost: 87219, Conflicts resolved: 11929)\n",
      "[INFO][2021/11/18 03:11:13 pm] Tracking objects in frames 300 to 399 (of 465)...\n",
      "[INFO][2021/11/18 03:11:15 pm]  - Timing (Bayesian updates: 13.40ms, Linking: 0.93ms)\n",
      "[INFO][2021/11/18 03:11:15 pm]  - Probabilities (Link: 0.99966, Lost: 0.99960)\n",
      "[INFO][2021/11/18 03:11:15 pm]  - Stats (Active: 412, Lost: 115829, Conflicts resolved: 15820)\n",
      "[INFO][2021/11/18 03:11:15 pm] Tracking objects in frames 400 to 465 (of 465)...\n",
      "[INFO][2021/11/18 03:11:17 pm]  - Timing (Bayesian updates: 22.98ms, Linking: 1.18ms)\n",
      "[INFO][2021/11/18 03:11:17 pm]  - Probabilities (Link: 0.97092, Lost: 1.00000)\n",
      "[INFO][2021/11/18 03:11:17 pm] SUCCESS.\n",
      "[INFO][2021/11/18 03:11:17 pm]  - Found 34349 tracks in 465 frames (in 0.0s)\n",
      "[INFO][2021/11/18 03:11:17 pm]  - Inserted 61124 dummy objects to fill tracking gaps\n",
      "[INFO][2021/11/18 03:11:17 pm] Loading hypothesis model: MDCK_hypothesis_Kristina\n",
      "[INFO][2021/11/18 03:11:17 pm] Calculating hypotheses (relax: False)...\n",
      "[INFO][2021/11/18 03:11:17 pm] Setting up constraints matrix for global optimisation...\n",
      "[INFO][2021/11/18 03:11:25 pm] Optimizing...\n",
      "[INFO][2021/11/18 03:11:26 pm] Optimization complete. (Solution: optimal)\n",
      "[INFO][2021/11/18 03:11:26 pm]  - Fates.FALSE_POSITIVE: 17817 (of 34349)\n",
      "[INFO][2021/11/18 03:11:26 pm]  - Fates.LINK: 528 (of 30523)\n",
      "[INFO][2021/11/18 03:11:26 pm]  - Fates.DIVIDE: 97 (of 15947)\n",
      "[INFO][2021/11/18 03:11:26 pm]  - Fates.APOPTOSIS: 992 (of 9963)\n",
      "[INFO][2021/11/18 03:11:26 pm]  - Fates.INITIALIZE_BORDER: 15518 (of 15717)\n",
      "[INFO][2021/11/18 03:11:26 pm]  - Fates.INITIALIZE_FRONT: 292 (of 438)\n",
      "[INFO][2021/11/18 03:11:26 pm]  - Fates.TERMINATE_BORDER: 14898 (of 15970)\n",
      "[INFO][2021/11/18 03:11:26 pm]  - Fates.TERMINATE_BACK: 17 (of 439)\n",
      "[INFO][2021/11/18 03:11:26 pm]  - TOTAL: 123346 hypotheses\n",
      "[INFO][2021/11/18 03:11:26 pm] Completed optimization with 33821 tracks\n",
      "[INFO][2021/11/18 03:11:26 pm] Opening HDF file: /home/nathan/data/kraken/test/MK0003/Pos15/tracking.h5...\n",
      "[INFO][2021/11/18 03:11:29 pm] Writing tracks/obj_type_1\n",
      "[WARNING][2021/11/18 03:11:29 pm] Removing tracks/obj_type_1.\n",
      "[INFO][2021/11/18 03:11:29 pm] Writing dummies/obj_type_1\n",
      "[INFO][2021/11/18 03:11:29 pm] Writing LBEP/obj_type_1\n",
      "[INFO][2021/11/18 03:11:29 pm] Writing fates/obj_type_1\n",
      "[INFO][2021/11/18 03:11:30 pm] Closing HDF file: /home/nathan/data/kraken/test/MK0003/Pos15/tracking.h5\n",
      "[INFO][2021/11/18 03:11:34 pm] Ending BayesianTracker session\n"
     ]
    }
   ],
   "source": [
    "# initialise a tracker session using a context manager\n",
    "with btrack.BayesianTracker() as tracker:\n",
    "\n",
    "    # configure the tracker using a config file\n",
    "    tracker.configure_from_file(\n",
    "        \"/home/nathan/analysis/cell-comp-analysis/BayesianTracker/models/MDCK_config_new.json\"\n",
    "    )\n",
    "    tracker.max_search_radius = 40\n",
    "\n",
    "    # append the objects to be tracked\n",
    "    tracker.append(filtered_objects)\n",
    "\n",
    "    # set the volume\n",
    "    tracker.volume=((0, 1200), (0, 1600), (-1e5, 1e5))\n",
    "\n",
    "    # track them (in interactive mode)\n",
    "    tracker.track_interactive(step_size=100)\n",
    "\n",
    "    # generate hypotheses and run the global optimizer\n",
    "    tracker.optimize()\n",
    "\n",
    "    tracker.export(('/home/nathan/data/kraken/test/MK0003/Pos15/tracking.h5'), obj_type='obj_type_1')\n",
    "\n",
    "    # get the tracks in a format for napari visualization\n",
    "    data, properties, graph = tracker.to_napari(ndim=2)\n",
    "    \n",
    "    tracks = tracker.tracks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
