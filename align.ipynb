{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "127b5eb3",
   "metadata": {},
   "source": [
    "# Align and remove under/overexposed images\n",
    "\n",
    "Adapted from Giulia Vallardi's ImageJ macro, this notebook removes any under/overexposed frames from timelapse experiments and aligns the images. \n",
    "\n",
    "The structure of this notebook is:\n",
    "\n",
    "1. Find images, organise containing directory as a 'raw images' folder and load using the octopuslite dask loader.\n",
    "2. Find over/underexposed images by measuring each channel and frame for average pixel intensity.\n",
    "3. Select a reference channel to center the alignment on\n",
    "4. Register alignment and save out transformation tensor\n",
    "5. Apply transformation matrix to all channels and save out images\n",
    "6. Check images using Napari\n",
    "7. Function to iterate over many experiments, many positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7859805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import enum\n",
    "import numpy as np\n",
    "from pystackreg import StackReg\n",
    "from skimage import io\n",
    "from tqdm import tqdm\n",
    "from octopuslite import DaskOctopusLiteLoader\n",
    "from skimage import transform as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b349a8a0",
   "metadata": {},
   "source": [
    "## 1. Find images, organise and load using octopuslite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbeda8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### define root directory and specific experiment and location\n",
    "root_dir = '/home/nathan/data/kraken/ras/'\n",
    "expt = \"ND0009\"\n",
    "pos = \"Pos2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1a5cbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "### create new subdir of for raw files and move them all there\n",
    "if not os.path.exists(os.path.join(root_dir, f'{expt}/{pos}/{pos}_raw')):\n",
    "    os.mkdir(os.path.join(root_dir, f'{expt}/{pos}/{pos}_raw'))\n",
    "    files = sorted(glob.glob(os.path.join(root_dir, f'{expt}/{pos}/*.tif')))\n",
    "    for file in files:\n",
    "        os.rename(file, file.replace(f'{pos}', f'{pos}/{pos}_raw'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a3d0870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cropping: None\n"
     ]
    }
   ],
   "source": [
    "### pre load files from raw file dir \n",
    "images = DaskOctopusLiteLoader(os.path.join(root_dir, f'{expt}/{pos}/{pos}_raw'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4314a4",
   "metadata": {},
   "source": [
    "## 2. Identify under/overexposed images and display average channel brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d11d5f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding mean values of image channels: 100%|██████████| 4/4 [02:30<00:00, 37.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of under/over-exposed frames: 19\n",
      "CPU times: user 20.5 s, sys: 8.18 s, total: 28.6 s\n",
      "Wall time: 2min 30s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# pixel range criteria\n",
    "max_pixel, min_pixel = 200, 2\n",
    "# set empty dict arrays for mean values \n",
    "mean_arrays = {}\n",
    "# set for dodgy frames (only unique entries)\n",
    "dodgy_frame_list = set([])\n",
    "#iterate over channels\n",
    "for channel in tqdm(images.channels, desc = f'Finding mean values of image channels'):\n",
    "    # find mean value of each frame in each channel\n",
    "    mean_arrays[channel.name] = np.mean(images[channel.name], axis = (1,2)).compute() \n",
    "    # iterate over frames\n",
    "    for frame, mean_value in enumerate(mean_arrays[channel.name]):\n",
    "        # check to see if mean frame pixel value meets criteria\n",
    "        if max_pixel < mean_value or mean_value < min_pixel:\n",
    "            # if so add to delete list\n",
    "            dodgy_frame_list.add(frame)\n",
    "# format delete list\n",
    "dodgy_frame_list = list(dodgy_frame_list)\n",
    "print('Number of under/over-exposed frames:', len(dodgy_frame_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e5e9f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[129,\n",
       " 905,\n",
       " 277,\n",
       " 548,\n",
       " 1068,\n",
       " 433,\n",
       " 437,\n",
       " 193,\n",
       " 578,\n",
       " 709,\n",
       " 968,\n",
       " 714,\n",
       " 203,\n",
       " 79,\n",
       " 101,\n",
       " 492,\n",
       " 1010,\n",
       " 376,\n",
       " 1017]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dodgy_frame_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96062b83",
   "metadata": {},
   "source": [
    "#### 2a. Filtering to remove blank or overexposed frames from image array and mean value arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a63933d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_images= {}\n",
    "for channel in images.channels:\n",
    "    filtered_images[channel.name] = np.delete(images[channel], dodgy_frame_list, axis = 0)\n",
    "    mean_arrays[channel.name] = np.delete(mean_arrays[channel.name], dodgy_frame_list, axis = 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c94938b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BRIGHTFIELD': dask.array<concatenate, shape=(1067, 1352, 1688), dtype=float32, chunksize=(1, 1352, 1688), chunktype=numpy.ndarray>,\n",
       " 'GFP': dask.array<concatenate, shape=(1067, 1352, 1688), dtype=float32, chunksize=(1, 1352, 1688), chunktype=numpy.ndarray>,\n",
       " 'RFP': dask.array<concatenate, shape=(1067, 1352, 1688), dtype=float32, chunksize=(1, 1352, 1688), chunktype=numpy.ndarray>,\n",
       " 'IRFP': dask.array<concatenate, shape=(1067, 1352, 1688), dtype=float32, chunksize=(1, 1352, 1688), chunktype=numpy.ndarray>}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6686782",
   "metadata": {},
   "source": [
    "## 3. Select reference image to base alignment around\n",
    "\n",
    "The automatically-measured brightest channel isn't necessarily the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8011e037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average channel brightness for selection of reference image:\n",
      "0: BRIGHTFIELD: 18.4342\n",
      "1: GFP: 64.47778\n",
      "2: RFP: 4.023584\n",
      "3: IRFP: 66.592766\n"
     ]
    }
   ],
   "source": [
    "print('Average channel brightness for selection of reference image:')\n",
    "for channel in images.channels:\n",
    "    print(f'{channel.value}: {channel.name}:', np.mean(mean_arrays[channel.name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e83d0329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GFP'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manually select reference channel by adding index\n",
    "reference_channel = images.channels[1]\n",
    "# automatically select reference channel from max average pixel value (ie. brightest channel)\n",
    "#reference_channel = images.channels[max([(channel.value, np.mean(mean_arrays[channel.name])) for channel in images.channels])[0]]\n",
    "reference_image = filtered_images[reference_channel.name]\n",
    "reference_channel.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b286dc16",
   "metadata": {},
   "source": [
    "#### 3a. Set cropped area of reference image to base alignment around \n",
    "Optional step as alignment struggles on 1200 frame (1353,1682) pixel images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5215fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1067, 1108, 1200)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crop_area = 1200\n",
    "# crop central window out of reference image\n",
    "reference_image = reference_image[:,int((reference_image.shape[2]-crop_area)//2)\n",
    "                                  :int(reference_image.shape[2]-(reference_image.shape[2]-crop_area)/2),\n",
    "                                  int((reference_image.shape[1]-crop_area)/2)\n",
    "                                  :int(reference_image.shape[1]-(reference_image.shape[1]-crop_area)/2)].compute()\n",
    "# if not cropping you still need to load image into memory\n",
    "#reference_image = reference_image.compute()\n",
    "reference_image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466ad46f",
   "metadata": {},
   "source": [
    "## 4. Register alignment and save out transformation tensor\n",
    "Transformation tensor is a 3D series of transformation matrices over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59ebe809",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nathan/analysis/miniconda3/envs/cellx/lib/python3.9/site-packages/pystackreg/pystackreg.py:379: UserWarning: Detected axis 2 as the possible time axis for the stack due to its low variability, but axis 0 was supplied for registration. Are you sure you supplied the correct axis?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12min 4s, sys: 1min 23s, total: 13min 27s\n",
      "Wall time: 13min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create operator using transformation type (translation)\n",
    "sr = StackReg(StackReg.TRANSLATION) \n",
    "\n",
    "# register each frame to the previous as transformation matrices/tensor\n",
    "transform_tensor = sr.register_stack(reference_image, reference = 'previous')\n",
    "\n",
    "# save out transform tensor\n",
    "np.save(os.path.join(root_dir, f'{expt}/{pos}/{reference_channel.name.lower()}_transform_tensor.npy'), transform_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c5c334e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1067, 3, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d310e7d",
   "metadata": {},
   "source": [
    "## 5. Apply transformation matrix to all channels and save out images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ae81366",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aligning brightfield channel 1/4: 100%|██████████| 1067/1067 [02:46<00:00,  6.42it/s]\n",
      "Aligning gfp channel 2/4: 100%|██████████| 1067/1067 [02:48<00:00,  6.32it/s]\n",
      "Aligning rfp channel 3/4: 100%|██████████| 1067/1067 [03:06<00:00,  5.72it/s]\n",
      "Aligning irfp channel 4/4: 100%|██████████| 1067/1067 [03:04<00:00,  5.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 24s, sys: 51.4 s, total: 6min 15s\n",
      "Wall time: 11min 45s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### iterating over channels\n",
    "# create aligned image dir if does not exist \n",
    "if not os.path.exists(os.path.join(root_dir, f'{expt}/{pos}/{pos}_aligned')):\n",
    "    os.mkdir(os.path.join(root_dir, f'{expt}/{pos}/{pos}_aligned'))\n",
    "# iterate over channels\n",
    "for channel in images.channels:\n",
    "    #iterate over all images in channel\n",
    "    for i in tqdm(range(len(transform_tensor)), desc = f'Aligning {channel.name.lower()} channel {channel.value+1}/{len(images.channels)}'):#filtered_images[channel.name]))):\n",
    "        # load specific transform matrix for that frame\n",
    "        transform_matrix = tf.EuclideanTransform(matrix = transform_tensor[i,...],rotation = None)\n",
    "        # transform image\n",
    "        transformed_image = (tf.warp(filtered_images[channel.name][i,...].compute(), transform_matrix, preserve_range=True)).astype(np.uint8)\n",
    "        # set transformed image pathname by editing base dir\n",
    "        fn = images.files(channel.name)[i].replace('_raw', '_aligned')\n",
    "        # save trans image out\n",
    "        io.imsave(fn, transformed_image, check_contrast=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918491e2",
   "metadata": {},
   "source": [
    "## 6. Check alignment using Napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "262a10b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "866e356b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cropping: None\n"
     ]
    }
   ],
   "source": [
    "aligned_images = DaskOctopusLiteLoader(os.path.join(root_dir, f'{expt}/{pos}/{pos}_aligned'))#, crop = (1200,1600), remove_background=False)\n",
    "\n",
    "viewer = napari.Viewer()\n",
    "for channel in aligned_images.channels:\n",
    "    #if channel.name == 'IRFP':\n",
    "    viewer.add_image(aligned_images[channel.name], name = channel.name, blending = 'additive', contrast_limits = [0,255])\n",
    "                     #, colormap = napari.utils.colormaps.SIMPLE_COLORMAPS.popitem()) # lazy hack to randomly generate different colormaps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3aac445",
   "metadata": {},
   "source": [
    "## Batch execute\n",
    "\n",
    "Do all of the above but for many experiment IDs and many positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "63fa67c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/home/nathan/data/kraken/ras/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5fc821c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cropping: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding mean values of image channels: 100%|██████████| 4/4 [02:52<00:00, 43.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of under/over-exposed frames: 15\n",
      "Automatically selected and cropped reference image: GFP\n",
      "Registering alignment for Pos5 ND0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aligning brightfield channel 1/4: 100%|██████████| 1185/1185 [03:27<00:00,  5.72it/s]\n",
      "Aligning gfp channel 2/4: 100%|██████████| 1185/1185 [03:08<00:00,  6.27it/s]\n",
      "Aligning rfp channel 3/4: 100%|██████████| 1185/1185 [03:29<00:00,  5.66it/s]\n",
      "Aligning irfp channel 4/4: 100%|██████████| 1185/1185 [03:38<00:00,  5.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cropping: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding mean values of image channels: 100%|██████████| 4/4 [03:15<00:00, 48.87s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of under/over-exposed frames: 4\n",
      "Automatically selected and cropped reference image: GFP\n",
      "Registering alignment for Pos11 ND0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nathan/analysis/miniconda3/envs/cellx/lib/python3.9/site-packages/pystackreg/pystackreg.py:379: UserWarning: Detected axis 2 as the possible time axis for the stack due to its low variability, but axis 0 was supplied for registration. Are you sure you supplied the correct axis?\n",
      "  warnings.warn(\n",
      "Aligning brightfield channel 1/4: 100%|██████████| 1196/1196 [01:20<00:00, 14.85it/s]\n",
      "Aligning gfp channel 2/4: 100%|██████████| 1196/1196 [03:18<00:00,  6.01it/s]\n",
      "Aligning rfp channel 3/4: 100%|██████████| 1196/1196 [03:35<00:00,  5.55it/s]\n",
      "Aligning irfp channel 4/4: 100%|██████████| 1196/1196 [03:35<00:00,  5.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cropping: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding mean values of image channels: 100%|██████████| 4/4 [03:56<00:00, 59.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of under/over-exposed frames: 11\n",
      "Automatically selected and cropped reference image: GFP\n",
      "Registering alignment for Pos3 ND0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nathan/analysis/miniconda3/envs/cellx/lib/python3.9/site-packages/pystackreg/pystackreg.py:379: UserWarning: Detected axis 2 as the possible time axis for the stack due to its low variability, but axis 0 was supplied for registration. Are you sure you supplied the correct axis?\n",
      "  warnings.warn(\n",
      "Aligning brightfield channel 1/4: 100%|██████████| 1189/1189 [01:27<00:00, 13.64it/s]\n",
      "Aligning gfp channel 2/4: 100%|██████████| 1189/1189 [01:27<00:00, 13.65it/s]\n",
      "Aligning rfp channel 3/4: 100%|██████████| 1189/1189 [03:04<00:00,  6.45it/s]\n",
      "Aligning irfp channel 4/4: 100%|██████████| 1189/1189 [03:14<00:00,  6.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cropping: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding mean values of image channels: 100%|██████████| 4/4 [03:59<00:00, 59.88s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of under/over-exposed frames: 11\n",
      "Automatically selected and cropped reference image: GFP\n",
      "Registering alignment for Pos1 ND0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aligning brightfield channel 1/4: 100%|██████████| 1189/1189 [01:26<00:00, 13.75it/s]\n",
      "Aligning gfp channel 2/4: 100%|██████████| 1189/1189 [01:28<00:00, 13.39it/s]\n",
      "Aligning rfp channel 3/4: 100%|██████████| 1189/1189 [01:24<00:00, 14.01it/s]\n",
      "Aligning irfp channel 4/4: 100%|██████████| 1189/1189 [02:36<00:00,  7.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cropping: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding mean values of image channels: 100%|██████████| 4/4 [03:35<00:00, 53.81s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of under/over-exposed frames: 17\n",
      "Automatically selected and cropped reference image: GFP\n",
      "Registering alignment for Pos8 ND0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aligning brightfield channel 1/4: 100%|██████████| 1183/1183 [01:25<00:00, 13.85it/s]\n",
      "Aligning gfp channel 2/4: 100%|██████████| 1183/1183 [01:27<00:00, 13.55it/s]\n",
      "Aligning rfp channel 3/4: 100%|██████████| 1183/1183 [01:35<00:00, 12.34it/s]\n",
      "Aligning irfp channel 4/4: 100%|██████████| 1183/1183 [02:17<00:00,  8.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cropping: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding mean values of image channels: 100%|██████████| 4/4 [03:39<00:00, 54.95s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of under/over-exposed frames: 9\n",
      "Automatically selected and cropped reference image: GFP\n",
      "Registering alignment for Pos10 ND0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nathan/analysis/miniconda3/envs/cellx/lib/python3.9/site-packages/pystackreg/pystackreg.py:379: UserWarning: Detected axis 1 as the possible time axis for the stack due to its low variability, but axis 0 was supplied for registration. Are you sure you supplied the correct axis?\n",
      "  warnings.warn(\n",
      "Aligning brightfield channel 1/4: 100%|██████████| 1191/1191 [01:50<00:00, 10.74it/s]\n",
      "Aligning gfp channel 2/4: 100%|██████████| 1191/1191 [02:07<00:00,  9.31it/s]\n",
      "Aligning rfp channel 3/4: 100%|██████████| 1191/1191 [02:41<00:00,  7.39it/s]\n",
      "Aligning irfp channel 4/4: 100%|██████████| 1191/1191 [02:01<00:00,  9.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cropping: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding mean values of image channels: 100%|██████████| 4/4 [02:47<00:00, 41.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of under/over-exposed frames: 9\n",
      "Automatically selected and cropped reference image: GFP\n",
      "Registering alignment for Pos0 ND0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nathan/analysis/miniconda3/envs/cellx/lib/python3.9/site-packages/pystackreg/pystackreg.py:379: UserWarning: Detected axis 2 as the possible time axis for the stack due to its low variability, but axis 0 was supplied for registration. Are you sure you supplied the correct axis?\n",
      "  warnings.warn(\n",
      "Aligning brightfield channel 1/4: 100%|██████████| 1191/1191 [01:25<00:00, 13.85it/s]\n",
      "Aligning gfp channel 2/4: 100%|██████████| 1191/1191 [01:59<00:00,  9.95it/s]\n",
      "Aligning rfp channel 3/4: 100%|██████████| 1191/1191 [02:43<00:00,  7.27it/s]\n",
      "Aligning irfp channel 4/4: 100%|██████████| 1191/1191 [03:20<00:00,  5.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cropping: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding mean values of image channels: 100%|██████████| 4/4 [03:51<00:00, 57.94s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of under/over-exposed frames: 9\n",
      "Automatically selected and cropped reference image: GFP\n",
      "Registering alignment for Pos2 ND0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nathan/analysis/miniconda3/envs/cellx/lib/python3.9/site-packages/pystackreg/pystackreg.py:379: UserWarning: Detected axis 2 as the possible time axis for the stack due to its low variability, but axis 0 was supplied for registration. Are you sure you supplied the correct axis?\n",
      "  warnings.warn(\n",
      "Aligning brightfield channel 1/4: 100%|██████████| 1191/1191 [01:24<00:00, 14.16it/s]\n",
      "Aligning gfp channel 2/4: 100%|██████████| 1191/1191 [01:25<00:00, 13.86it/s]\n",
      "Aligning rfp channel 3/4: 100%|██████████| 1191/1191 [01:24<00:00, 14.08it/s]\n",
      "Aligning irfp channel 4/4: 100%|██████████| 1191/1191 [02:10<00:00,  9.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cropping: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding mean values of image channels: 100%|██████████| 4/4 [03:21<00:00, 50.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of under/over-exposed frames: 14\n",
      "Automatically selected and cropped reference image: GFP\n",
      "Registering alignment for Pos6 ND0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nathan/analysis/miniconda3/envs/cellx/lib/python3.9/site-packages/pystackreg/pystackreg.py:379: UserWarning: Detected axis 1 as the possible time axis for the stack due to its low variability, but axis 0 was supplied for registration. Are you sure you supplied the correct axis?\n",
      "  warnings.warn(\n",
      "Aligning brightfield channel 1/4: 100%|██████████| 1186/1186 [01:23<00:00, 14.19it/s]\n",
      "Aligning gfp channel 2/4: 100%|██████████| 1186/1186 [01:24<00:00, 14.05it/s]\n",
      "Aligning rfp channel 3/4: 100%|██████████| 1186/1186 [03:02<00:00,  6.51it/s]\n",
      "Aligning irfp channel 4/4: 100%|██████████| 1186/1186 [02:30<00:00,  7.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cropping: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding mean values of image channels: 100%|██████████| 4/4 [02:49<00:00, 42.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of under/over-exposed frames: 7\n",
      "Automatically selected and cropped reference image: GFP\n",
      "Registering alignment for Pos7 ND0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aligning brightfield channel 1/4: 100%|██████████| 1193/1193 [01:24<00:00, 14.14it/s]\n",
      "Aligning gfp channel 2/4: 100%|██████████| 1193/1193 [01:24<00:00, 14.05it/s]\n",
      "Aligning rfp channel 3/4: 100%|██████████| 1193/1193 [01:58<00:00, 10.08it/s]\n",
      "Aligning irfp channel 4/4: 100%|██████████| 1193/1193 [02:22<00:00,  8.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cropping: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding mean values of image channels: 100%|██████████| 4/4 [04:02<00:00, 60.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of under/over-exposed frames: 12\n",
      "Automatically selected and cropped reference image: GFP\n",
      "Registering alignment for Pos9 ND0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nathan/analysis/miniconda3/envs/cellx/lib/python3.9/site-packages/pystackreg/pystackreg.py:379: UserWarning: Detected axis 1 as the possible time axis for the stack due to its low variability, but axis 0 was supplied for registration. Are you sure you supplied the correct axis?\n",
      "  warnings.warn(\n",
      "Aligning brightfield channel 1/4: 100%|██████████| 1188/1188 [01:23<00:00, 14.16it/s]\n",
      "Aligning gfp channel 2/4: 100%|██████████| 1188/1188 [01:43<00:00, 11.52it/s]\n",
      "Aligning rfp channel 3/4: 100%|██████████| 1188/1188 [02:46<00:00,  7.14it/s]\n",
      "Aligning irfp channel 4/4: 100%|██████████| 1188/1188 [02:29<00:00,  7.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cropping: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding mean values of image channels: 100%|██████████| 4/4 [02:45<00:00, 41.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of under/over-exposed frames: 16\n",
      "Automatically selected and cropped reference image: GFP\n",
      "Registering alignment for Pos4 ND0006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aligning brightfield channel 1/4: 100%|██████████| 1184/1184 [01:26<00:00, 13.74it/s]\n",
      "Aligning gfp channel 2/4: 100%|██████████| 1184/1184 [01:45<00:00, 11.24it/s]\n",
      "Aligning rfp channel 3/4: 100%|██████████| 1184/1184 [02:37<00:00,  7.53it/s]\n",
      "Aligning irfp channel 4/4: 100%|██████████| 1184/1184 [02:24<00:00,  8.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cropping: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding mean values of image channels: 100%|██████████| 4/4 [03:25<00:00, 51.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of under/over-exposed frames: 10\n",
      "Automatically selected and cropped reference image: GFP\n",
      "Registering alignment for Pos13 ND0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aligning brightfield channel 1/4: 100%|██████████| 1190/1190 [01:32<00:00, 12.92it/s]\n",
      "Aligning gfp channel 2/4: 100%|██████████| 1190/1190 [01:48<00:00, 11.01it/s]\n",
      "Aligning rfp channel 3/4: 100%|██████████| 1190/1190 [02:54<00:00,  6.81it/s]\n",
      "Aligning irfp channel 4/4: 100%|██████████| 1190/1190 [02:43<00:00,  7.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cropping: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding mean values of image channels: 100%|██████████| 4/4 [03:16<00:00, 49.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of under/over-exposed frames: 9\n",
      "Automatically selected and cropped reference image: GFP\n",
      "Registering alignment for Pos5 ND0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aligning brightfield channel 1/4: 100%|██████████| 1191/1191 [01:32<00:00, 12.92it/s]\n",
      "Aligning gfp channel 2/4: 100%|██████████| 1191/1191 [02:14<00:00,  8.84it/s]\n",
      "Aligning rfp channel 3/4: 100%|██████████| 1191/1191 [02:37<00:00,  7.54it/s]\n",
      "Aligning irfp channel 4/4: 100%|██████████| 1191/1191 [03:16<00:00,  6.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cropping: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding mean values of image channels: 100%|██████████| 4/4 [03:17<00:00, 49.40s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of under/over-exposed frames: 11\n",
      "Automatically selected and cropped reference image: GFP\n",
      "Registering alignment for Pos11 ND0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aligning brightfield channel 1/4: 100%|██████████| 1189/1189 [01:21<00:00, 14.60it/s]\n",
      "Aligning gfp channel 2/4: 100%|██████████| 1189/1189 [01:29<00:00, 13.35it/s]\n",
      "Aligning rfp channel 3/4: 100%|██████████| 1189/1189 [02:28<00:00,  8.02it/s]\n",
      "Aligning irfp channel 4/4: 100%|██████████| 1189/1189 [02:42<00:00,  7.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cropping: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding mean values of image channels: 100%|██████████| 4/4 [03:28<00:00, 52.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of under/over-exposed frames: 13\n",
      "Automatically selected and cropped reference image: GFP\n",
      "Registering alignment for Pos14 ND0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aligning brightfield channel 1/4: 100%|██████████| 1187/1187 [01:23<00:00, 14.22it/s]\n",
      "Aligning gfp channel 2/4: 100%|██████████| 1187/1187 [01:24<00:00, 13.97it/s]\n",
      "Aligning rfp channel 3/4: 100%|██████████| 1187/1187 [01:53<00:00, 10.42it/s]\n",
      "Aligning irfp channel 4/4: 100%|██████████| 1187/1187 [02:22<00:00,  8.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cropping: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding mean values of image channels: 100%|██████████| 4/4 [03:18<00:00, 49.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of under/over-exposed frames: 10\n",
      "Automatically selected and cropped reference image: GFP\n",
      "Registering alignment for Pos15 ND0001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aligning brightfield channel 1/4: 100%|██████████| 1190/1190 [01:24<00:00, 14.11it/s]\n",
      "Aligning gfp channel 2/4: 100%|██████████| 1190/1190 [02:00<00:00,  9.88it/s]\n",
      "Aligning rfp channel 3/4: 100%|██████████| 1190/1190 [02:48<00:00,  7.07it/s]\n",
      "Aligning irfp channel 4/4: 100%|██████████| 1190/1190 [03:15<00:00,  6.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cropping: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding mean values of image channels: 100%|██████████| 4/4 [03:17<00:00, 49.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of under/over-exposed frames: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/nathan/analysis/miniconda3/envs/cellx/lib/python3.9/site-packages/IPython/core/magics/execution.py\", line 1313, in time\n",
      "    out = eval(code, glob, local_ns)\n",
      "  File \"<timed eval>\", line 1, in <module>\n",
      "  File \"<ipython-input-17-c808f0592021>\", line 52, in alignment\n",
      "    reference_image = reference_image[:,int((reference_image.shape[2]-crop_area)/2):int(reference_image.shape[2]-(reference_image.shape[2]-crop_area)/2),int((reference_image.shape[1]-crop_area)/2):int(reference_image.shape[1]-(reference_image.shape[1]-crop_area)/2)].compute()\n",
      "  File \"/home/nathan/analysis/miniconda3/envs/cellx/lib/python3.9/site-packages/dask/base.py\", line 288, in compute\n",
      "    (result,) = compute(self, traverse=False, **kwargs)\n",
      "  File \"/home/nathan/analysis/miniconda3/envs/cellx/lib/python3.9/site-packages/dask/base.py\", line 570, in compute\n",
      "    results = schedule(dsk, keys, **kwargs)\n",
      "  File \"/home/nathan/analysis/miniconda3/envs/cellx/lib/python3.9/site-packages/dask/threaded.py\", line 79, in get\n",
      "    results = get_async(\n",
      "  File \"/home/nathan/analysis/miniconda3/envs/cellx/lib/python3.9/site-packages/dask/local.py\", line 506, in get_async\n",
      "    for key, res_info, failed in queue_get(queue).result():\n",
      "  File \"/home/nathan/analysis/miniconda3/envs/cellx/lib/python3.9/site-packages/dask/local.py\", line 134, in queue_get\n",
      "    return q.get()\n",
      "  File \"/home/nathan/analysis/miniconda3/envs/cellx/lib/python3.9/queue.py\", line 171, in get\n",
      "    self.not_empty.wait()\n",
      "  File \"/home/nathan/analysis/miniconda3/envs/cellx/lib/python3.9/threading.py\", line 312, in wait\n",
      "    waiter.acquire()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nathan/analysis/miniconda3/envs/cellx/lib/python3.9/site-packages/IPython/core/interactiveshell.py\", line 2061, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nathan/analysis/miniconda3/envs/cellx/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/nathan/analysis/miniconda3/envs/cellx/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/nathan/analysis/miniconda3/envs/cellx/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/nathan/analysis/miniconda3/envs/cellx/lib/python3.9/inspect.py\", line 1541, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/nathan/analysis/miniconda3/envs/cellx/lib/python3.9/inspect.py\", line 1503, in getframeinfo\n",
      "    lines, lnum = findsource(frame)\n",
      "  File \"/home/nathan/analysis/miniconda3/envs/cellx/lib/python3.9/site-packages/IPython/core/ultratb.py\", line 182, in findsource\n",
      "    lines = linecache.getlines(file, globals_dict)\n",
      "  File \"/home/nathan/analysis/miniconda3/envs/cellx/lib/python3.9/linecache.py\", line 46, in getlines\n",
      "    return updatecache(filename, module_globals)\n",
      "  File \"/home/nathan/analysis/miniconda3/envs/cellx/lib/python3.9/linecache.py\", line 137, in updatecache\n",
      "    lines = fp.readlines()\n",
      "  File \"/home/nathan/analysis/miniconda3/envs/cellx/lib/python3.9/codecs.py\", line 319, in decode\n",
      "    def decode(self, input, final=False):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/analysis/miniconda3/envs/cellx/lib/python3.9/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1312\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1313\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1314\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-c808f0592021>\u001b[0m in \u001b[0;36malignment\u001b[0;34m(root_dir, expt_list, max_pixel, min_pixel, crop_area)\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mreference_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiltered_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mreference_channel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0mreference_image\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreference_image\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mcrop_area\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mcrop_area\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mcrop_area\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreference_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mcrop_area\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m             \u001b[0mreference_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/analysis/miniconda3/envs/cellx/lib/python3.9/site-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    287\u001b[0m         \"\"\"\n\u001b[0;32m--> 288\u001b[0;31m         \u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraverse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/analysis/miniconda3/envs/cellx/lib/python3.9/site-packages/dask/base.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    569\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 570\u001b[0;31m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    571\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrepack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpostcomputes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/analysis/miniconda3/envs/cellx/lib/python3.9/site-packages/dask/threaded.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(dsk, result, cache, num_workers, pool, **kwargs)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     results = get_async(\n\u001b[0m\u001b[1;32m     80\u001b[0m         \u001b[0mpool\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubmit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/analysis/miniconda3/envs/cellx/lib/python3.9/site-packages/dask/local.py\u001b[0m in \u001b[0;36mget_async\u001b[0;34m(submit, num_workers, dsk, result, cache, get_id, rerun_exceptions_locally, pack_exception, raise_exception, callbacks, dumps, loads, chunksize, **kwargs)\u001b[0m\n\u001b[1;32m    505\u001b[0m                 \u001b[0mfire_tasks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m                 \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_info\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfailed\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mqueue_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqueue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    507\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfailed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/analysis/miniconda3/envs/cellx/lib/python3.9/site-packages/dask/local.py\u001b[0m in \u001b[0;36mqueue_get\u001b[0;34m(q)\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mqueue_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/analysis/miniconda3/envs/cellx/lib/python3.9/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    170\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_qsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/analysis/miniconda3/envs/cellx/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    311\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 312\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    313\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/analysis/miniconda3/envs/cellx/lib/python3.9/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2060\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2061\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2062\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-1ccb798908e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"alignment(root_dir,\\n          expt_list = ['ND0006', 'ND0001', 'ND0002', 'ND0003', 'ND0004', 'ND0000'],\\n          max_pixel = 200, \\n          min_pixel = 2, \\n          crop_area = 500)\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/analysis/miniconda3/envs/cellx/lib/python3.9/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2401\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2402\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2403\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2404\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/analysis/miniconda3/envs/cellx/lib/python3.9/site-packages/decorator.py\u001b[0m in \u001b[0;36mfun\u001b[0;34m(*args, **kw)\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mkwsyntax\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 232\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcaller\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextras\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    233\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[0mfun\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/analysis/miniconda3/envs/cellx/lib/python3.9/site-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/analysis/miniconda3/envs/cellx/lib/python3.9/site-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1313\u001b[0m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1315\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1316\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1317\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/analysis/miniconda3/envs/cellx/lib/python3.9/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2061\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2062\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2063\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2064\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2065\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/analysis/miniconda3/envs/cellx/lib/python3.9/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/analysis/miniconda3/envs/cellx/lib/python3.9/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
      "\u001b[0;32m~/analysis/miniconda3/envs/cellx/lib/python3.9/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/analysis/miniconda3/envs/cellx/lib/python3.9/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/analysis/miniconda3/envs/cellx/lib/python3.9/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "alignment(root_dir,\n",
    "          expt_list = ['ND0006', 'ND0001', 'ND0002', 'ND0003', 'ND0004', 'ND0000'],\n",
    "          max_pixel = 200, \n",
    "          min_pixel = 2, \n",
    "          crop_area = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952bbbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()\n",
    "for channel in aligned_images.channels:\n",
    "    viewer.add_image(aligned_images[channel.name], name = channel.name, blending = 'additive', contrast_limits = [0,255], colormap = napari.utils.colormaps.SIMPLE_COLORMAPS.popitem()) # lazy hack to randomly generate different colormaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eea9708c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alignment(root_dir, expt_list, max_pixel, min_pixel, crop_area):\n",
    "\n",
    "    ### Iterate over all experiments defined in expt_list\n",
    "    for expt in expt_list:\n",
    "        # Find all positions in that experiment\n",
    "        pos_list = [pos for pos in os.listdir(os.path.join(root_dir, expt)) if 'Pos' in pos]\n",
    "        ### Iterate over all positions in that experiment\n",
    "        for pos in pos_list:\n",
    "            ### create new subdir of for raw files and move them all there\n",
    "            if not os.path.exists(os.path.join(root_dir, f'{expt}/{pos}/{pos}_raw')):\n",
    "                os.mkdir(os.path.join(root_dir, f'{expt}/{pos}/{pos}_raw'))\n",
    "                files = sorted(glob.glob(os.path.join(root_dir, f'{expt}/{pos}/*.tif')))\n",
    "                for file in files:\n",
    "                    os.rename(file, file.replace(f'{pos}', f'{pos}/{pos}_raw'))\n",
    "\n",
    "            ### pre load files from raw file dir \n",
    "            images = DaskOctopusLiteLoader(os.path.join(root_dir, f'{expt}/{pos}/{pos}_raw'))\n",
    "\n",
    "            ### measure mean pixel value arrays and use to find under/over-exposed frames\n",
    "            # set empty dict arrays for mean values \n",
    "            mean_arrays = {}\n",
    "            # set for dodgy frames (only unique entries)\n",
    "            dodgy_frame_list = set([])\n",
    "            #iterate over channels\n",
    "            for channel in tqdm(images.channels, desc = f'Finding mean values of image channels'):\n",
    "                # find mean value of each frame in each channel\n",
    "                mean_arrays[channel.name] = np.mean(images[channel.name], axis = (1,2)).compute() \n",
    "                # iterate over frames\n",
    "                for frame, mean_value in enumerate(mean_arrays[channel.name]):\n",
    "                    # check to see if mean frame pixel value meets criteria\n",
    "                    if max_pixel < mean_value or mean_value < min_pixel:\n",
    "                        # if so add to delete list\n",
    "                        dodgy_frame_list.add(frame)\n",
    "            # format delete list\n",
    "            dodgy_frame_list = list(dodgy_frame_list)\n",
    "            print('Number of under/over-exposed frames:', len(dodgy_frame_list))\n",
    "\n",
    "            # create new image dicts with dodgy frames removed\n",
    "            filtered_images= {}\n",
    "            for channel in images.channels:\n",
    "                # delete dodgy frames from images and mean value arrays\n",
    "                filtered_images[channel.name] = np.delete(images[channel], dodgy_frame_list, axis = 0)\n",
    "                mean_arrays[channel.name] = np.delete(mean_arrays[channel.name], dodgy_frame_list, axis = 0) \n",
    "            \n",
    "            ### Automatically pick reference image to perform alignment on \n",
    "            # Pick gfp channel\n",
    "            reference_channel = images.channels[1]\n",
    "            # Pick channel based on index of brightest channel from maximum mean pixel array\n",
    "            #reference_channel = images.channels[max([(channel.value, np.mean(mean_arrays[channel.name])) for channel in images.channels])[0]]\n",
    "            # Define reference images\n",
    "            reference_image = filtered_images[reference_channel.name]\n",
    "            reference_image = reference_image[:,int((reference_image.shape[2]-crop_area)/2):int(reference_image.shape[2]-(reference_image.shape[2]-crop_area)/2),int((reference_image.shape[1]-crop_area)/2):int(reference_image.shape[1]-(reference_image.shape[1]-crop_area)/2)].compute()\n",
    "            reference_image.shape\n",
    "            print('Automatically selected and cropped reference image:', reference_channel.name)\n",
    "\n",
    "            ### Register alignment\n",
    "            print('Registering alignment for', pos, expt)\n",
    "            # create operator using transformation type (translation)\n",
    "            sr = StackReg(StackReg.TRANSLATION) \n",
    "            # register each frame to the previous as transformation matrices/tensor\n",
    "            transform_tensor = sr.register_stack(reference_image, reference = 'previous')\n",
    "            # save out transform tensor\n",
    "            np.save(os.path.join(root_dir, f'{expt}/{pos}/{reference_channel.name.lower()}_transform_tensor.npy'), transform_tensor)\n",
    "            \n",
    "            ### Perform alignment\n",
    "            # create aligned image dir if does not exist \n",
    "            if not os.path.exists(os.path.join(root_dir, f'{expt}/{pos}/{pos}_aligned')):\n",
    "                os.mkdir(os.path.join(root_dir, f'{expt}/{pos}/{pos}_aligned'))\n",
    "            # iterate over channels\n",
    "            for channel in images.channels:\n",
    "                #iterate over all images in channel\n",
    "                for i in tqdm(range(len(transform_tensor)), desc = f'Aligning {channel.name.lower()} channel {channel.value+1}/{len(images.channels)}'):#filtered_images[channel.name]))):\n",
    "                    # load specific transform matrix for that frame\n",
    "                    transform_matrix = tf.EuclideanTransform(matrix = transform_tensor[i,...],rotation = None)\n",
    "                    # transform image\n",
    "                    transformed_image = (tf.warp(filtered_images[channel.name][i,...].compute(), transform_matrix, preserve_range=True)).astype(np.uint8)\n",
    "                    # set transformed image pathname by editing base dir\n",
    "                    fn = images.files(channel.name)[i].replace('_raw', '_aligned')\n",
    "                    # save trans image out\n",
    "                    io.imsave(fn, transformed_image, check_contrast=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CellX",
   "language": "python",
   "name": "cellx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
