{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "127b5eb3",
   "metadata": {},
   "source": [
    "# Align and remove blanks\n",
    "\n",
    "Adapted from Giulia Vallardi's ImageJ macro, this notebook removes any blank frames from timelapse experiments and aligns the images. \n",
    "\n",
    "\"Fiji macro to remove over- and under-exposed images, and align the image stacks\n",
    "\n",
    "The settings for the alignments are: \n",
    "registration by Translation > only modify XY coordinates\n",
    "Shrinkage constrain activated (this model allows a better registration based on all images, not using a reference image. It is more time consuming though)\n",
    "Transform matrices are saved during registration and then applied to the other channels during transformation.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa19f60e",
   "metadata": {},
   "source": [
    "# to - do: decide how to import dask octopus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "20b37ccd",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'octopuslite'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e4d1dcca6c3d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0moctopuslite\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'octopuslite'"
     ]
    }
   ],
   "source": [
    "import octopuslite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7859805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import enum\n",
    "import numpy as np\n",
    "from pystackreg import StackReg\n",
    "from skimage import io\n",
    "from tqdm import tqdm\n",
    "from daskoctopus import DaskOctopusLiteLoader\n",
    "from skimage import transform as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b349a8a0",
   "metadata": {},
   "source": [
    "# Find images, organise into raw folder and load using dask octo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbeda8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### define root directory and specific experiment and location (will later make iterable)\n",
    "root_dir = '/home/nathan/data/kraken/commitment/test/'\n",
    "expt = \"MK0003\"\n",
    "pos = \"Pos1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1a5cbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "### create new subdir of for raw files and move them all there\n",
    "if not os.path.exists(os.path.join(root_dir, f'{expt}/{pos}/{pos}_raw')):\n",
    "    os.mkdir(os.path.join(root_dir, f'{expt}/{pos}/{pos}_raw'))\n",
    "    files = sorted(glob.glob(os.path.join(root_dir, f'{expt}/{pos}/*.tif')))\n",
    "    for file in files:\n",
    "        os.rename(file, file.replace(f'{pos}', f'{pos}/{pos}_raw'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a3d0870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cropping: None\n"
     ]
    }
   ],
   "source": [
    "### pre load files from raw file dir \n",
    "images = DaskOctopusLiteLoader(os.path.join(root_dir, f'{expt}/{pos}/{pos}_raw'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4314a4",
   "metadata": {},
   "source": [
    "# Find blank or overexposed images and display average channel brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d11d5f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cropping: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding mean values of brightfield images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 1/4 [00:03<00:09,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding mean values of gfp images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 2/4 [00:06<00:06,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding mean values of rfp images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 3/4 [00:09<00:03,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding mean values of irfp images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:12<00:00,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of under/over-exposed frames: 8\n",
      "CPU times: user 27.1 s, sys: 6.09 s, total: 33.2 s\n",
      "Wall time: 13.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# pixel range criteria\n",
    "max_pixel, min_pixel = 200, 2\n",
    "\n",
    "### find mean values ### pre load files from raw file dir \n",
    "images = DaskOctopusLiteLoader(os.path.join(root_dir, f'{expt}/{pos}/{pos}_raw'))\n",
    "\n",
    "mean_arrays = {}\n",
    "dodgy_frame_list = set([])\n",
    "for channel in tqdm(images.channels):\n",
    "    print(f'Finding mean values of {channel.name.lower()} images')\n",
    "    mean_arrays[channel.name] = np.mean(images[channel.name], axis = (1,2)).compute() \n",
    "    for frame, mean_value in enumerate(mean_arrays[channel.name]):\n",
    "        if max_pixel < mean_value or mean_value < min_pixel:\n",
    "            dodgy_frame_list.add(frame)\n",
    "dodgy_frame_list = list(dodgy_frame_list)\n",
    "\n",
    "print('Number of under/over-exposed frames:', len(dodgy_frame_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6686782",
   "metadata": {},
   "source": [
    "# Select reference image to base alignment around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8011e037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average channel brightness for selection of reference image:\n",
      "0: BRIGHTFIELD: 28.949467\n",
      "1: GFP: 62.79905\n",
      "2: RFP: 6.4401646\n",
      "3: IRFP: 76.01225\n"
     ]
    }
   ],
   "source": [
    "print('Average channel brightness for selection of reference image:')\n",
    "for channel in images.channels:\n",
    "    print(f'{channel.value}: {channel.name}:', np.mean(mean_arrays[channel.name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e83d0329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GFP'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manually select reference channel by adding index\n",
    "reference_channel = images.channels[1]\n",
    "# automatically select reference channel from max average pixel value (ie. brightest channel)\n",
    "#reference_channel = images.channels[max([(channel.value, np.mean(mean_arrays[channel.name])) for channel in images.channels])[0]]\n",
    "reference_image = images[reference_channel.name]\n",
    "reference_channel.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b286dc16",
   "metadata": {},
   "source": [
    "## Set cropped area of reference image to base alignment around (whole image struggles to compute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e5215fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200, 500, 500)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crop_area = 500\n",
    "reference_image = reference_image[:,int((reference_image.shape[2]-crop_area)/2):int(reference_image.shape[2]-(reference_image.shape[2]-crop_area)/2),int((reference_image.shape[1]-crop_area)/2):int(reference_image.shape[1]-(reference_image.shape[1]-crop_area)/2)].compute()\n",
    "reference_image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466ad46f",
   "metadata": {},
   "source": [
    "# Register alignment and save out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59ebe809",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nathan/analysis/miniconda3/envs/cellx/lib/python3.9/site-packages/pystackreg/pystackreg.py:379: UserWarning: Detected axis 1 as the possible time axis for the stack due to its low variability, but axis 0 was supplied for registration. Are you sure you supplied the correct axis?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 23min 39s, sys: 2min 19s, total: 25min 58s\n",
      "Wall time: 25min 56s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create operator using transformation type (translation)\n",
    "sr = StackReg(StackReg.TRANSLATION) \n",
    "\n",
    "# register each frame to the previous as transformation matrices/tensor\n",
    "transform_tensor = sr.register_stack(reference_image, reference = 'previous').astype(np.int8)\n",
    "\n",
    "# save out transform tensor\n",
    "np.save(os.path.join(root_dir, f'{expt}/{pos}/{reference_channel.name.lower()}_transform_tensor.npy'), transform_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c5c334e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200, 3, 3)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d310e7d",
   "metadata": {},
   "source": [
    "# Apply transformation matrix to all channels and save out images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ae81366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning brightfield channel 1 / 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [02:27<00:00,  8.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning gfp channel 2 / 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [02:21<00:00,  8.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning rfp channel 3 / 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [02:19<00:00,  8.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning irfp channel 4 / 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1200/1200 [02:23<00:00,  8.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 26s, sys: 16.4 s, total: 6min 43s\n",
      "Wall time: 9min 32s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### iterating over channels\n",
    "# create aligned image dir if does not exist \n",
    "if not os.path.exists(os.path.join(root_dir, f'{expt}/{pos}/{pos}_aligned')):\n",
    "    os.mkdir(os.path.join(root_dir, f'{expt}/{pos}/{pos}_aligned'))\n",
    "# iterate over channels\n",
    "for channel in images.channels:\n",
    "    print('Aligning', channel.name.lower(), 'channel', channel.value+1, '/', len(images.channels))\n",
    "    #iterate over all images in channel\n",
    "    for i in tqdm(range(len(images[channel.name]))):\n",
    "        # skip dodgy frames and don't save out into aligned folder\n",
    "        if i in dodgy_frame_list:\n",
    "            continue\n",
    "        # load specific transform matrix for that frame\n",
    "        transform_matrix = tf.EuclideanTransform(matrix = transform_tensor[i,...],rotation = None)\n",
    "        # transform image\n",
    "        transformed_image = (tf.warp(images[channel.name][i,...], transform_matrix)*255).astype(np.uint8)\n",
    "        # set transformed image pathname by editing base dir\n",
    "        fn = images.files(channel.name)[i].replace('_raw', '_aligned')\n",
    "        # save trans image out\n",
    "        io.imsave(fn, transformed_image, check_contrast=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918491e2",
   "metadata": {},
   "source": [
    "# Check alignment using Napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "262a10b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "866e356b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cropping: None\n"
     ]
    }
   ],
   "source": [
    "aligned_images = DaskOctopusLiteLoader(os.path.join(root_dir, f'{expt}/{pos}/{pos}_aligned'))\n",
    "\n",
    "viewer = napari.Viewer()\n",
    "for channel in aligned_images.channels:\n",
    "    viewer.add_image(aligned_images[channel.name], name = channel.name, blending = 'additive', contrast_limits = [0,255])\n",
    "                     #, colormap = napari.utils.colormaps.SIMPLE_COLORMAPS.popitem()) # lazy hack to randomly generate different colormaps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3aac445",
   "metadata": {},
   "source": [
    "# Batch execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "63fa67c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/home/nathan/data/kraken/commitment/test/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc821c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "alignment(expt_list = ['MK0000', 'MK0001', 'MK0002', 'MK0003'], \n",
    "          max_pixel = 200, \n",
    "          min_pixel = 2, \n",
    "          crop_area = 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952bbbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()\n",
    "for channel in aligned_images.channels:\n",
    "    viewer.add_image(aligned_images[channel.name], name = channel.name, blending = 'additive', contrast_limits = [0,255], colormap = napari.utils.colormaps.SIMPLE_COLORMAPS.popitem()) # lazy hack to randomly generate different colormaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eea9708c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alignment(expt_list, max_pixel, min_pixel, crop_area):\n",
    "\n",
    "    ### Iterate over all experiments defined in expt_list\n",
    "    for expt in expt_list:\n",
    "        # Find all positions in that experiment\n",
    "        pos_list = [pos for pos in os.listdir(os.path.join(root_dir, expt)) if 'Pos' in pos]\n",
    "        ### Iterate over all positions in that experiment\n",
    "        for pos in pos_list:\n",
    "            ### create new subdir of for raw files and move them all there\n",
    "            if not os.path.exists(os.path.join(root_dir, f'{expt}/{pos}/{pos}_raw')):\n",
    "                os.mkdir(os.path.join(root_dir, f'{expt}/{pos}/{pos}_raw'))\n",
    "                files = sorted(glob.glob(os.path.join(root_dir, f'{expt}/{pos}/*.tif')))\n",
    "                for file in files:\n",
    "                    os.rename(file, file.replace(f'{pos}', f'{pos}/{pos}_raw'))\n",
    "\n",
    "            ### pre load files from raw file dir \n",
    "            images = DaskOctopusLiteLoader(os.path.join(root_dir, f'{expt}/{pos}/{pos}_raw'))\n",
    "\n",
    "            ### measure mean pixel value arrays and use to find under/over-exposed frames\n",
    "            # create empty dicts and sets to store values in \n",
    "            mean_arrays = {}\n",
    "            dodgy_frame_list = set([])\n",
    "            # iterate over channels\n",
    "            for channel in tqdm(images.channels):\n",
    "                print(f'Finding mean values of {channel.name.lower()} images', pos, expt)\n",
    "                # find mean pixel values for each channel\n",
    "                mean_arrays[channel.name] = np.mean(images[channel.name], axis = (1,2)).compute() \n",
    "                # iterate over frames\n",
    "                for frame, mean_value in enumerate(mean_arrays[channel.name]):\n",
    "                    if max_pixel < mean_value or mean_value < min_pixel:\n",
    "                        # if frame does not meet inclusion criteria then add to dodgy list\n",
    "                        dodgy_frame_list.add(frame)\n",
    "            dodgy_frame_list = list(dodgy_frame_list)\n",
    "            print('Number of under/over-exposed frames:', len(dodgy_frame_list), pos, expt)\n",
    "\n",
    "            ### create aligned image dir if does not exist \n",
    "            if not os.path.exists(os.path.join(root_dir, f'{expt}/{pos}/{pos}_aligned')):\n",
    "                os.mkdir(os.path.join(root_dir, f'{expt}/{pos}/{pos}_aligned'))\n",
    "\n",
    "            ### Automatically pick reference image to perform alignment on \n",
    "            # Pick channel based on index of brightest channel from maximum mean pixel array\n",
    "            reference_channel = images.channels[max([(channel.value, np.mean(mean_arrays[channel.name])) for channel in images.channels])[0]]\n",
    "            # Define reference images\n",
    "            reference_image = images[reference_channel.name]\n",
    "            reference_image = reference_image[:,int((reference_image.shape[2]-crop_area)/2):int(reference_image.shape[2]-(reference_image.shape[2]-crop_area)/2),int((reference_image.shape[1]-crop_area)/2):int(reference_image.shape[1]-(reference_image.shape[1]-crop_area)/2)].compute()\n",
    "            reference_image.shape\n",
    "            print('Automatically selected and cropped reference image:', reference_channel.name)\n",
    "\n",
    "            ### Register alignment\n",
    "            print('Registering alignment for', pos, expt)\n",
    "            # create operator using transformation type (translation)\n",
    "            sr = StackReg(StackReg.TRANSLATION) \n",
    "            # register each frame using reference image to the previous as transformation matrices/tensor\n",
    "            transform_tensor = sr.register_stack(reference_image, reference = 'previous').astype(np.uint8)\n",
    "            # save out transform tensor\n",
    "            np.save(os.path.join(root_dir, f'{expt}/{pos}/{reference_channel.name.lower()}_transform_tensor.npy'), transform_tensor)\n",
    "\n",
    "            ### Perform alignment\n",
    "            # create aligned image dir if does not exist \n",
    "            if not os.path.exists(os.path.join(root_dir, f'{expt}/{pos}/{pos}_aligned')):\n",
    "                os.mkdir(os.path.join(root_dir, f'{expt}/{pos}/{pos}_aligned'))\n",
    "            # iterate over channels\n",
    "            for channel in images.channels:\n",
    "                print('Aligning', channel.name.lower(), 'channel', channel.value+1, '/', len(images.channels))\n",
    "                #iterate over all images in channel\n",
    "                for i in tqdm(range(len(images[channel.name]))):\n",
    "                    # skip dodgy frames and don't save out into aligned folder\n",
    "                    if i in dodgy_frame_list:\n",
    "                        continue\n",
    "                    # load specific transform matrix for that frame\n",
    "                    transform_matrix = tf.EuclideanTransform(matrix = transform_tensor[i,...],rotation = None)\n",
    "                    # transform image\n",
    "                    transformed_image = (tf.warp(images[channel.name][i,...], transform_matrix)*255).astype(np.uint8)\n",
    "                    # set transformed image pathname by editing base dir\n",
    "                    fn = images.files(channel.name)[i].replace('_raw', '_aligned')\n",
    "                    # save trans image out\n",
    "                    io.imsave(fn, transformed_image, check_contrast=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3af662",
   "metadata": {},
   "source": [
    "# Compile stacks and save out?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2c79b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "start()\n",
    "aligned_images = DaskOctopusLiteLoader(os.path.join(root_dir, f'{expt}/{pos}/{pos}_aligned'))\n",
    "stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CellX",
   "language": "python",
   "name": "cellx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
