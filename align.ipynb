{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "127b5eb3",
   "metadata": {},
   "source": [
    "# Align and remove under/overexposed images\n",
    "\n",
    "Adapted from Giulia Vallardi's ImageJ macro, this notebook removes any under/overexposed frames from timelapse experiments and aligns the images. \n",
    "\n",
    "The structure of this notebook is:\n",
    "\n",
    "1. Find images, organise containing directory as a 'raw images' folder and load using the octopuslite dask loader.\n",
    "2. Find over/underexposed images by measuring each channel and frame for average pixel intensity.\n",
    "3. Select a reference channel to center the alignment on\n",
    "4. Register alignment and save out transformation tensor\n",
    "5. Apply transformation matrix to all channels and save out images\n",
    "6. Check images using Napari\n",
    "7. Function to iterate over many experiments, many positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7859805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import enum\n",
    "import numpy as np\n",
    "from pystackreg import StackReg\n",
    "from skimage import io\n",
    "from tqdm import tqdm\n",
    "from octopuslite import DaskOctopusLiteLoader\n",
    "from skimage import transform as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b349a8a0",
   "metadata": {},
   "source": [
    "## 1. Find images, organise and load using octopuslite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbeda8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "### define root directory and specific experiment and location\n",
    "root_dir = '/home/nathan/data/kraken/ras/'\n",
    "expt = \"ND0009\"\n",
    "pos = \"Pos2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1a5cbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "### create new subdir of for raw files and move them all there\n",
    "if not os.path.exists(os.path.join(root_dir, f'{expt}/{pos}/{pos}_raw')):\n",
    "    os.mkdir(os.path.join(root_dir, f'{expt}/{pos}/{pos}_raw'))\n",
    "    files = sorted(glob.glob(os.path.join(root_dir, f'{expt}/{pos}/*.tif')))\n",
    "    for file in files:\n",
    "        os.rename(file, file.replace(f'{pos}', f'{pos}/{pos}_raw'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a3d0870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cropping: None\n"
     ]
    }
   ],
   "source": [
    "### pre load files from raw file dir \n",
    "images = DaskOctopusLiteLoader(os.path.join(root_dir, f'{expt}/{pos}/{pos}_raw'), remove_background = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4314a4",
   "metadata": {},
   "source": [
    "## 2. Identify under/overexposed images and display average channel brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d11d5f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding mean values of image channels: 100%|██████████| 4/4 [02:30<00:00, 37.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of under/over-exposed frames: 19\n",
      "CPU times: user 20.5 s, sys: 8.18 s, total: 28.6 s\n",
      "Wall time: 2min 30s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# pixel range criteria\n",
    "max_pixel, min_pixel = 200, 2\n",
    "# set empty dict arrays for mean values \n",
    "mean_arrays = {}\n",
    "# set for dodgy frames (only unique entries)\n",
    "dodgy_frame_list = set([])\n",
    "#iterate over channels\n",
    "for channel in tqdm(images.channels, desc = f'Finding mean values of image channels'):\n",
    "    # find mean value of each frame in each channel\n",
    "    mean_arrays[channel.name] = np.mean(images[channel.name], axis = (1,2)).compute() \n",
    "    # iterate over frames\n",
    "    for frame, mean_value in enumerate(mean_arrays[channel.name]):\n",
    "        # check to see if mean frame pixel value meets criteria\n",
    "        if max_pixel < mean_value or mean_value < min_pixel:\n",
    "            # if so add to delete list\n",
    "            dodgy_frame_list.add(frame)\n",
    "# format delete list\n",
    "dodgy_frame_list = list(dodgy_frame_list)\n",
    "print('Number of under/over-exposed frames:', len(dodgy_frame_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e5e9f27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[129,\n",
       " 905,\n",
       " 277,\n",
       " 548,\n",
       " 1068,\n",
       " 433,\n",
       " 437,\n",
       " 193,\n",
       " 578,\n",
       " 709,\n",
       " 968,\n",
       " 714,\n",
       " 203,\n",
       " 79,\n",
       " 101,\n",
       " 492,\n",
       " 1010,\n",
       " 376,\n",
       " 1017]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dodgy_frame_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96062b83",
   "metadata": {},
   "source": [
    "#### 2a. Filtering to remove blank or overexposed frames from image array and mean value arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a63933d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_images= {}\n",
    "for channel in images.channels:\n",
    "    filtered_images[channel.name] = np.delete(images[channel], dodgy_frame_list, axis = 0)\n",
    "    mean_arrays[channel.name] = np.delete(mean_arrays[channel.name], dodgy_frame_list, axis = 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2c94938b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BRIGHTFIELD': dask.array<concatenate, shape=(1067, 1352, 1688), dtype=float32, chunksize=(1, 1352, 1688), chunktype=numpy.ndarray>,\n",
       " 'GFP': dask.array<concatenate, shape=(1067, 1352, 1688), dtype=float32, chunksize=(1, 1352, 1688), chunktype=numpy.ndarray>,\n",
       " 'RFP': dask.array<concatenate, shape=(1067, 1352, 1688), dtype=float32, chunksize=(1, 1352, 1688), chunktype=numpy.ndarray>,\n",
       " 'IRFP': dask.array<concatenate, shape=(1067, 1352, 1688), dtype=float32, chunksize=(1, 1352, 1688), chunktype=numpy.ndarray>}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6686782",
   "metadata": {},
   "source": [
    "## 3. Select reference image to base alignment around\n",
    "\n",
    "The automatically-measured brightest channel isn't necessarily the best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8011e037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average channel brightness for selection of reference image:\n",
      "0: BRIGHTFIELD: 18.4342\n",
      "1: GFP: 64.47778\n",
      "2: RFP: 4.023584\n",
      "3: IRFP: 66.592766\n"
     ]
    }
   ],
   "source": [
    "print('Average channel brightness for selection of reference image:')\n",
    "for channel in images.channels:\n",
    "    print(f'{channel.value}: {channel.name}:', np.mean(mean_arrays[channel.name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e83d0329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GFP'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manually select reference channel by adding index\n",
    "reference_channel = images.channels[1]\n",
    "# automatically select reference channel from max average pixel value (ie. brightest channel)\n",
    "#reference_channel = images.channels[max([(channel.value, np.mean(mean_arrays[channel.name])) for channel in images.channels])[0]]\n",
    "reference_image = filtered_images[reference_channel.name]\n",
    "reference_channel.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b286dc16",
   "metadata": {},
   "source": [
    "#### 3a. Set cropped area of reference image to base alignment around \n",
    "Optional step as alignment struggles on 1200 frame (1353,1682) pixel images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5215fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1067, 1108, 1200)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crop_area = 1200\n",
    "# crop central window out of reference image\n",
    "reference_image = reference_image[:,int((reference_image.shape[2]-crop_area)//2)\n",
    "                                  :int(reference_image.shape[2]-(reference_image.shape[2]-crop_area)/2),\n",
    "                                  int((reference_image.shape[1]-crop_area)/2)\n",
    "                                  :int(reference_image.shape[1]-(reference_image.shape[1]-crop_area)/2)].compute()\n",
    "# if not cropping you still need to load image into memory\n",
    "#reference_image = reference_image.compute()\n",
    "reference_image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466ad46f",
   "metadata": {},
   "source": [
    "## 4. Register alignment and save out transformation tensor\n",
    "Transformation tensor is a 3D series of transformation matrices over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59ebe809",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nathan/analysis/miniconda3/envs/cellx/lib/python3.9/site-packages/pystackreg/pystackreg.py:379: UserWarning: Detected axis 2 as the possible time axis for the stack due to its low variability, but axis 0 was supplied for registration. Are you sure you supplied the correct axis?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12min 4s, sys: 1min 23s, total: 13min 27s\n",
      "Wall time: 13min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create operator using transformation type (translation)\n",
    "sr = StackReg(StackReg.TRANSLATION) \n",
    "\n",
    "# register each frame to the previous as transformation matrices/tensor\n",
    "transform_tensor = sr.register_stack(reference_image, reference = 'previous')\n",
    "\n",
    "# save out transform tensor\n",
    "np.save(os.path.join(root_dir, f'{expt}/{pos}/{reference_channel.name.lower()}_transform_tensor.npy'), transform_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8c5c334e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1067, 3, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d310e7d",
   "metadata": {},
   "source": [
    "## 5. Apply transformation matrix to all channels and save out images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ae81366",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aligning brightfield channel 1/4: 100%|██████████| 1067/1067 [02:46<00:00,  6.42it/s]\n",
      "Aligning gfp channel 2/4: 100%|██████████| 1067/1067 [02:48<00:00,  6.32it/s]\n",
      "Aligning rfp channel 3/4: 100%|██████████| 1067/1067 [03:06<00:00,  5.72it/s]\n",
      "Aligning irfp channel 4/4: 100%|██████████| 1067/1067 [03:04<00:00,  5.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 24s, sys: 51.4 s, total: 6min 15s\n",
      "Wall time: 11min 45s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### iterating over channels\n",
    "# create aligned image dir if does not exist \n",
    "if not os.path.exists(os.path.join(root_dir, f'{expt}/{pos}/{pos}_aligned')):\n",
    "    os.mkdir(os.path.join(root_dir, f'{expt}/{pos}/{pos}_aligned'))\n",
    "# iterate over channels\n",
    "for channel in images.channels:\n",
    "    #iterate over all images in channel\n",
    "    for i in tqdm(range(len(transform_tensor)), desc = f'Aligning {channel.name.lower()} channel {channel.value+1}/{len(images.channels)}'):#filtered_images[channel.name]))):\n",
    "        # load specific transform matrix for that frame\n",
    "        transform_matrix = tf.EuclideanTransform(matrix = transform_tensor[i,...],rotation = None)\n",
    "        # transform image\n",
    "        transformed_image = (tf.warp(filtered_images[channel.name][i,...].compute(), transform_matrix, preserve_range=True)).astype(np.uint8)\n",
    "        # set transformed image pathname by editing base dir\n",
    "        fn = images.files(channel.name)[i].replace('_raw', '_aligned')\n",
    "        # save trans image out\n",
    "        io.imsave(fn, transformed_image, check_contrast=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918491e2",
   "metadata": {},
   "source": [
    "## 6. Check alignment using Napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "262a10b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "866e356b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cropping: None\n"
     ]
    }
   ],
   "source": [
    "aligned_images = DaskOctopusLiteLoader(os.path.join(root_dir, f'{expt}/{pos}/{pos}_aligned'))#, crop = (1200,1600), remove_background=False)\n",
    "\n",
    "viewer = napari.Viewer()\n",
    "for channel in aligned_images.channels:\n",
    "    #if channel.name == 'IRFP':\n",
    "    viewer.add_image(aligned_images[channel.name], name = channel.name, blending = 'additive', contrast_limits = [0,255])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3aac445",
   "metadata": {},
   "source": [
    "## Batch execute\n",
    "\n",
    "Do all of the above but for many experiment IDs and many positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63fa67c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/home/nathan/data/kraken/ras/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc821c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "alignment(root_dir,\n",
    "          expt_list = ['ND0010', 'ND0011', 'ND0009'],\n",
    "          max_pixel = 200, \n",
    "          min_pixel = 2, \n",
    "          crop_area = 500, \n",
    "          save_out_im = False, ### this does not save out a copy of the images, only the transformation matrix\n",
    "          overwrite = False) ### this checks for any prexisting transformations and does not overwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "952bbbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "viewer = napari.Viewer()\n",
    "for channel in aligned_images.channels:\n",
    "    viewer.add_image(aligned_images[channel.name], name = channel.name, blending = 'additive', contrast_limits = [0,255], colormap = napari.utils.colormaps.SIMPLE_COLORMAPS.popitem()) # lazy hack to randomly generate different colormaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eea9708c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alignment(root_dir, expt_list, max_pixel, min_pixel, crop_area, save_out, overwrite):\n",
    "\n",
    "    ### Iterate over all experiments defined in expt_list\n",
    "    for expt in expt_list:\n",
    "        # Find all positions in that experiment\n",
    "        pos_list = [pos for pos in os.listdir(os.path.join(root_dir, expt)) if 'Pos' in pos and os.path.isdir(os.path.join(root_dir, expt, pos))]        ### Iterate over all positions in that experiment\n",
    "        for pos in pos_list:\n",
    "            ### check if raw directory already created and if type of transform file already exists and decide whether to skip pos\n",
    "            if not overwrite and os.path.exists (os.path.join(root_dir, f'{expt}/{pos}/{pos}_raw')) and glob.glob(os.path.join(root_dir, f'{expt}/{pos}/*transform*.npy')) != []:\n",
    "                print(glob.glob(os.path.join(root_dir, f'{expt}/{pos}/*transform*.npy')), f'file found, skipping {expt}/{pos}')\n",
    "                continue\n",
    "            \n",
    "            ### create new subdir of for raw files and move them all there\n",
    "            if not os.path.exists(os.path.join(root_dir, f'{expt}/{pos}/{pos}_raw')):\n",
    "                os.mkdir(os.path.join(root_dir, f'{expt}/{pos}/{pos}_raw'))\n",
    "                files = sorted(glob.glob(os.path.join(root_dir, f'{expt}/{pos}/*.tif')))\n",
    "                for file in files:\n",
    "                    os.rename(file, file.replace(f'{pos}', f'{pos}/{pos}_raw'))\n",
    "            \n",
    "            ### pre load files from raw file dir \n",
    "            images = DaskOctopusLiteLoader(os.path.join(root_dir, f'{expt}/{pos}/{pos}_raw'), remove_background= False)\n",
    "\n",
    "            ### measure mean pixel value arrays and use to find under/over-exposed frames\n",
    "            # set empty dict arrays for mean values \n",
    "            mean_arrays = {}\n",
    "            # set for dodgy frames (only unique entries)\n",
    "            dodgy_frame_list = set([])\n",
    "            #iterate over channels\n",
    "            for channel in tqdm(images.channels, desc = f'Finding mean values of image channels'):\n",
    "                # find mean value of each frame in each channel\n",
    "                mean_arrays[channel.name] = np.mean(images[channel.name], axis = (1,2)).compute() \n",
    "                # iterate over frames\n",
    "                for frame, mean_value in enumerate(mean_arrays[channel.name]):\n",
    "                    # check to see if mean frame pixel value meets criteria\n",
    "                    if max_pixel < mean_value or mean_value < min_pixel:\n",
    "                        # if so add to delete list\n",
    "                        dodgy_frame_list.add(frame)\n",
    "            # format delete list\n",
    "            dodgy_frame_list = list(dodgy_frame_list)\n",
    "            print('Number of under/over-exposed frames:', len(dodgy_frame_list))\n",
    "\n",
    "            # create new image dicts with dodgy frames removed\n",
    "            filtered_images= {}\n",
    "            for channel in images.channels:\n",
    "                # delete dodgy frames from images and mean value arrays\n",
    "                filtered_images[channel.name] = np.delete(images[channel], dodgy_frame_list, axis = 0)\n",
    "                mean_arrays[channel.name] = np.delete(mean_arrays[channel.name], dodgy_frame_list, axis = 0) \n",
    "            \n",
    "            ### Automatically pick reference image to perform alignment on \n",
    "            # Pick gfp channel\n",
    "            reference_channel = images.channels[1]\n",
    "            # Pick channel based on index of brightest channel from maximum mean pixel array\n",
    "            #reference_channel = images.channels[max([(channel.value, np.mean(mean_arrays[channel.name])) for channel in images.channels])[0]]\n",
    "            # Define reference images\n",
    "            reference_image = filtered_images[reference_channel.name]\n",
    "            reference_image = reference_image[:,int((reference_image.shape[2]-crop_area)/2):int(reference_image.shape[2]-(reference_image.shape[2]-crop_area)/2),int((reference_image.shape[1]-crop_area)/2):int(reference_image.shape[1]-(reference_image.shape[1]-crop_area)/2)].compute()\n",
    "            reference_image.shape\n",
    "            print('Automatically selected and cropped reference image:', reference_channel.name)\n",
    "\n",
    "            ### Register alignment\n",
    "            print('Registering alignment for', pos, expt)\n",
    "            # create operator using transformation type (translation)\n",
    "            sr = StackReg(StackReg.TRANSLATION) \n",
    "            # register each frame to the previous as transformation matrices/tensor\n",
    "            transform_tensor = sr.register_stack(reference_image, reference = 'previous')\n",
    "            # save out transform tensor\n",
    "            np.save(os.path.join(root_dir, f'{expt}/{pos}/{reference_channel.name.lower()}_transform_tensor.npy'), transform_tensor)\n",
    "            \n",
    "            if save_out_im:\n",
    "                ### Perform alignment\n",
    "                # create aligned image dir if does not exist \n",
    "                if not os.path.exists(os.path.join(root_dir, f'{expt}/{pos}/{pos}_aligned')):\n",
    "                    os.mkdir(os.path.join(root_dir, f'{expt}/{pos}/{pos}_aligned'))\n",
    "                # iterate over channels\n",
    "                for channel in images.channels:\n",
    "                    #iterate over all images in channel\n",
    "                    for i in tqdm(range(len(transform_tensor)), desc = f'Aligning {channel.name.lower()} channel {channel.value+1}/{len(images.channels)}'):#filtered_images[channel.name]))):\n",
    "                        # load specific transform matrix for that frame\n",
    "                        transform_matrix = tf.EuclideanTransform(matrix = transform_tensor[i,...],rotation = None)\n",
    "                        # transform image\n",
    "                        transformed_image = (tf.warp(filtered_images[channel.name][i,...].compute(), transform_matrix, preserve_range=True)).astype(np.uint8)\n",
    "                        # set transformed image pathname by editing base dir\n",
    "                        fn = images.files(channel.name)[i].replace('_raw', '_aligned')\n",
    "                        # save trans image out\n",
    "                        io.imsave(fn, transformed_image, check_contrast=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CellX",
   "language": "python",
   "name": "cellx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
