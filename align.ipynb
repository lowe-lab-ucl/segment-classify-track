{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "127b5eb3",
   "metadata": {},
   "source": [
    "# Align and remove under/overexposed images\n",
    "\n",
    "This notebook removes any under/overexposed frames from timelapse experiments and aligns the images. \n",
    "\n",
    "### The aligned images will be used later in the object localisation and tracking steps. \n",
    "\n",
    "The structure of this notebook is:\n",
    "\n",
    "1. Load images using the octopuslite dask loader.\n",
    "2. Find over/underexposed images by measuring each channel and frame for average pixel intensity.\n",
    "3. Select a reference channel to center the alignment on\n",
    "4. Register alignment and save out transformation tensor\n",
    "5. (Optional) Apply transformation matrix to all channels and save out images\n",
    "6. Check images using Napari\n",
    "7. Function to iterate over many experiments, many positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7859805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import enum\n",
    "import numpy as np\n",
    "from pystackreg import StackReg\n",
    "from skimage.io import imsave\n",
    "from tqdm import tqdm\n",
    "from octopuslite import DaskOctopusLiteLoader, image_generator\n",
    "from skimage import transform as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b349a8a0",
   "metadata": {},
   "source": [
    "## 1. Find images, organise and load using octopuslite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8155bde",
   "metadata": {},
   "source": [
    "Define root directory and specific experiment and location to align"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbeda8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/home/nathan/data/'\n",
    "expt = 'ND0012'\n",
    "pos = 'Pos0'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7def82",
   "metadata": {},
   "source": [
    "Create new subdir for image files and move them all there. This is so that the miscelleanous non-image files (such as transformation matrices and tracking files) are easy to access later on and not lost amongst many single frame timelapse images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "894fb819",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = f'{root_dir}/{expt}/{pos}/{pos}_images'\n",
    "if not os.path.exists(image_path):\n",
    "    os.mkdir(image_path)\n",
    "    files = sorted(glob.glob(f'{root_dir}/{expt}/{pos}/*.tif'))\n",
    "    for file in files:\n",
    "        os.rename(file, file.replace(f'{pos}', f'{pos}/{pos}_images'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3403f8d",
   "metadata": {},
   "source": [
    "Lazily load image array and associated information using dask octopuslite-loader and display channels found. Note the optional background removal is not invoked at this stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a3d0870",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BRIGHTFIELD', 'GFP', 'RFP', 'IRFP']\n"
     ]
    }
   ],
   "source": [
    "images = DaskOctopusLiteLoader(image_path, remove_background = False)\n",
    "print([channel.name for channel in images.channels])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4314a4",
   "metadata": {},
   "source": [
    "## 2. Identify under/overexposed images and display average channel brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57e3d185",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Finding mean values of image channels: 100%|██████████| 4/4 [00:13<00:00,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of under/over-exposed frames: 19\n",
      "CPU times: user 11.5 s, sys: 2.49 s, total: 14 s\n",
      "Wall time: 14 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# pixel range criteria\n",
    "max_pixel, min_pixel = 200, 2\n",
    "# set empty dict arrays for mean values \n",
    "mean_arrays = {}\n",
    "# set for dodgy frames (only unique entries)\n",
    "dodgy_frame_list = set([])\n",
    "#iterate over channels\n",
    "for channel in tqdm(images.channels, desc = f'Finding mean values of image channels'):\n",
    "    # find mean value of each frame in each channel\n",
    "    mean_arrays[channel.name] = [np.mean(img) for img in image_generator(images.files(channel.name))]\n",
    "    # iterate over frames\n",
    "    for frame, mean_value in enumerate(mean_arrays[channel.name]):\n",
    "        # check to see if mean frame pixel value meets criteria\n",
    "        if max_pixel < mean_value or mean_value < min_pixel:\n",
    "            # if so add to delete list\n",
    "            dodgy_frame_list.add(frame)\n",
    "# format delete list to only include single values\n",
    "dodgy_frame_list = list(dodgy_frame_list)\n",
    "print('Number of under/over-exposed frames:', len(dodgy_frame_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc235269",
   "metadata": {},
   "source": [
    "### 2a. Filter blanks from main image folder into separate directory\n",
    "\n",
    "This step is optional as there is a parameter within `DaskOctopusLiteLoader` that filters the images, but employing that every time you load images is time consuming for large data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c7dd6bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table>\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 3.48 GiB </td>\n",
       "                        <td> 2.18 MiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (1638, 1352, 1688) </td>\n",
       "                        <td> (1, 1352, 1688) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Count </th>\n",
       "                        <td> 4914 Tasks </td>\n",
       "                        <td> 1638 Chunks </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                    <th> Type </th>\n",
       "                    <td> uint8 </td>\n",
       "                    <td> numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"248\" height=\"214\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"78\" y2=\"68\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"10\" y1=\"96\" x2=\"78\" y2=\"164\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"96\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"13\" y1=\"3\" x2=\"13\" y2=\"99\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"17\" y2=\"103\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"20\" y2=\"106\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"24\" y2=\"110\" />\n",
       "  <line x1=\"28\" y1=\"18\" x2=\"28\" y2=\"114\" />\n",
       "  <line x1=\"31\" y1=\"21\" x2=\"31\" y2=\"117\" />\n",
       "  <line x1=\"35\" y1=\"25\" x2=\"35\" y2=\"121\" />\n",
       "  <line x1=\"38\" y1=\"28\" x2=\"38\" y2=\"124\" />\n",
       "  <line x1=\"42\" y1=\"32\" x2=\"42\" y2=\"128\" />\n",
       "  <line x1=\"46\" y1=\"36\" x2=\"46\" y2=\"132\" />\n",
       "  <line x1=\"49\" y1=\"39\" x2=\"49\" y2=\"135\" />\n",
       "  <line x1=\"53\" y1=\"43\" x2=\"53\" y2=\"139\" />\n",
       "  <line x1=\"56\" y1=\"46\" x2=\"56\" y2=\"142\" />\n",
       "  <line x1=\"60\" y1=\"50\" x2=\"60\" y2=\"146\" />\n",
       "  <line x1=\"64\" y1=\"54\" x2=\"64\" y2=\"150\" />\n",
       "  <line x1=\"67\" y1=\"57\" x2=\"67\" y2=\"153\" />\n",
       "  <line x1=\"71\" y1=\"61\" x2=\"71\" y2=\"157\" />\n",
       "  <line x1=\"74\" y1=\"64\" x2=\"74\" y2=\"160\" />\n",
       "  <line x1=\"78\" y1=\"68\" x2=\"78\" y2=\"164\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 78.49735154725398,68.49735154725398 78.49735154725398,164.61109562308337 10.0,96.11374407582939\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"130\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"13\" y1=\"3\" x2=\"133\" y2=\"3\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"137\" y2=\"7\" />\n",
       "  <line x1=\"20\" y1=\"10\" x2=\"140\" y2=\"10\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"144\" y2=\"14\" />\n",
       "  <line x1=\"28\" y1=\"18\" x2=\"148\" y2=\"18\" />\n",
       "  <line x1=\"31\" y1=\"21\" x2=\"151\" y2=\"21\" />\n",
       "  <line x1=\"35\" y1=\"25\" x2=\"155\" y2=\"25\" />\n",
       "  <line x1=\"38\" y1=\"28\" x2=\"158\" y2=\"28\" />\n",
       "  <line x1=\"42\" y1=\"32\" x2=\"162\" y2=\"32\" />\n",
       "  <line x1=\"46\" y1=\"36\" x2=\"166\" y2=\"36\" />\n",
       "  <line x1=\"49\" y1=\"39\" x2=\"169\" y2=\"39\" />\n",
       "  <line x1=\"53\" y1=\"43\" x2=\"173\" y2=\"43\" />\n",
       "  <line x1=\"56\" y1=\"46\" x2=\"176\" y2=\"46\" />\n",
       "  <line x1=\"60\" y1=\"50\" x2=\"180\" y2=\"50\" />\n",
       "  <line x1=\"64\" y1=\"54\" x2=\"184\" y2=\"54\" />\n",
       "  <line x1=\"67\" y1=\"57\" x2=\"187\" y2=\"57\" />\n",
       "  <line x1=\"71\" y1=\"61\" x2=\"191\" y2=\"61\" />\n",
       "  <line x1=\"74\" y1=\"64\" x2=\"194\" y2=\"64\" />\n",
       "  <line x1=\"78\" y1=\"68\" x2=\"198\" y2=\"68\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"78\" y2=\"68\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"130\" y1=\"0\" x2=\"198\" y2=\"68\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 130.0,0.0 198.49735154725397,68.49735154725398 78.49735154725398,68.49735154725398\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"78\" y1=\"68\" x2=\"198\" y2=\"68\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"78\" y1=\"164\" x2=\"198\" y2=\"164\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"78\" y1=\"68\" x2=\"78\" y2=\"164\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"198\" y1=\"68\" x2=\"198\" y2=\"164\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"78.49735154725398,68.49735154725398 198.49735154725397,68.49735154725398 198.49735154725397,164.61109562308337 78.49735154725398,164.61109562308337\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"138.497352\" y=\"184.611096\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >1688</text>\n",
       "  <text x=\"218.497352\" y=\"116.554224\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,218.497352,116.554224)\">1352</text>\n",
       "  <text x=\"34.248676\" y=\"150.362420\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,34.248676,150.362420)\">1638</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<stack, shape=(1638, 1352, 1688), dtype=uint8, chunksize=(1, 1352, 1688), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if blanks dir exists and make if not\n",
    "if not os.path.exists(f'{root_dir}/{expt}/{pos}/{pos}_blanks'):\n",
    "    os.mkdir(f'{root_dir}/{expt}/{pos}/{pos}_blanks')\n",
    "# move blank images into this directory\n",
    "for channel in images.channels:\n",
    "    for f in images.files(channel.name):\n",
    "        for i in dodgy_frame_list:\n",
    "            if str(i).zfill(9) in f:\n",
    "                os.rename(f, f.replace('_images', '_blanks'))\n",
    "# reload image arrays now that blanks filtered\n",
    "images = DaskOctopusLiteLoader(image_path, remove_background = False)\n",
    "images['gfp']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6686782",
   "metadata": {},
   "source": [
    "## 3. Select reference image to base alignment around\n",
    "\n",
    "Display the average intensities of each channel. The automatically-measured brightest channel isn't necessarily the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8011e037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average channel brightness for selection of reference image:\n",
      "0: BRIGHTFIELD: 40.96403863128827\n",
      "1: GFP: 45.97970142886046\n",
      "2: RFP: 6.969645431239206\n",
      "3: IRFP: 47.732877102157886\n"
     ]
    }
   ],
   "source": [
    "print('Average channel brightness for selection of reference image:')\n",
    "for channel in images.channels:\n",
    "    print(f'{channel.value}: {channel.name}:', np.mean(mean_arrays[channel.name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e83d0329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'GFP'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# manually select reference channel by adding index\n",
    "reference_channel = images.channels[1]\n",
    "# automatically select reference channel from max average pixel value (ie. brightest channel)\n",
    "#reference_channel = images.channels[max([(channel.value, np.mean(mean_arrays[channel.name])) for channel in images.channels])[0]]\n",
    "reference_channel.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b286dc16",
   "metadata": {},
   "source": [
    "#### 3a. Set cropped area of reference image to base alignment around \n",
    "Cropping as alignment struggles on large arrays such as `shape = (1200,1353,1682)`, this step is optional but you will still need to run `.compute()` on the dask array to load the image into memory to perform the alignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7cf2f6bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cropping: (500, 500)\n",
      "CPU times: user 4min 53s, sys: 3min 39s, total: 8min 32s\n",
      "Wall time: 55.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1638, 500, 500)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# crop central window out of reference image\n",
    "reference_image = DaskOctopusLiteLoader(image_path, \n",
    "                                        crop = (500, 500)\n",
    "                                       )[reference_channel.name].compute()\n",
    "reference_image.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "466ad46f",
   "metadata": {},
   "source": [
    "## 4. Register alignment and save out transformation tensor\n",
    "Transformation tensor is a 3D series of transformation matrices over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "59ebe809",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nathan/analysis/miniconda3/envs/cellx/lib/python3.9/site-packages/pystackreg/pystackreg.py:379: UserWarning: Detected axis 2 as the possible time axis for the stack due to its low variability, but axis 0 was supplied for registration. Are you sure you supplied the correct axis?\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 19s, sys: 3.78 s, total: 3min 23s\n",
      "Wall time: 3min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# create operator using transformation type (translation)\n",
    "sr = StackReg(StackReg.TRANSLATION) \n",
    "\n",
    "# register each frame to the previous as transformation matrices/tensor\n",
    "transform_tensor = sr.register_stack(reference_image, reference = 'previous')\n",
    "\n",
    "# save out transform tensor\n",
    "np.save(f'{root_dir}/{expt}/{pos}/{reference_channel.name.lower()}_transform_tensor.npy', transform_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8c5c334e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1638, 3, 3)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d310e7d",
   "metadata": {},
   "source": [
    "## 5. (Optional) Apply transformation matrix to all channels and save out images in separate directory\n",
    "\n",
    "Consumes a lot of time and space to replicate images with minor translational shifts, it is advised to just use the transform parameter in the `DaskOctopusLiteLoader`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ae81366",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Aligning brightfield channel 1/4: 100%|██████████| 1067/1067 [02:46<00:00,  6.42it/s]\n",
      "Aligning gfp channel 2/4: 100%|██████████| 1067/1067 [02:48<00:00,  6.32it/s]\n",
      "Aligning rfp channel 3/4: 100%|██████████| 1067/1067 [03:06<00:00,  5.72it/s]\n",
      "Aligning irfp channel 4/4: 100%|██████████| 1067/1067 [03:04<00:00,  5.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 24s, sys: 51.4 s, total: 6min 15s\n",
      "Wall time: 11min 45s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "### iterating over channels\n",
    "# create aligned image dir if does not exist \n",
    "if not os.path.exists(f'{root_dir}/{expt}/{pos}/{pos}_aligned'):\n",
    "    os.mkdir(f'{root_dir}/{expt}/{pos}/{pos}_aligned')\n",
    "# iterate over channels\n",
    "for channel in images.channels:\n",
    "    #iterate over all images in channel\n",
    "    for i in tqdm(range(len(transform_tensor)), \n",
    "                  desc = f'Aligning {channel.name.lower()} channel {channel.value+1}/{len(images.channels)}'):\n",
    "        # load specific transform matrix for that frame\n",
    "        transform_matrix = tf.EuclideanTransform(matrix = transform_tensor[i,...],\n",
    "                                                 rotation = None)\n",
    "        # transform image\n",
    "        transformed_image = (tf.warp(images[channel.name][i,...].compute(), \n",
    "                                     transform_matrix, preserve_range=True)).astype(np.uint8)\n",
    "        # set transformed image pathname by editing base dir\n",
    "        fn = images.files(channel.name)[i].replace('_images', '_aligned')\n",
    "        # save trans image out\n",
    "        imsave(fn, transformed_image, check_contrast=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918491e2",
   "metadata": {},
   "source": [
    "## 6. Check alignment using Napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "262a10b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import napari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "798b9d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "aligned_images = DaskOctopusLiteLoader(image_path, \n",
    "                                       #crop = (1200,1600), \n",
    "                                       transforms = f'{root_dir}/{expt}/{pos}/gfp_transform_tensor.npy',\n",
    "                                       remove_background=False)\n",
    "viewer = napari.Viewer()\n",
    "for channel in aligned_images.channels:\n",
    "    viewer.add_image(aligned_images[channel.name], \n",
    "                     name = channel.name, \n",
    "                     blending = 'additive', \n",
    "                     contrast_limits = [0,255])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3aac445",
   "metadata": {},
   "source": [
    "## Batch execute\n",
    "\n",
    "Do all of the above but for many experiment IDs and many positions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc821c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Finding mean values of image channels:  75%|███████▌  | 3/4 [04:03<01:19, 79.86s/it]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "alignment(root_dir = '/home/nathan/data/kraken/ras',\n",
    "          expt_list = ['ND0012'],\n",
    "          max_pixel = 200, \n",
    "          min_pixel = 2,\n",
    "          alignment_channel = 'gfp',\n",
    "          crop_area = 500, \n",
    "          save_out_images = False, ### this does not save out a copy of the images, only the transformation matrix\n",
    "          overwrite = False) ### this checks for any prexisting transformations and does not overwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "eea9708c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def alignment(root_dir, expt_list, max_pixel, min_pixel, alignment_channel, crop_area, save_out_images, overwrite):\n",
    "\n",
    "    ### Iterate over all experiments defined in expt_list\n",
    "    for expt in expt_list:\n",
    "        # Find all positions in that experiment\n",
    "        pos_list = [pos for pos in os.listdir(f'{root_dir}/{expt}') \n",
    "                    if 'Pos' in pos \n",
    "                    and os.path.isdir(f'{root_dir}/{expt}/{pos}')]        \n",
    "        ### Iterate over all positions in that experiment\n",
    "        for pos in pos_list:\n",
    "            ### check if overwrite param is false check if raw directory already created and if type of transform file already exists and decide whether to skip pos\n",
    "            if not overwrite and os.path.exists (f'{root_dir}/{expt}/{pos}/{pos}_images') and glob.glob(f'{root_dir}/{expt}/{pos}/*transform*.npy'):\n",
    "                print(glob.glob(f'{root_dir}/{expt}/{pos}/*transform*.npy'), f'file found, skipping {expt}/{pos}')\n",
    "                continue\n",
    "            \n",
    "            print(f'Starting {expt}/{pos}')\n",
    "            \n",
    "            ### create new subdir of for raw files and move them all there\n",
    "            image_path = f'{root_dir}/{expt}/{pos}/{pos}_images'\n",
    "            if not os.path.exists(image_path):\n",
    "                os.mkdir(image_path)\n",
    "                files = sorted(glob.glob(f'{root_dir}/{expt}/{pos}/*.tif'))\n",
    "                for file in files:\n",
    "                    os.rename(file, file.replace(f'{pos}', f'{pos}/{pos}_images'))\n",
    "            \n",
    "            ### pre load files from raw file dir \n",
    "            images = DaskOctopusLiteLoader(image_path, remove_background= False)\n",
    "\n",
    "            ### measure mean pixel value arrays and use to find under/over-exposed frames\n",
    "            # set empty dict arrays for mean values \n",
    "            mean_arrays = {}\n",
    "            # set for dodgy frames (only unique entries)\n",
    "            dodgy_frame_list = set([])\n",
    "            #iterate over channels\n",
    "            for channel in tqdm(images.channels, desc = f'Finding mean values of image channels'):\n",
    "                # find mean value of each frame in each channel\n",
    "                mean_arrays[channel.name] = [np.mean(img) for img in image_generator(images.files(channel.name))]\n",
    "                # iterate over frames\n",
    "                for frame, mean_value in enumerate(mean_arrays[channel.name]):\n",
    "                    # check to see if mean frame pixel value meets criteria\n",
    "                    if max_pixel < mean_value or mean_value < min_pixel:\n",
    "                        # if so add to delete list\n",
    "                        dodgy_frame_list.add(frame)\n",
    "            # format delete list to only include single values\n",
    "            dodgy_frame_list = list(dodgy_frame_list)\n",
    "            print('Number of under/over-exposed frames:', len(dodgy_frame_list))\n",
    "\n",
    "            # check if blanks dir exists and make if not\n",
    "            if not os.path.exists(f'{root_dir}/{expt}/{pos}/{pos}_blanks'):\n",
    "                os.mkdir(f'{root_dir}/{expt}/{pos}/{pos}_blanks')\n",
    "            # move blank images into this directory\n",
    "            for channel in images.channels:\n",
    "                for f in images.files(channel.name):\n",
    "                    for i in dodgy_frame_list:\n",
    "                        if str(i).zfill(9) in f:\n",
    "                            os.rename(f, f.replace('_images', '_blanks'))\n",
    "            \n",
    "            # crop central window out of reference image with blanks removed\n",
    "            reference_image = DaskOctopusLiteLoader(image_path, \n",
    "                                                    crop = (crop_area, crop_area)\n",
    "                                                   )[alignment_channel].compute() \n",
    "    \n",
    "            ### Register alignment\n",
    "            print('Registering alignment for', pos, expt)\n",
    "            # create operator using transformation type (translation)\n",
    "            sr = StackReg(StackReg.TRANSLATION) \n",
    "            # register each frame to the previous as transformation matrices/tensor\n",
    "            transform_tensor = sr.register_stack(reference_image, reference = 'previous')\n",
    "            # save out transform tensor\n",
    "            np.save(f'{root_dir}/{expt}/{pos}/{alignment_channel}_transform_tensor.npy', transform_tensor)\n",
    "            \n",
    "            if save_out_images:\n",
    "                ### Perform alignment\n",
    "                # create aligned image dir if does not exist \n",
    "                if not os.path.exists(f'{root_dir}/{expt}/{pos}/{pos}_aligned'):\n",
    "                    os.mkdir(f'{root_dir}/{expt}/{pos}/{pos}_aligned')\n",
    "                # iterate over channels\n",
    "                for channel in images.channels:\n",
    "                    #iterate over all images in channel\n",
    "                    for i in tqdm(range(len(transform_tensor)), \n",
    "                                  desc = f'Aligning {channel.name.lower()} channel {channel.value+1}/{len(images.channels)}'):\n",
    "                        # load specific transform matrix for that frame\n",
    "                        transform_matrix = tf.EuclideanTransform(matrix = transform_tensor[i,...],\n",
    "                                                                 rotation = None)\n",
    "                        # transform image\n",
    "                        transformed_image = (tf.warp(filtered_images[channel.name][i,...].compute(), \n",
    "                                                     transform_matrix, preserve_range=True)).astype(np.uint8)\n",
    "                        # set transformed image pathname by editing base dir\n",
    "                        fn = images.files(channel.name)[i].replace('_images', '_aligned')\n",
    "                        # save trans image out\n",
    "                        imsave(fn, transformed_image, check_contrast=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CellX",
   "language": "python",
   "name": "cellx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
