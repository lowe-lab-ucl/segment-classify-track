{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "127b5eb3",
   "metadata": {},
   "source": [
    "# Align and remove blanks\n",
    "\n",
    "Adapted from Giulia Vallardi's ImageJ macro, this notebook removes any blank frames from timelapse experiments and aligns the images. \n",
    "\n",
    "\"Fiji macro to remove over- and under-exposed images, and align the image stacks\n",
    "\n",
    "The settings for the alignments are: \n",
    "registration by Translation > only modify XY coordinates\n",
    "Shrinkage constrain activated (this model allows a better registration based on all images, not using a reference image. It is more time consuming though)\n",
    "Transform matrices are saved during registration and then applied to the other channels during transformation.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7859805",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import enum\n",
    "import numpy as np\n",
    "from pystackreg import StackReg\n",
    "from skimage import io\n",
    "from tqdm import tqdm\n",
    "from daskoctopus import DaskOctopusLiteLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b767dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdb823e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start():\n",
    "    global start_time\n",
    "    start_time = timeit.default_timer()\n",
    "\n",
    "def stop():\n",
    "    elapsed = timeit.default_timer() - start_time\n",
    "    print('elapsed time:', elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "706c8277",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define channels (in order)\n",
    "@enum.unique\n",
    "class channels(enum.Enum):\n",
    "    bf = 0 \n",
    "    gfp = 1\n",
    "    rfp = 2\n",
    "    irfp = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb3b3a5",
   "metadata": {},
   "source": [
    "# Find images, organise into raw folder and load using dask octo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "faf8db2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### define root directory and specific experiment and location (will later make iterable)\n",
    "root_dir = '/home/nathan/data/kraken/commitment/test/'\n",
    "expt = \"MK0003\"\n",
    "pos = \"PosX\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d2b0bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "### create new subdir of for raw files and move them all there\n",
    "if not os.path.exists(os.path.join(root_dir, f'{expt}/{pos}/{pos}_raw')):\n",
    "    os.mkdir(os.path.join(root_dir, f'{expt}/{pos}/{pos}_raw'))\n",
    "    files = sorted(glob.glob(os.path.join(root_dir, f'{expt}/{pos}/*.tif')))\n",
    "    for file in files:\n",
    "        os.rename(file, file.replace(f'{pos}', f'{pos}/{pos}_raw'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56a25003",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cropping: None\n"
     ]
    }
   ],
   "source": [
    "### pre load files from raw file dir \n",
    "octopus_loader = DaskOctopusLiteLoader(os.path.join(root_dir, f'{expt}/{pos}/{pos}_raw'))#, crop=(1200, 1600))\n",
    "gfp = octopus_loader['gfp']\n",
    "rfp = octopus_loader['rfp']\n",
    "irfp = octopus_loader['irfp']\n",
    "bf = octopus_loader['brightfield']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc9ea894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1200, 1352, 1688)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07086ff",
   "metadata": {},
   "source": [
    "# Filter out blank or overexposed images and display average channel brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59823a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average channel brightness for selection of reference image:\n",
      "gfp: 62.79905 rfp: 6.4401646 irfp: 76.01225 bf: 28.949467\n"
     ]
    }
   ],
   "source": [
    "# pixel range criteria\n",
    "max_pixel, min_pixel = 200, 2\n",
    "\n",
    "### find mean values\n",
    "gfp_mean_array = np.mean(gfp, axis = (1,2)).compute()\n",
    "rfp_mean_array = np.mean(rfp, axis = (1,2)).compute()\n",
    "irfp_mean_array = np.mean(irfp, axis = (1,2)).compute()\n",
    "bf_mean_array = np.mean(bf, axis = (1,2)).compute()\n",
    "\n",
    "# find blanks / overexposed and create dodgy frame list\n",
    "dodgy_frame_list = set([])\n",
    "for i, array in enumerate([gfp_mean_array, rfp_mean_array, irfp_mean_array, bf_mean_array]):\n",
    "    for frame, mean_value in enumerate(array):\n",
    "        if max_pixel < mean_value or mean_value < min_pixel:\n",
    "            dodgy_frame_list.add(frame)\n",
    "dodgy_frame_list = list(dodgy_frame_list)\n",
    "\n",
    "# delete dodgy frames from stacks\n",
    "gfp = np.delete(gfp, dodgy_frame_list, axis = 0)\n",
    "rfp = np.delete(rfp, dodgy_frame_list, axis = 0)\n",
    "irfp = np.delete(irfp, dodgy_frame_list, axis = 0)\n",
    "bf = np.delete(bf, dodgy_frame_list, axis = 0)\n",
    "\n",
    "print('Average channel brightness for selection of reference image:')\n",
    "print('gfp:', np.mean(gfp_mean_array), 'rfp:', np.mean(rfp_mean_array), 'irfp:', np.mean(irfp_mean_array), 'bf:', np.mean(bf_mean_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "57676357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1192, 1352, 1688)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d1a804",
   "metadata": {},
   "source": [
    "# Select reference image to base alignment around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4bc54e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### trying to format it so that i can save out transform file name formatted nicely and auto select other channels to perform alignment on after\n",
    "reference_channel = channels['irfp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "320e9ec6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <td>\n",
       "            <table>\n",
       "                <thead>\n",
       "                    <tr>\n",
       "                        <td> </td>\n",
       "                        <th> Array </th>\n",
       "                        <th> Chunk </th>\n",
       "                    </tr>\n",
       "                </thead>\n",
       "                <tbody>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Bytes </th>\n",
       "                        <td> 1.11 GiB </td>\n",
       "                        <td> 0.95 MiB </td>\n",
       "                    </tr>\n",
       "                    \n",
       "                    <tr>\n",
       "                        <th> Shape </th>\n",
       "                        <td> (1192, 500, 500) </td>\n",
       "                        <td> (1, 500, 500) </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                        <th> Count </th>\n",
       "                        <td> 8300 Tasks </td>\n",
       "                        <td> 1192 Chunks </td>\n",
       "                    </tr>\n",
       "                    <tr>\n",
       "                    <th> Type </th>\n",
       "                    <td> float32 </td>\n",
       "                    <td> numpy.ndarray </td>\n",
       "                    </tr>\n",
       "                </tbody>\n",
       "            </table>\n",
       "        </td>\n",
       "        <td>\n",
       "        <svg width=\"180\" height=\"170\" style=\"stroke:rgb(0,0,0);stroke-width:1\" >\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"80\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"10\" y1=\"50\" x2=\"80\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"10\" y2=\"50\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"13\" y1=\"3\" x2=\"13\" y2=\"54\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"17\" y2=\"57\" />\n",
       "  <line x1=\"21\" y1=\"11\" x2=\"21\" y2=\"61\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"24\" y2=\"65\" />\n",
       "  <line x1=\"28\" y1=\"18\" x2=\"28\" y2=\"68\" />\n",
       "  <line x1=\"32\" y1=\"22\" x2=\"32\" y2=\"72\" />\n",
       "  <line x1=\"35\" y1=\"25\" x2=\"35\" y2=\"76\" />\n",
       "  <line x1=\"39\" y1=\"29\" x2=\"39\" y2=\"80\" />\n",
       "  <line x1=\"43\" y1=\"33\" x2=\"43\" y2=\"83\" />\n",
       "  <line x1=\"47\" y1=\"37\" x2=\"47\" y2=\"87\" />\n",
       "  <line x1=\"50\" y1=\"40\" x2=\"50\" y2=\"91\" />\n",
       "  <line x1=\"54\" y1=\"44\" x2=\"54\" y2=\"94\" />\n",
       "  <line x1=\"58\" y1=\"48\" x2=\"58\" y2=\"98\" />\n",
       "  <line x1=\"61\" y1=\"51\" x2=\"61\" y2=\"102\" />\n",
       "  <line x1=\"65\" y1=\"55\" x2=\"65\" y2=\"106\" />\n",
       "  <line x1=\"69\" y1=\"59\" x2=\"69\" y2=\"109\" />\n",
       "  <line x1=\"73\" y1=\"63\" x2=\"73\" y2=\"113\" />\n",
       "  <line x1=\"76\" y1=\"66\" x2=\"76\" y2=\"117\" />\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"80\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 80.58823529411765,70.58823529411765 80.58823529411765,120.9238057639163 10.0,50.33557046979866\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"60\" y2=\"0\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"13\" y1=\"3\" x2=\"64\" y2=\"3\" />\n",
       "  <line x1=\"17\" y1=\"7\" x2=\"67\" y2=\"7\" />\n",
       "  <line x1=\"21\" y1=\"11\" x2=\"71\" y2=\"11\" />\n",
       "  <line x1=\"24\" y1=\"14\" x2=\"75\" y2=\"14\" />\n",
       "  <line x1=\"28\" y1=\"18\" x2=\"78\" y2=\"18\" />\n",
       "  <line x1=\"32\" y1=\"22\" x2=\"82\" y2=\"22\" />\n",
       "  <line x1=\"35\" y1=\"25\" x2=\"86\" y2=\"25\" />\n",
       "  <line x1=\"39\" y1=\"29\" x2=\"90\" y2=\"29\" />\n",
       "  <line x1=\"43\" y1=\"33\" x2=\"93\" y2=\"33\" />\n",
       "  <line x1=\"47\" y1=\"37\" x2=\"97\" y2=\"37\" />\n",
       "  <line x1=\"50\" y1=\"40\" x2=\"101\" y2=\"40\" />\n",
       "  <line x1=\"54\" y1=\"44\" x2=\"104\" y2=\"44\" />\n",
       "  <line x1=\"58\" y1=\"48\" x2=\"108\" y2=\"48\" />\n",
       "  <line x1=\"61\" y1=\"51\" x2=\"112\" y2=\"51\" />\n",
       "  <line x1=\"65\" y1=\"55\" x2=\"116\" y2=\"55\" />\n",
       "  <line x1=\"69\" y1=\"59\" x2=\"119\" y2=\"59\" />\n",
       "  <line x1=\"73\" y1=\"63\" x2=\"123\" y2=\"63\" />\n",
       "  <line x1=\"76\" y1=\"66\" x2=\"127\" y2=\"66\" />\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"130\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"10\" y1=\"0\" x2=\"80\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"60\" y1=\"0\" x2=\"130\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"10.0,0.0 60.33557046979866,0.0 130.9238057639163,70.58823529411765 80.58823529411765,70.58823529411765\" style=\"fill:#8B4903A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Horizontal lines -->\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"130\" y2=\"70\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"80\" y1=\"120\" x2=\"130\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Vertical lines -->\n",
       "  <line x1=\"80\" y1=\"70\" x2=\"80\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "  <line x1=\"130\" y1=\"70\" x2=\"130\" y2=\"120\" style=\"stroke-width:2\" />\n",
       "\n",
       "  <!-- Colored Rectangle -->\n",
       "  <polygon points=\"80.58823529411765,70.58823529411765 130.9238057639163,70.58823529411765 130.9238057639163,120.9238057639163 80.58823529411765,120.9238057639163\" style=\"fill:#ECB172A0;stroke-width:0\"/>\n",
       "\n",
       "  <!-- Text -->\n",
       "  <text x=\"105.756021\" y=\"140.923806\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" >500</text>\n",
       "  <text x=\"150.923806\" y=\"95.756021\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(-90,150.923806,95.756021)\">500</text>\n",
       "  <text x=\"35.294118\" y=\"105.629688\" font-size=\"1.0rem\" font-weight=\"100\" text-anchor=\"middle\" transform=\"rotate(45,35.294118,105.629688)\">1192</text>\n",
       "</svg>\n",
       "        </td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "dask.array<getitem, shape=(1192, 500, 500), dtype=float32, chunksize=(1, 500, 500), chunktype=numpy.ndarray>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irfp[:,int((irfp.shape[2]-500)/2):int(irfp.shape[2]-(irfp.shape[2]-500)/2),int((irfp.shape[1]-500)/2):int(irfp.shape[1]-(irfp.shape[1]-500)/2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b82ac7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### trying cropping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ac1cd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_image = irfp[:,int((irfp.shape[2]-500)/2):int(irfp.shape[2]-(irfp.shape[2]-500)/2),int((irfp.shape[1]-500)/2):int(irfp.shape[1]-(irfp.shape[1]-500)/2)].compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eade2c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "if reference_channel.name == 'irfp':\n",
    "    reference_image = irfp.compute()\n",
    "\n",
    "### etc etc is there a better way to do this?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1677fbf",
   "metadata": {},
   "source": [
    "# Align dask stack and save out transformation matrix\n",
    "\n",
    "## --- currently struggling with memory to do this after previous calculations  ---\n",
    "\n",
    "### ~1. Clear memory of unnecessary files?~\n",
    "### 2. Or try iterating over stack and performing alignment calc?\n",
    "### 3. Or perform alignment on crop of central area?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "380c9ffb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nathan/analysis/miniconda3/envs/cellx/lib/python3.9/site-packages/pystackreg/pystackreg.py:379: UserWarning: Detected axis 2 as the possible time axis for the stack due to its low variability, but axis 0 was supplied for registration. Are you sure you supplied the correct axis?\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# create operator using transformation type (translation)\n",
    "sr = StackReg(StackReg.TRANSLATION) \n",
    "\n",
    "# register each frame to the previous as transformation matrices\n",
    "t_mats = sr.register_stack(reference_image, reference = 'previous').astype(np.uint8)\n",
    "\n",
    "# save out transformatrion matrices\n",
    "### format for channel choice???\n",
    "np.save(os.path.join(root_dir, f'{expt}/{pos}/', 'transformation_matrices.npy'), t_mats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c42f0ef",
   "metadata": {},
   "source": [
    "# ~transformation matrix for 500x500 crop worked, now trying that on original image~ doesnt work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29362eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_image = sr.transform_stack(irfp.compute()).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5a126d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# try loading tmats and applying (need to remove blank frames first)\n",
    "sr = StackReg(StackReg.TRANSLATION) \n",
    "t_mats = np.load(os.path.join(root_dir, f'{expt}/{pos}/transformation_matrices.npy'))\n",
    "transformed_image = sr.transform_stack(irfp, tmats=t_mats).astype(np.uint8)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e27017",
   "metadata": {},
   "source": [
    "# looks like this is working, either bc StackReg was reloaded or bc the kernel was cleared before transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942ba44f",
   "metadata": {},
   "outputs": [],
   "source": [
    "io.imsave(os.path.join(root_dir, f'{expt}/{pos}/trans_irfp.tif'), transformed_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bf96c44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1192, 3, 3)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_mats.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995d6796",
   "metadata": {},
   "source": [
    "# Apply transformation to each image stack and save out individual files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ae96f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform original stack\n",
    "transformed_image = sr.transform_stack(reference_image).astype(np.uint8)\n",
    "# save out original transformed stack \n",
    "### new directory\n",
    "io.imsave(os.path.join(root_dir, f'{expt}/{pos}/trans_irfp.tif'), transformed_image)\n",
    "\n",
    "### and all other channels ### NEEDS FORMATTING so that selected reference channel does not get saved this time, only the others do\n",
    "image = rfp.compute()#io.imread(os.path.join(data_dir,'Pos1_stacks/gfp_short.tif'))\n",
    "\n",
    "transformed_image = sr.transform_stack(image, tmats=t_mats).astype(np.uint8)\n",
    "\n",
    "io.imsave(os.path.join(root_dir, f'{expt}/{pos}/trans_rfp.tif'), transformed_image)\n",
    "\n",
    "image = gfp.compute()#io.imread(os.path.join(data_dir,'Pos1_stacks/gfp_short.tif'))\n",
    "\n",
    "transformed_image = sr.transform_stack(image, tmats=t_mats).astype(np.uint8)\n",
    "\n",
    "io.imsave(os.path.join(root_dir, f'{expt}/{pos}/trans_gfp.tif'), transformed_image)\n",
    "\n",
    "image = bf.compute()#io.imread(os.path.join(data_dir,'Pos1_stacks/gfp_short.tif'))\n",
    "\n",
    "transformed_image = sr.transform_stack(image, tmats=t_mats).astype(np.uint8)\n",
    "\n",
    "io.imsave(os.path.join(root_dir, f'{expt}/{pos}/trans_bf.tif'), transformed_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4c112e",
   "metadata": {},
   "source": [
    "# currently fails at step 4 (transforming an image) for a standard sized timelapse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a855a15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = timeit.default_timer()\n",
    "\n",
    "\n",
    "# create operator using transformation type (translation)\n",
    "sr = StackReg(StackReg.TRANSLATION) \n",
    "print(1)\n",
    "# register each frame to the previous as transformation matrices\n",
    "t_mats = sr.register_stack(reference_image, reference = 'previous').astype(np.uint8)\n",
    "print(2)\n",
    "# save out transformatrion matrices\n",
    "### format for channel choice\n",
    "np.save(os.path.join(PATH, 'rfp_dask_transformation_matrices.npy'), t_mats)\n",
    "print(3)\n",
    "# transform original stack\n",
    "transformed_image = sr.transform_stack(reference_image).astype(np.uint8)\n",
    "print(4)\n",
    "# save out original transformed stack \n",
    "### new directory\n",
    "io.imsave(os.path.join(PATH,'trans_rfp.tif'), transformed_image)\n",
    "print(5)\n",
    "# load other images and transform them\n",
    "### for channel in other channels\n",
    "### if not reference channel\n",
    "image = rfp.compute()#io.imread(os.path.join(data_dir,'Pos1_stacks/gfp_short.tif'))\n",
    "print(7)\n",
    "transformed_image = sr.transform_stack(image, tmats=t_mats).astype(np.uint8)\n",
    "print(8)\n",
    "io.imsave(os.path.join(PATH,'trans_gfp.tif'), transformed_image)\n",
    "\n",
    "\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "print(elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6652622",
   "metadata": {},
   "outputs": [],
   "source": [
    "### define pos and expt \n",
    "expt = 'MK0003'\n",
    "pos = 'Pos1'\n",
    "root_dir = '/home/nathan/data/kraken/commitment/test/'\n",
    "data_dir = os.path.join(root_dir, expt, pos)\n",
    "\n",
    "### move raw files into raw files directory and create aligned dir\n",
    "raw_data_dir = os.path.join(data_dir, f'{pos}_raw')\n",
    "os.mkdir(raw_data_dir)\n",
    "raw_files = glob.glob(os.path.join(data_dir, '*.tif'))\n",
    "for filename in raw_files:\n",
    "    os.rename(filename, filename.replace(f'{pos}', f'{pos}/{pos}_raw'))\n",
    "os.mkdir(os.path.join(data_dir, f'{pos}_aligned'))\n",
    "\n",
    "### organise into dask stacks using dask octopus loader\n",
    "octopus = DaskOctopusLiteLoader(raw_data_dir)#, crop=(1200, 1600))\n",
    "gfp = octopus[\"GFP\"]\n",
    "rfp = octopus[\"RFP\"]\n",
    "irfp = octopus[\"IRFP\"]\n",
    "bf = octopus[\"BRIGHTFIELD\"]\n",
    "\n",
    "### load actual images\n",
    "if reference_channel = \n",
    "reference_image = gfp.compute() if reference_channel == 'gfp' else rfp.compute()\n",
    "\n",
    "\n",
    "# create operator using transformation type (translation)\n",
    "sr = StackReg(StackReg.TRANSLATION) \n",
    "print(1)\n",
    "# register each frame to the previous as transformation matrices\n",
    "t_mats = sr.register_stack(reference_image, reference = 'previous').astype(np.uint8)\n",
    "print(2)\n",
    "# save out transformatrion matrices\n",
    "### format for channel choice\n",
    "np.save(os.path.join(PATH, 'rfp_dask_transformation_matrices.npy'), t_mats)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e34c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "### USING SKIMAGE.IO \n",
    "\n",
    "expt = 'MK0003'\n",
    "pos = 'Pos1'\n",
    "\n",
    "# set root dir and data dir so can be iterable \n",
    "root_dir = '/home/nathan/data/kraken/commitment/test/'\n",
    "data_dir = os.path.join(root_dir, expt, pos)\n",
    "### change this line to be more versatile for non_stacks as files are saved as single images originally -- use octo lite loader\n",
    "### also change for channel choice\n",
    "reference_image = io.imread(os.path.join(data_dir,'Pos1_stacks/rfp_short.tif')) # 3 dimensions : frames x width x height\n",
    "\n",
    "# create operator using transformation type (translation)\n",
    "sr = StackReg(StackReg.TRANSLATION) \n",
    "\n",
    "# register each frame to the previous as transformation matrices\n",
    "t_mats = sr.register_stack(reference_image, reference = 'previous').astype(np.uint8)\n",
    "\n",
    "# save out transformatrion matrices\n",
    "### format for channel choice\n",
    "np.save(os.path.join(data_dir, 'rfp_transformation_matrices.npy'), t_mats)\n",
    "\n",
    "# transform original stack\n",
    "transformed_image = sr.transform_stack(reference_image).astype(np.uint8)\n",
    "\n",
    "# save out original transformed stack \n",
    "### new directory\n",
    "io.imsave('trans_rfp.tif', transformed_image)\n",
    "\n",
    "# load other images and transform them\n",
    "### for channel in other channels\n",
    "### if not reference channel\n",
    "image = io.imread(os.path.join(data_dir,'Pos1_stacks/gfp_short.tif'))\n",
    "transformed_image = sr.transform_stack(image, tmats=t_mats).astype(np.uint8)\n",
    "io.imsave('trans_gfp.tif', transformed_image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f51d3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(reference_image[0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a3c554",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(t_mats[0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4b8d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(transformed_image[0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8d0781",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "img0 = io.imread('/home/nathan/data/kraken/commitment/test/MK0003/Pos1/Pos1_stacks/rfp_short.tif') # 3 dimensions : frames x width x height\n",
    "print(1)\n",
    "img1 = io.imread('/home/nathan/data/kraken/commitment/test/MK0003/Pos1/Pos1_stacks/gfp_short.tif') # same shape as img0\n",
    "print(2)\n",
    "\n",
    "# both stacks must have the same shape\n",
    "assert img0.shape == img1.shape\n",
    "print(3)\n",
    "\n",
    "# create operator using transformation\n",
    "sr = StackReg(StackReg.RIGID_BODY) \n",
    "print(4, 'long step')\n",
    "# register each frame to the previous (already registered) one\n",
    "# this is what the original StackReg ImageJ plugin uses\n",
    "tmats = sr.register_stack(img0, reference='previous')\n",
    "print(4.5)\n",
    "out = sr.transform_stack(img1)\n",
    "print(5)\n",
    "\n",
    "# tmats contains the transformation matrices -> they can be saved\n",
    "# and loaded at another time\n",
    "import numpy as np\n",
    "np.save('/home/nathan/data/kraken/commitment/test/MK0003/Pos1/Pos1_stacks/transformation_matrices.npy', tmats)\n",
    "print(6)\n",
    "\n",
    "tmats_loaded = np.load('/home/nathan/data/kraken/commitment/test/MK0003/Pos1/Pos1_stacks/transformation_matrices.npy')\n",
    "print(7)\n",
    "\n",
    "# make sure you use the correct transformation here!\n",
    "sr = StackReg(StackReg.RIGID_BODY)\n",
    "print(8)\n",
    "\n",
    "# transform stack using the tmats loaded from file\n",
    "sr.transform_stack(img1, tmats=tmats_loaded)\n",
    "print(9)\n",
    "\n",
    "# with the transformation matrices at hand you can also\n",
    "# use the transformation algorithms from other packages:\n",
    "from skimage import transform as tf\n",
    "\n",
    "out = np.zeros(img0.shape).astype(float)\n",
    "print(10)\n",
    "\n",
    "for i in tqdm(range(tmats.shape[0])):\n",
    "    tform = tf.AffineTransform(matrix=tmats[i, :, :])\n",
    "    out[i, :, :] = tf.warp(img1[i, :, :], tform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465850fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(sr.transform_stack(img1, tmats=tmats_loaded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7e935c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bbdf539",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img0[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee27fbb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(out[i])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bc481ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### Macro code from Fiji\n",
    "\n",
    "# macro \"Remove blanks+align GFP\" {\n",
    "\n",
    "# // Batch mode allows fiji to work with images but not have them actually open - saves time and memory\n",
    "# setBatchMode(true);\n",
    "\n",
    "# // Choose the PosX you wish to align, get info on which files are present, and the name of the folder\n",
    "# dir = getDirectory(\"Choose a Directory\");\n",
    "# lista = getFileList(dir);\n",
    "# name = File.getName(dir);\n",
    "\n",
    "\n",
    "\n",
    "initial_img_dir = f'/home/nathan/data/kraken/commitment/test/{expt}/{pos}'\n",
    "#file_list = os.listdir(initial_img_dir)\n",
    "### or for full list of file paths\n",
    "file_list = glob.glob(os.path.join(initial_img_dir, '*.tif'))\n",
    "\n",
    "# // Name and create the 'raw' and 'blanks_removed' folders.\n",
    "# rawName=name+\"_raw\";\n",
    "# rawDir=dir+rawName;\n",
    "\n",
    "# make directories to organise raw and blanks into\n",
    "os.mkdir(os.path.join(initial_img_dir, f'{pos}_raw'))\n",
    "os.mkdir(os.path.join(initial_img_dir, f'{pos}_blanks'))\n",
    "\n",
    "# File.makeDirectory(rawDir);\n",
    "\n",
    "# this creates seperate directories for each channel of removed blanks\n",
    "## necessary????\n",
    "# Pname = name + \"_blanks_removed\";\n",
    "# Ch0=Pname+\"_Ch0\";\n",
    "# Ch1=Pname+\"_Ch1\";\n",
    "# Ch2=Pname+\"_Ch2\";\n",
    "# Ch0folder=dir+Ch0;\n",
    "# File.makeDirectory(Ch0folder);\n",
    "# Ch1folder=dir+Ch1;\n",
    "# File.makeDirectory(Ch1folder);\n",
    "# Ch2folder=dir+Ch2;\n",
    "# File.makeDirectory(Ch2folder);\n",
    "\n",
    "\n",
    "# // Define the image prefix for each channel\n",
    "# Ch0prefix = \"img_channel000\";\n",
    "# Ch1prefix = \"img_channel001\";\n",
    "# Ch2prefix = \"img_channel002\";\n",
    "# //Number of images\n",
    "# numberSlice=lista.length;\n",
    "# // import all the images in the PosX folder\n",
    "# run(\"Image Sequence...\",\"open=&dir number=\"+numberSlice+\" starting=1 increment=1 scale=100 file=channel sort\");\n",
    "# // Select the stack\n",
    "# imageID= getImageID();\n",
    "# if (isOpen (imageID)) {\n",
    "# selectImage (imageID);\n",
    "# }\n",
    "# // Define the number of channels and timepoints of the experiment\n",
    "# nChannels=3;\n",
    "# nFrames = nSlices / nChannels;\n",
    "# // Create a hyperstack\n",
    "# run(\"Stack to Hyperstack...\", \"order=xytcz channels=\" + nChannels + \" slices=1 frames=\" + nFrames + \" display=Grayscale\");\n",
    "# // Run the Measurestack function (described below)\n",
    "\n",
    "# Measurestack in imagej is employed to measure the mean value of each image\n",
    "# iterate over each channel and all frames in channel to measure mean value\n",
    "#exclude if <2 or >200\n",
    "\n",
    "\n",
    "\n",
    "# Measurestack(imageID);\n",
    "# function Measurestack(imageID) {\n",
    "# \tsetOption(\"Stack position\", true);\n",
    "\n",
    "# \t// For each slice (aka frame) measure the mean image value, and get info regarding frame and channel\n",
    "# \tfor (slice=1; slice<=nSlices; slice++) {\n",
    "# \t\tsetSlice(slice);\n",
    "# \t\trun(\"Measure\");\n",
    "# \t\tr=getResult(\"Mean\");\n",
    "# \t\tframe=getResult(\"Frame\");\n",
    "# \t\tchannel=getResult(\"Ch\");\n",
    "\n",
    "# \t\t\t// Depending on the mean value, either do nothing or move the image if it's not suitable for alignment (by calling the MoveBoOX function)\n",
    "# \t\t\tif (r<=2) {\n",
    "# \t\t\tprint(\"Mean: \" + r + \". \" + \"frame: \" + frame + \" Ch: \" + channel + \" is a blank\");\n",
    "# \t\t\tMoveBoOX(imageID);\n",
    "# \t\t\t}\n",
    "# \t\t\telse if (r>=200) {\n",
    "# \t\t\tprint(\"Mean: \" + r + \". \" + \"frame: \" + frame + \" Ch: \" + channel + \" is overexposed\");\n",
    "# \t\t\tMoveBoOX(imageID);\n",
    "# \t\t\t}\n",
    "# \t\t\telse if (r>2 && r<200) {\n",
    "# \t\t\tprint(\"Mean: \" + r + \". \" + \"frame: \" + frame + \" Ch: \" + channel);\n",
    "# \t\t\t}\n",
    "# \t}\n",
    "# }\n",
    "\n",
    "# // MoveBoOX function will move all channels related to an over or underexposed frame to the _raw folder\n",
    "# function MoveBoOX(imageID) {\n",
    "\n",
    "# \t// frame is frame -1 because fiji starts from 1, but files start from 0\n",
    "# \tframeN=getValue(\"Frame\")-1;\n",
    "# \tprint(frameN);\n",
    "# \tend=\"\"+frameN+\"_z000.tif\";\n",
    "# \tprint(end);\n",
    "# \t// For any image in the list that has the specified frame, move it to _raw folder\n",
    "# \tfor (i = 0; i < lista.length; i++) {\n",
    "# \t\tif (endsWith(lista[i], end)) {\n",
    "# \t\tFile.rename(dir+lista[i], rawDir+File.separator+lista[i]);\n",
    "# \t\t}\n",
    "# \t}\n",
    "# }\n",
    "\n",
    "# // Any image that was ok for mean value, move it to a _blanks_removed folder, according to the specific channel\n",
    "# for (i = 0; i < lista.length; i++) {\n",
    "# \t\tif (startsWith(lista[i], Ch0prefix)) {\n",
    "# \t\tFile.rename(dir+lista[i], Ch0folder+File.separator+lista[i]);\n",
    "# \t\t}\n",
    "# \t\tif (startsWith(lista[i], Ch1prefix)) {\n",
    "# \t\tFile.rename(dir+lista[i], Ch1folder+File.separator+lista[i]);\n",
    "# \t\t}\n",
    "# \t\tif (startsWith(lista[i], Ch2prefix)) {\n",
    "# \t\tFile.rename(dir+lista[i], Ch2folder+File.separator+lista[i]);\n",
    "# \t\t}\n",
    "# }\n",
    "\n",
    "# print(\"\");\n",
    "# print(\"Blanks Removed\");\n",
    "# print(\"\");\n",
    "# run(\"Clear Results\");\n",
    "# run(\"Close All\");\n",
    "\n",
    "# // Run the transform function\n",
    "# Transform (imageID);\n",
    "\n",
    "# function Transform (imageID) {\n",
    "\n",
    "# \t// Create folders for _aligned and _transforms files\n",
    "# \tname=File.getName(dir);\n",
    "# \toutputName = name+\"_aligned\";\n",
    "# \toutput = dir+outputName;\n",
    "# \tFile.makeDirectory(output);\n",
    "# \tTransformsname=name+\"_transforms\";\n",
    "# \tTransforms=dir+Transformsname;\n",
    "# \tFile.makeDirectory(Transforms);\n",
    "\n",
    "# \t// Run the register virtual stack function on ch1 with the specified settings, save the transform matrices\n",
    "# \tprint(\"Running Register Virtual Stack Slices on Ch1...\");\n",
    "# \trun(\"Register Virtual Stack Slices\", \"source=[\"+Ch1folder+\"] output=[\"+output+\"] feature=Translation registration=[Translation          -- no deformation                      ] save shrinkage\");\n",
    "# \tprint(\"Ch1 registered and trasforms stored\");\n",
    "# \tCh1image=getTitle();\n",
    "# \tclose(Ch1image);\n",
    "\n",
    "# \t// Run the transofrm virtual stack function on ch0 with the correct transformation matrices\n",
    "# \tprint(\"Running Transform Virtual Stack Slices on Ch0...\");\n",
    "# \trun(\"Transform Virtual Stack Slices\", \"source=[\"+Ch0folder+\"] output=[\"+output+\"] transforms=[\"+Transforms+\"]\");\n",
    "# \tprint(\"Ch0 transformed\");\n",
    "# \tCh0image=getTitle();\n",
    "# \tclose(Ch0image);\n",
    "\n",
    "# \t// Run the transofrm virtual stack function on ch2 with the correct transformation matrices\n",
    "# \tprint(\"Running Transform Virtual Stack Slices on Ch2...\");\n",
    "# \trun(\"Transform Virtual Stack Slices\", \"source=[\"+Ch2folder+\"] output=[\"+output+\"] transforms=[\"+Transforms+\"]\");\n",
    "# \tprint(\"Ch2 transformed\");\n",
    "# \tCh2image=getTitle();\n",
    "# \tclose(Ch2image);\n",
    "\n",
    "# \tprint(\"Finished\");\n",
    "\n",
    "# \t// Save the log data as a log file\n",
    "# \tselectWindow(\"Log\");\n",
    "# \tLogName=\"Log_blanks_e_register\";\n",
    "# \tsaveAs(\"text\", dir+LogName);\n",
    "# }\n",
    "\n",
    "# // Move all original files in the _blanks_removed folders to the raw folder.\n",
    "# print(\"Moving files to raw folder...\");\n",
    "\n",
    "# listCh0=getFileList(Ch0folder);\n",
    "# for (i = 0; i < listCh0.length; i++) {\n",
    "# \tFile.rename(Ch0folder+File.separator+listCh0[i], rawDir+File.separator+listCh0[i]);\n",
    "# \t}\n",
    "\n",
    "# listCh1=getFileList(Ch1folder);\n",
    "# for (j = 0; j < listCh1.length; j++) {\n",
    "# \tFile.rename(Ch1folder+File.separator+listCh1[j], rawDir+File.separator+listCh1[j]);\n",
    "# \t}\n",
    "\n",
    "# listCh2=getFileList(Ch2folder);\n",
    "# for (k = 0; k < listCh2.length; k++) {\n",
    "# \tFile.rename(Ch2folder+File.separator+listCh2[k], rawDir+File.separator+listCh2[k]);\n",
    "# \t}\n",
    "\n",
    "# // Delete the empty folders\n",
    "# print(\"deleting intermediate folders...\");\n",
    "# File.delete(Ch0folder);\n",
    "# File.delete(Ch1folder);\n",
    "# File.delete(Ch2folder);\n",
    "\n",
    "# // Clear the log window\n",
    "# print(\"\\\\Clear\");\n",
    "# }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CellX",
   "language": "python",
   "name": "cellx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
