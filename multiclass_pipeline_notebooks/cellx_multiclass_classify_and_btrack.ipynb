{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1cada0f4",
   "metadata": {},
   "source": [
    "# Phenotype classifcation using CellX \n",
    "\n",
    "This notebook shows how to take segmented time lapse microscopy images and use h2b fluorescence markers to classfiy mitotic state of the cell cycle. \n",
    "\n",
    "The sections of this notebook are as follows:\n",
    "\n",
    "1. Load images\n",
    "2. Localise the objects\n",
    "3. Classify the objects\n",
    "4. Filter the objects\n",
    "5. Run btrack, uniting the objects locations over time\n",
    "\n",
    "The data used in this notebook is timelapse microscopy data with h2b-gfp/rfp markers that show the spatial extent of the nucleus and it's mitotic state. \n",
    "\n",
    "This notebook uses the dask octopuslite image loader from the CellX/Lowe lab project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c311e3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from octopuslite import DaskOctopusLiteLoader, image_generator\n",
    "import btrack\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.io import imread, imshow\n",
    "from cellx import load_model\n",
    "from cellx.tools.image import InfinitePaddedImage\n",
    "from skimage.transform import resize\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = [18,8]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a5906f",
   "metadata": {},
   "source": [
    "## 1. Load segmentation images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "67ee9d2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cropping: (1200, 1600)\n"
     ]
    }
   ],
   "source": [
    "# load images\n",
    "expt = 'ND0011'\n",
    "pos = 'Pos6'\n",
    "root_dir = '/home/nathan/data'\n",
    "image_path = f'{root_dir}/{expt}/{pos}/{pos}_images'\n",
    "images = DaskOctopusLiteLoader(image_path, crop=(1200,1600), remove_background=False)\n",
    "## efficiently load segmentation images by providing the path to the generator function\n",
    "segmentation = image_generator(images.files('mask'), crop=(1200,1600))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfccac2e",
   "metadata": {},
   "source": [
    "## 2. Localise the objects\n",
    "We need to also measure the mean intensity regionprops parameter in order to differentiate object class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06e130c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "objects = btrack.utils.segmentation_to_objects(\n",
    "    segmentation,\n",
    "    properties = ('area', 'mean_intensity'),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa49b7b",
   "metadata": {},
   "source": [
    "#### Can also assign measured values from raw image to each segment using `skimage.measure.regionprops` parameters\n",
    "But also need to load the raw images to be measured first and redefine the segmentation image generator as we are using again. Cannot currently save out `intensity_image` parameter to object file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a4548905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cropping: (1200, 1600)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[INFO][2022/01/21 04:44:05 PM] Localizing objects from segmentation...\n",
      "[INFO][2022/01/21 04:44:05 PM] Found intensity_image data\n",
      "[INFO][2022/01/21 04:44:05 PM] Calculating weighted centroids using intensity_image\n",
      "[INFO][2022/01/21 04:44:05 PM] Objects are of type: <class 'dict'>\n",
      "[INFO][2022/01/21 04:44:05 PM] ...Found 596 objects in 9 frames.\n"
     ]
    }
   ],
   "source": [
    "gfp = image_generator(images.files('gfp'), crop=(1200,1600))\n",
    "segmentation = image_generator(images.files('mask'), crop=(1200,1600))\n",
    "detailed_objects = btrack.utils.segmentation_to_objects(\n",
    "    segmentation,\n",
    "    gfp,\n",
    "    properties = ('area', 'mean_intensity', 'intensity_image'), \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "91e2efcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>t</th>\n",
       "      <th>dummy</th>\n",
       "      <th>states</th>\n",
       "      <th>label</th>\n",
       "      <th>prob</th>\n",
       "      <th>area</th>\n",
       "      <th>intensity_image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>284.482239</td>\n",
       "      <td>783.94415</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1026</td>\n",
       "      <td>(37, 36) array</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "{'ID': 0, 'x': 284.48223906409874, 'y': 783.9441501643441, 'z': 0.0, 't': 0, 'dummy': False, 'states': 0, 'label': 5, 'prob': 0.0, 'area': 1026, 'intensity_image': array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=uint8)}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detailed_objects[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63775a4c",
   "metadata": {},
   "source": [
    "Example image showing PCNA-iRFP morphology "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d3a75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(detailed_objects[0].properties['intensity_image'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08114355",
   "metadata": {},
   "source": [
    "## 2b. Differentiate the objects based on class ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583c2fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_gfp = [obj for obg in objects if obj.properties['mean_intensity'] == 1]\n",
    "objects_rfp = [obj for obg in objects if obj.properties['mean_intensity'] == 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbc05b98",
   "metadata": {},
   "source": [
    "## 3. Classify the objects "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1725583",
   "metadata": {},
   "source": [
    "Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10cd85e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('./models/cellx_classifier_stardist.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bce619f",
   "metadata": {},
   "source": [
    "Define normalisation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92d135ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_channels(x):\n",
    "\n",
    "    for dim in range(x.shape[-1]):\n",
    "        x[..., dim] = normalize(x[..., dim])\n",
    "        \n",
    "    return x\n",
    "\n",
    "def normalize(x):\n",
    "\n",
    "    xf = x.astype(np.float32)\n",
    "    mx = np.mean(xf)\n",
    "    sd = np.max([np.std(xf), 1./np.prod(x.shape)])\n",
    "\n",
    "    return (xf - mx) / sd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb8428f",
   "metadata": {},
   "source": [
    "Define classifier function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "41184a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_objects(image, objects, obj_type):\n",
    "    \n",
    "    # define stages of cell cycle to classify (dependent on model type)\n",
    "    LABELS = [\"interphase\", \"prometaphase\", \"metaphase\", \"anaphase\", \"apoptosis\"]\n",
    "    \n",
    "    # iterate over frames\n",
    "    for n in tqdm(range(image.shape[0])):\n",
    "        \n",
    "        # only select objects if in frame\n",
    "        _objects = [o for o in objects if o.t == n]\n",
    "        \n",
    "        # empty placeholder arrays\n",
    "        crops = []\n",
    "        to_update = []\n",
    "        \n",
    "        # select h2b channel to aid in classification\n",
    "        fp = gfp if obj_type == 1 else rfp\n",
    "        \n",
    "        # create stack by computing each frame of dask array input\n",
    "        frame = np.stack(\n",
    "            [image[n, ...].compute(), fp[n, ...].compute()], \n",
    "            axis=-1,) \n",
    "        \n",
    "        # create padded image for network\n",
    "        vol = InfinitePaddedImage(frame, mode = 'reflect')\n",
    "        \n",
    "        # iterate over objects \n",
    "        for obj in _objects:\n",
    "            \n",
    "            # create coords for image slice\n",
    "            xs = slice(int(obj.x-40), int(obj.x+40), 1)\n",
    "            ys = slice(int(obj.y-40), int(obj.y+40), 1)\n",
    "            \n",
    "            # crop image\n",
    "            crop = vol[ys, xs, :]\n",
    "            crop = resize(crop, (64, 64), preserve_range=True).astype(np.float32)\n",
    "            \n",
    "            # normalise image\n",
    "            if crop.shape == (64 ,64, 2):\n",
    "                crops.append(normalize_channels(crop))\n",
    "                to_update.append(obj)\n",
    "            else:\n",
    "                print(crop.shape)\n",
    "                \n",
    "        if not crops:\n",
    "            continue\n",
    "            \n",
    "        # use classifcation model to predict\n",
    "        pred = model.predict(np.stack(crops, axis=0))\n",
    "        \n",
    "        # check correct number of predictions\n",
    "        assert pred.shape[0] == len(_objects)\n",
    "        \n",
    "        # assign labels to objects\n",
    "        for idx in range(pred.shape[0]):\n",
    "            obj = _objects[idx]\n",
    "            \n",
    "            # assigning details of prediction\n",
    "            pred_label = np.argmax(pred[idx, ...])\n",
    "            pred_softmax = softmax(pred[idx, ...])\n",
    "            logits = {f\"prob_{k}\": pred_softmax[ki] for ki, k in enumerate(LABELS)}\n",
    "            \n",
    "            # write out\n",
    "            obj.label = pred_label\n",
    "            obj.properties = logits\n",
    "\n",
    "    return objects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db8781b4",
   "metadata": {},
   "source": [
    "#### Load raw images for classifier, a colour channel dependent on `obj_type` needed too (i.e. GFP is `obj_type = 1`, RFP is `obj_type = 2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657771d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bf = images['brightfield']\n",
    "gfp = images['gfp']\n",
    "rfp = images['rfp']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30835a86",
   "metadata": {},
   "source": [
    "#### Classify objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420e84c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_gfp = classify_objects(bf, objects_gfp, obj_type = 1)\n",
    "objects_rfp = classify_objects(bf, objects_rfp, obj_type = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70646be",
   "metadata": {},
   "source": [
    "#### Inspect an example object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec4f611",
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_gfp[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c5c716",
   "metadata": {},
   "source": [
    "#### Save out classified GFP objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796afd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "with btrack.dataio.HDF5FileHandler(\n",
    "    f'{root_dir}/{expt}/{pos}/segmented.h5', 'w', obj_type='obj_type_1',\n",
    ") as hdf:\n",
    "    #hdf.write_segmentation(masks['mask'])\n",
    "    hdf.write_objects(objects_gfp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdb0274",
   "metadata": {},
   "source": [
    "#### Save out classified RFP objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71de0f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "with btrack.dataio.HDF5FileHandler(\n",
    "    f'{root_dir}/{expt}/{pos}/segmented.h5', 'w', obj_type='obj_type_2',\n",
    ") as hdf:\n",
    "    #hdf.write_segmentation(masks['mask'])\n",
    "    hdf.write_objects(objects_rfp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b1696a",
   "metadata": {},
   "source": [
    "## 4. Filter the objects \n",
    "\n",
    "Based on segments that are too small to feasibly be cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f660dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "objects_gfp = [o for o in objects_gfp if o.properties['area']>100.]\n",
    "objects_rfp = [o for o in objects_rfp if o.properties['area']>100.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e64ac4ae",
   "metadata": {},
   "source": [
    "## 5. Run btrack  \n",
    "\n",
    "Unite each object with it's subsequent position at the following time point and export as a tracking file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e456e142",
   "metadata": {},
   "source": [
    "#### For GFP objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb6623e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# initialise a tracker session using a context manager\n",
    "with btrack.BayesianTracker() as tracker:\n",
    "\n",
    "    # configure the tracker using a config file\n",
    "    tracker.configure_from_file(\n",
    "        './models/MDCK_config_wildtype.json'\n",
    "    )\n",
    "    tracker.max_search_radius = 40\n",
    "\n",
    "    # append the objects to be tracked\n",
    "    tracker.append(objects_gfp)\n",
    "\n",
    "    # set the volume\n",
    "    tracker.volume=((0, 1200), (0, 1600), (-1e5, 1e5))\n",
    "\n",
    "    # track them (in interactive mode)\n",
    "    tracker.track_interactive(step_size=100)\n",
    "\n",
    "    # generate hypotheses and run the global optimizer\n",
    "    tracker.optimize()\n",
    "\n",
    "    tracker.export(f'{root_dir}/{expt}/{pos}/tracks.h5', obj_type='obj_type_1')\n",
    "\n",
    "    # get the tracks in a format for napari visualization (optional)\n",
    "    visaulise_tracks, properties, graph = tracker.to_napari(ndim=2)\n",
    "    \n",
    "    gfp_tracks = tracker.tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e418844",
   "metadata": {},
   "source": [
    "#### For RFP objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76bb469",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise a tracker session using a context manager\n",
    "with btrack.BayesianTracker() as tracker:\n",
    "\n",
    "    # configure the tracker using a config file\n",
    "    tracker.configure_from_file(\n",
    "        './models/MDCK_config_scribble_sparse.json'\n",
    "    )\n",
    "    tracker.max_search_radius = 40\n",
    "\n",
    "    # append the objects to be tracked\n",
    "    tracker.append(objects_rfp)\n",
    "\n",
    "    # set the volume\n",
    "    tracker.volume=((0, 1200), (0, 1600), (-1e5, 1e5))\n",
    "\n",
    "    # track them (in interactive mode)\n",
    "    tracker.track_interactive(step_size=100)\n",
    "\n",
    "    # generate hypotheses and run the global optimizer\n",
    "    tracker.optimize()\n",
    "\n",
    "    tracker.export(f'{root_dir}/{expt}/{pos}/tracks.h5', obj_type='obj_type_2')\n",
    "\n",
    "    # get the tracks in a format for napari visualization (optional)\n",
    "    visaulise_tracks, properties, graph = tracker.to_napari(ndim=2)\n",
    "    \n",
    "    rfp_tracks = tracker.tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b2e10e7",
   "metadata": {},
   "source": [
    "# 6. Batch process\n",
    "Iterate over many experiments and positions (need to ensure you define normalisation and classification functions above first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1792133",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = '/home/nathan/data'\n",
    "expt_list = ['ND0009', 'ND0010', 'ND0011']\n",
    "pos_list = 'all'\n",
    "overwrite = False\n",
    "\n",
    "for expt in expt_list:\n",
    "    \n",
    "        # Find all positions in that experiment, if pos_list is all then it finds all positions\n",
    "        if pos_list == 'all':\n",
    "            pos_list = [pos for pos in os.listdir(f'{root_dir}/{expt}') \n",
    "                    if 'Pos' in pos \n",
    "                    and os.path.isdir(f'{root_dir}/{expt}/{pos}')]  \n",
    "            \n",
    "        ### Iterate over all positions in that experiment\n",
    "        for pos in pos_list:\n",
    "            \n",
    "            ### check if overwrite param is false check if raw directory already created and if type of transform file already exists and decide whether to skip pos\n",
    "            if not overwrite and glob.glob(f'{root_dir}/{expt}/{pos}/*tracks*.h5'):\n",
    "                print(glob.glob(f'{root_dir}/{expt}/{pos}/*tracks*.h5'), f'file found, skipping {expt}/{pos}')\n",
    "                continue\n",
    "                \n",
    "            print(f'Starting {expt}/{pos}')\n",
    "            # load segmentation images in efficient image generator style\n",
    "            segmentation = image_generator(images.files('mask'), crop=(1200,1600))\n",
    "            \n",
    "            # ID the objects in each segmentation image and assign option properties to them\n",
    "            objects = btrack.utils.segmentation_to_objects(\n",
    "            segmentation,\n",
    "            properties = ('area', ),\n",
    "            )\n",
    "            \n",
    "            # differentiate the objects based on class ID\n",
    "            objects_gfp = [obj for obg in objects if obj.properties['mean_intensity'] == 1]\n",
    "            objects_rfp = [obj for obg in objects if obj.properties['mean_intensity'] == 2]\n",
    "            \n",
    "            # load classifcation model and define labels\n",
    "            model = load_model('./models/cellx_classifier_stardist.h5')\n",
    "            LABELS = [\"interphase\", \"prometaphase\", \"metaphase\", \"anaphase\", \"apoptosis\"]\n",
    "\n",
    "            # load images for classifcation\n",
    "            bf = images['brightfield']\n",
    "            gfp = images['gfp']\n",
    "            rfp = images['rfp']\n",
    "            \n",
    "            # classify objects\n",
    "            print(\"Classifying objects\")\n",
    "            objects_gfp = classify_objects(bf, objects_gfp, obj_type = 1)\n",
    "            objects_rfp = classify_objects(bf, objects_rfp, obj_type = 2)\n",
    "            \n",
    "            # save out classified objects as segmentation h5 file\n",
    "            with btrack.dataio.HDF5FileHandler(\n",
    "                f'{root_dir}/{expt}/{pos}/segmented.h5', 'w', obj_type='obj_type_1',\n",
    "            ) as hdf:\n",
    "                #hdf.write_segmentation(masks['mask'])\n",
    "                hdf.write_objects(objects_gfp)\n",
    "            with btrack.dataio.HDF5FileHandler(\n",
    "                f'{root_dir}/{expt}/{pos}/segmented.h5', 'w', obj_type='obj_type_2',\n",
    "            ) as hdf:\n",
    "                #hdf.write_segmentation(masks['mask'])\n",
    "                hdf.write_objects(objects_rfp)    \n",
    "            \n",
    "            # filter objects for non-cell type sizes\n",
    "            objects_gfp = [o for o in objects_gfp if o.properties['area']>100.]\n",
    "            objects_rfp = [o for o in objects_rfp if o.properties['area']>100.]\n",
    "            \n",
    "            # initialise a tracker session using a context manager for gfp\n",
    "            with btrack.BayesianTracker() as tracker:\n",
    "\n",
    "                # configure the tracker using a config file\n",
    "                tracker.configure_from_file(\n",
    "                    './models/MDCK_config_wildtype.json'\n",
    "                )\n",
    "                tracker.max_search_radius = 40\n",
    "\n",
    "                # append the objects to be tracked\n",
    "                tracker.append(objects_gfp)\n",
    "\n",
    "                # set the volume\n",
    "                tracker.volume=((0, 1200), (0, 1600), (-1e5, 1e5))\n",
    "\n",
    "                # track them (in interactive mode)\n",
    "                tracker.track_interactive(step_size=100)\n",
    "\n",
    "                # generate hypotheses and run the global optimizer\n",
    "                tracker.optimize()\n",
    "\n",
    "                tracker.export(f'{root_dir}/{expt}/{pos}/tracks.h5', obj_type='obj_type_1')\n",
    "\n",
    "            # initialise a tracker session using a context manager for rfp\n",
    "            with btrack.BayesianTracker() as tracker:\n",
    "\n",
    "                # configure the tracker using a config file\n",
    "                tracker.configure_from_file(\n",
    "                    './models/.json'\n",
    "                )\n",
    "                tracker.max_search_radius = 40\n",
    "\n",
    "                # append the objects to be tracked\n",
    "                tracker.append(objects_rfp)\n",
    "\n",
    "                # set the volume\n",
    "                tracker.volume=((0, 1200), (0, 1600), (-1e5, 1e5))\n",
    "\n",
    "                # track them (in interactive mode)\n",
    "                tracker.track_interactive(step_size=100)\n",
    "\n",
    "                # generate hypotheses and run the global optimizer\n",
    "                tracker.optimize()\n",
    "\n",
    "                tracker.export(f'{root_dir}/{expt}/{pos}/tracks.h5', obj_type='obj_type_2')\n",
    "                \n",
    "            print(f'Finished {expt}/{pos}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CellX",
   "language": "python",
   "name": "cellx"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
